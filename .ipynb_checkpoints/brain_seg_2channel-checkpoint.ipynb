{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tables\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import scipy.misc\n",
    "import scipy.stats \n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gist_earth'\n",
    "from PIL import Image\n",
    "\n",
    "from tf_unet import image_util\n",
    "from tf_unet import unet\n",
    "from tf_unet import util\n",
    "from tf_unet.image_util import ImageDataProvider\n",
    "from skimage import exposure, img_as_float#, #data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bggenerator(ImageDataProvider):\n",
    "    n_class = 3\n",
    "    channels = 2\n",
    "    def _load_file(self, path, dtype=np.float32):\n",
    "        img = nib.load(path)\n",
    "        data = img.get_data()[...,0,0]\n",
    "        if dtype == np.float32:\n",
    "            #print ('in load file: this is data file path: ')\n",
    "            #print (path)\n",
    "            data = img_as_float(data)\n",
    "            data = exposure.equalize_adapthist(data, clip_limit=0.01, nbins=256)\n",
    "            #print ('in load_file')\n",
    "            #print(path)\n",
    "            #print (np.max(data))\n",
    "            #data = exposure.equalize_hist(data, nbins=4096)        \n",
    "            #data =data * 4096\n",
    "        #data = scipy.misc.imresize(data,[472,760], interp='bilinear', mode=None)\n",
    "        data = np.pad(data,20,'constant')\n",
    "        data = np.rot90(data)\n",
    "        \n",
    "        #used to be [148, 220]\n",
    "        #print (path)\n",
    "        #print (type(data))\n",
    "        #print (data.shape)\n",
    "        return np.array(data, dtype)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files entries used: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mri/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "generator = bggenerator(\"./data/*/*.hdr\",data_suffix=\"DeepCorT1.hdr\",mask_suffix=\"DeepBinary.hdr\",data2_suffix=\"DeepCorSWIM.hdr\")\n",
    "x_test, y_test = generator(1)\n",
    "\n",
    "#print ('in here')\n",
    "#print (generator(2)[1].shape)\n",
    "#print (generator(2)[0].shape)\n",
    "#print (np.max(generator(22)[1]))\n",
    "#print (np.max(generator(22)[0]))\n",
    "#print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75c4c346a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAEyCAYAAAD3I/0kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgr/H6/H6qKDZrr0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75c4dd8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,4, sharey=True, figsize=(16,5))\n",
    "ax[0].imshow(x_test[0,...,0], aspect=\"auto\")\n",
    "ax[1].imshow(x_test[0,...,1], aspect=\"auto\")\n",
    "ax[2].imshow(y_test[0,...,1], aspect=\"auto\")\n",
    "ax[3].imshow(y_test[0,...,2], aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.histogram([1,2,3,4])\n",
    "#stats.itemfreq([1,2,3,4])\n",
    "#img = nib.load('./data/1/DeepCorSWIM.hdr')\n",
    "#data = img.get_data()[...,0,0]\n",
    "#print(type(data))\n",
    "#print(data.shape)\n",
    "#data2 = np.pad(data,20,'constant')\n",
    "#data2.shape    \n",
    "#print(np.min(data))\n",
    "#print(np.max(data))\n",
    "#print(type(data))\n",
    "#plt.imshow(data,aspect = 'auto')\n",
    "#plt.imshow(data2,aspect = 'auto')\n",
    "#import os\n",
    "#img = nib.Nifti1Image(mask, np.eye(4))\n",
    "#print (mask.dtype)\n",
    "#print (img.get_data_dtype() == np.dtype(np.float32))\n",
    "#print (img.header.get_xyzt_units())\n",
    "#nib.save(img, os.path.join('build','mask3.nii.gz'))\n",
    "\n",
    "#img = nib.load('./build/mask3.nii.gz')\n",
    "#print(img.shape)\n",
    "#data = img.get_data()\n",
    "#data = img.get_data()[...,0,0]\n",
    "#plt.imshow(data, aspect = 'auto')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 12:15:28,780 Layers 3, features 256, filter size 3x3, pool size: 2x2\n"
     ]
    }
   ],
   "source": [
    "net = unet.Unet(channels=generator.channels, n_class=generator.n_class, layers=3, features_root=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = unet.Trainer(net)#,optimizer = \"adam\",opt_kwargs = dict(adam=0.01))#, optimizer=\"adam\", opt_kwargs=dict(adam=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: adams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 12:15:29,862 Removing '/home/mri/Desktop/to_wanglin/brain_seg_mult/prediction'\n",
      "2017-09-03 12:15:29,864 Removing '/home/mri/Desktop/to_wanglin/brain_seg_mult/unet_trained'\n",
      "2017-09-03 12:15:29,897 Allocating '/home/mri/Desktop/to_wanglin/brain_seg_mult/prediction'\n",
      "2017-09-03 12:15:29,898 Allocating '/home/mri/Desktop/to_wanglin/brain_seg_mult/unet_trained'\n",
      "/home/mri/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "2017-09-03 12:15:31,378 Verification error= 69.6%, loss= 1.0836\n",
      "2017-09-03 12:15:31,611 Start optimization\n",
      "2017-09-03 12:15:32,698 Iter 0, Minibatch Loss= 4.2134, Training Accuracy= 0.7995, Minibatch error= 20.1%\n",
      "2017-09-03 12:15:42,823 Iter 50, Minibatch Loss= 0.8607, Training Accuracy= 0.7583, Minibatch error= 24.2%\n",
      "2017-09-03 12:15:52,489 Epoch 0, Average loss: 0.8206, learning rate: 0.0010\n",
      "2017-09-03 12:15:52,570 Verification error= 19.7%, loss= 0.7130\n",
      "2017-09-03 12:15:53,420 Iter 100, Minibatch Loss= 0.6712, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-09-03 12:16:03,867 Iter 150, Minibatch Loss= 0.3874, Training Accuracy= 0.8242, Minibatch error= 17.6%\n",
      "2017-09-03 12:16:14,166 Epoch 1, Average loss: 0.4108, learning rate: 0.0010\n",
      "2017-09-03 12:16:14,240 Verification error= 14.3%, loss= 0.3607\n",
      "2017-09-03 12:16:15,626 Iter 200, Minibatch Loss= 0.3656, Training Accuracy= 0.8570, Minibatch error= 14.3%\n",
      "2017-09-03 12:16:26,469 Iter 250, Minibatch Loss= 0.4715, Training Accuracy= 0.8060, Minibatch error= 19.4%\n",
      "2017-09-03 12:16:37,131 Epoch 2, Average loss: 0.3579, learning rate: 0.0010\n",
      "2017-09-03 12:16:37,206 Verification error= 14.2%, loss= 0.3528\n",
      "2017-09-03 12:16:38,607 Iter 300, Minibatch Loss= 0.2783, Training Accuracy= 0.8906, Minibatch error= 10.9%\n",
      "2017-09-03 12:16:49,944 Iter 350, Minibatch Loss= 0.3114, Training Accuracy= 0.8448, Minibatch error= 15.5%\n",
      "2017-09-03 12:17:00,802 Epoch 3, Average loss: 0.3478, learning rate: 0.0010\n",
      "2017-09-03 12:17:00,877 Verification error= 14.0%, loss= 0.3717\n",
      "2017-09-03 12:17:02,343 Iter 400, Minibatch Loss= 0.3886, Training Accuracy= 0.8677, Minibatch error= 13.2%\n",
      "2017-09-03 12:17:13,745 Iter 450, Minibatch Loss= 0.3500, Training Accuracy= 0.8706, Minibatch error= 12.9%\n",
      "2017-09-03 12:17:24,961 Epoch 4, Average loss: 0.3404, learning rate: 0.0010\n",
      "2017-09-03 12:17:25,035 Verification error= 13.7%, loss= 0.3748\n",
      "2017-09-03 12:17:26,600 Iter 500, Minibatch Loss= 0.3117, Training Accuracy= 0.9023, Minibatch error= 9.8%\n",
      "2017-09-03 12:17:38,416 Iter 550, Minibatch Loss= 0.4080, Training Accuracy= 0.7956, Minibatch error= 20.4%\n",
      "2017-09-03 12:17:50,048 Epoch 5, Average loss: 0.3326, learning rate: 0.0010\n",
      "2017-09-03 12:17:50,121 Verification error= 14.8%, loss= 0.3589\n",
      "2017-09-03 12:17:51,618 Iter 600, Minibatch Loss= 0.3073, Training Accuracy= 0.8581, Minibatch error= 14.2%\n",
      "2017-09-03 12:18:03,867 Iter 650, Minibatch Loss= 0.3633, Training Accuracy= 0.8195, Minibatch error= 18.0%\n",
      "2017-09-03 12:18:15,891 Epoch 6, Average loss: 0.3251, learning rate: 0.0010\n",
      "2017-09-03 12:18:15,965 Verification error= 15.5%, loss= 0.4069\n",
      "2017-09-03 12:18:17,516 Iter 700, Minibatch Loss= 0.4695, Training Accuracy= 0.7995, Minibatch error= 20.1%\n",
      "2017-09-03 12:18:30,127 Iter 750, Minibatch Loss= 0.3820, Training Accuracy= 0.8552, Minibatch error= 14.5%\n",
      "2017-09-03 12:18:42,566 Epoch 7, Average loss: 0.3221, learning rate: 0.0010\n",
      "2017-09-03 12:18:42,641 Verification error= 17.6%, loss= 0.4298\n",
      "2017-09-03 12:18:44,246 Iter 800, Minibatch Loss= 0.4105, Training Accuracy= 0.8190, Minibatch error= 18.1%\n",
      "2017-09-03 12:18:57,276 Iter 850, Minibatch Loss= 0.4046, Training Accuracy= 0.8339, Minibatch error= 16.6%\n",
      "2017-09-03 12:19:10,091 Epoch 8, Average loss: 0.3130, learning rate: 0.0010\n",
      "2017-09-03 12:19:10,165 Verification error= 17.9%, loss= 0.3735\n",
      "2017-09-03 12:19:11,898 Iter 900, Minibatch Loss= 0.4680, Training Accuracy= 0.7776, Minibatch error= 22.2%\n",
      "2017-09-03 12:19:25,391 Iter 950, Minibatch Loss= 0.2970, Training Accuracy= 0.8810, Minibatch error= 11.9%\n",
      "2017-09-03 12:19:38,703 Epoch 9, Average loss: 0.3105, learning rate: 0.0010\n",
      "2017-09-03 12:19:38,777 Verification error= 18.3%, loss= 0.3887\n",
      "2017-09-03 12:19:40,508 Iter 1000, Minibatch Loss= 0.3385, Training Accuracy= 0.8341, Minibatch error= 16.6%\n",
      "2017-09-03 12:19:54,511 Iter 1050, Minibatch Loss= 0.4044, Training Accuracy= 0.8346, Minibatch error= 16.5%\n",
      "2017-09-03 12:20:08,191 Epoch 10, Average loss: 0.3052, learning rate: 0.0010\n",
      "2017-09-03 12:20:08,266 Verification error= 18.3%, loss= 0.4076\n",
      "2017-09-03 12:20:10,010 Iter 1100, Minibatch Loss= 0.3737, Training Accuracy= 0.8391, Minibatch error= 16.1%\n",
      "2017-09-03 12:20:24,379 Iter 1150, Minibatch Loss= 0.3523, Training Accuracy= 0.8612, Minibatch error= 13.9%\n",
      "2017-09-03 12:20:38,557 Epoch 11, Average loss: 0.2972, learning rate: 0.0010\n",
      "2017-09-03 12:20:38,631 Verification error= 18.5%, loss= 0.3745\n",
      "2017-09-03 12:20:40,432 Iter 1200, Minibatch Loss= 0.4215, Training Accuracy= 0.7953, Minibatch error= 20.5%\n",
      "2017-09-03 12:20:55,243 Iter 1250, Minibatch Loss= 0.3461, Training Accuracy= 0.8091, Minibatch error= 19.1%\n",
      "2017-09-03 12:21:09,862 Epoch 12, Average loss: 0.2924, learning rate: 0.0010\n",
      "2017-09-03 12:21:09,939 Verification error= 19.2%, loss= 0.4025\n",
      "2017-09-03 12:21:11,766 Iter 1300, Minibatch Loss= 0.3993, Training Accuracy= 0.8042, Minibatch error= 19.6%\n",
      "2017-09-03 12:21:27,049 Iter 1350, Minibatch Loss= 0.5027, Training Accuracy= 0.7659, Minibatch error= 23.4%\n",
      "2017-09-03 12:21:42,057 Epoch 13, Average loss: 0.2877, learning rate: 0.0010\n",
      "2017-09-03 12:21:42,131 Verification error= 19.1%, loss= 0.4602\n",
      "2017-09-03 12:21:44,022 Iter 1400, Minibatch Loss= 0.4098, Training Accuracy= 0.8440, Minibatch error= 15.6%\n",
      "2017-09-03 12:21:59,698 Iter 1450, Minibatch Loss= 0.4490, Training Accuracy= 0.8089, Minibatch error= 19.1%\n",
      "2017-09-03 12:22:15,081 Epoch 14, Average loss: 0.2839, learning rate: 0.0010\n",
      "2017-09-03 12:22:15,157 Verification error= 19.1%, loss= 0.4452\n",
      "2017-09-03 12:22:17,072 Iter 1500, Minibatch Loss= 0.4300, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 12:22:33,110 Iter 1550, Minibatch Loss= 0.4999, Training Accuracy= 0.7672, Minibatch error= 23.3%\n",
      "2017-09-03 12:22:48,895 Epoch 15, Average loss: 0.2826, learning rate: 0.0010\n",
      "2017-09-03 12:22:48,969 Verification error= 19.4%, loss= 0.4076\n",
      "2017-09-03 12:22:50,953 Iter 1600, Minibatch Loss= 0.3141, Training Accuracy= 0.8802, Minibatch error= 12.0%\n",
      "2017-09-03 12:23:07,514 Iter 1650, Minibatch Loss= 0.3619, Training Accuracy= 0.8221, Minibatch error= 17.8%\n",
      "2017-09-03 12:23:23,819 Epoch 16, Average loss: 0.2799, learning rate: 0.0010\n",
      "2017-09-03 12:23:23,893 Verification error= 19.1%, loss= 0.4436\n",
      "2017-09-03 12:23:26,040 Iter 1700, Minibatch Loss= 0.4486, Training Accuracy= 0.8323, Minibatch error= 16.8%\n",
      "2017-09-03 12:23:43,012 Iter 1750, Minibatch Loss= 0.4031, Training Accuracy= 0.8339, Minibatch error= 16.6%\n",
      "2017-09-03 12:23:59,681 Epoch 17, Average loss: 0.2779, learning rate: 0.0010\n",
      "2017-09-03 12:23:59,755 Verification error= 18.9%, loss= 0.4323\n",
      "2017-09-03 12:24:01,823 Iter 1800, Minibatch Loss= 0.3870, Training Accuracy= 0.8578, Minibatch error= 14.2%\n",
      "2017-09-03 12:24:19,262 Iter 1850, Minibatch Loss= 0.4462, Training Accuracy= 0.7891, Minibatch error= 21.1%\n",
      "2017-09-03 12:24:36,423 Epoch 18, Average loss: 0.2733, learning rate: 0.0010\n",
      "2017-09-03 12:24:36,497 Verification error= 19.0%, loss= 0.4010\n",
      "2017-09-03 12:24:38,622 Iter 1900, Minibatch Loss= 0.3883, Training Accuracy= 0.8070, Minibatch error= 19.3%\n",
      "2017-09-03 12:24:56,512 Iter 1950, Minibatch Loss= 0.4290, Training Accuracy= 0.8055, Minibatch error= 19.5%\n",
      "2017-09-03 12:25:14,056 Epoch 19, Average loss: 0.2698, learning rate: 0.0010\n",
      "2017-09-03 12:25:14,130 Verification error= 18.9%, loss= 0.4449\n",
      "2017-09-03 12:25:16,317 Iter 2000, Minibatch Loss= 0.5175, Training Accuracy= 0.7674, Minibatch error= 23.3%\n",
      "2017-09-03 12:25:34,595 Iter 2050, Minibatch Loss= 0.4194, Training Accuracy= 0.8435, Minibatch error= 15.7%\n",
      "2017-09-03 12:25:52,523 Epoch 20, Average loss: 0.2726, learning rate: 0.0010\n",
      "2017-09-03 12:25:52,600 Verification error= 18.8%, loss= 0.4690\n",
      "2017-09-03 12:25:54,822 Iter 2100, Minibatch Loss= 0.4436, Training Accuracy= 0.8120, Minibatch error= 18.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 12:26:13,486 Iter 2150, Minibatch Loss= 0.3865, Training Accuracy= 0.8604, Minibatch error= 14.0%\n",
      "2017-09-03 12:26:31,805 Epoch 21, Average loss: 0.2667, learning rate: 0.0010\n",
      "2017-09-03 12:26:31,876 Verification error= 18.9%, loss= 0.4085\n",
      "2017-09-03 12:26:34,274 Iter 2200, Minibatch Loss= 0.5016, Training Accuracy= 0.7677, Minibatch error= 23.2%\n",
      "2017-09-03 12:26:53,351 Iter 2250, Minibatch Loss= 0.3104, Training Accuracy= 0.8870, Minibatch error= 11.3%\n",
      "2017-09-03 12:27:12,096 Epoch 22, Average loss: 0.2667, learning rate: 0.0010\n",
      "2017-09-03 12:27:12,168 Verification error= 18.6%, loss= 0.4234\n",
      "2017-09-03 12:27:14,476 Iter 2300, Minibatch Loss= 0.3703, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-09-03 12:27:34,018 Iter 2350, Minibatch Loss= 0.4368, Training Accuracy= 0.8367, Minibatch error= 16.3%\n",
      "2017-09-03 12:27:53,197 Epoch 23, Average loss: 0.2654, learning rate: 0.0010\n",
      "2017-09-03 12:27:53,272 Verification error= 18.1%, loss= 0.4397\n",
      "2017-09-03 12:27:55,644 Iter 2400, Minibatch Loss= 0.3835, Training Accuracy= 0.8443, Minibatch error= 15.6%\n",
      "2017-09-03 12:28:15,588 Iter 2450, Minibatch Loss= 0.3896, Training Accuracy= 0.8654, Minibatch error= 13.5%\n",
      "2017-09-03 12:28:35,188 Epoch 24, Average loss: 0.2626, learning rate: 0.0010\n",
      "2017-09-03 12:28:35,262 Verification error= 18.1%, loss= 0.4123\n",
      "2017-09-03 12:28:37,654 Iter 2500, Minibatch Loss= 0.4567, Training Accuracy= 0.8023, Minibatch error= 19.8%\n",
      "2017-09-03 12:28:58,082 Iter 2550, Minibatch Loss= 0.4092, Training Accuracy= 0.8193, Minibatch error= 18.1%\n",
      "2017-09-03 12:29:18,134 Epoch 25, Average loss: 0.2593, learning rate: 0.0010\n",
      "2017-09-03 12:29:18,206 Verification error= 17.9%, loss= 0.4231\n",
      "2017-09-03 12:29:20,641 Iter 2600, Minibatch Loss= 0.4264, Training Accuracy= 0.8201, Minibatch error= 18.0%\n",
      "2017-09-03 12:29:41,449 Iter 2650, Minibatch Loss= 0.5270, Training Accuracy= 0.7680, Minibatch error= 23.2%\n",
      "2017-09-03 12:30:01,962 Epoch 26, Average loss: 0.2587, learning rate: 0.0010\n",
      "2017-09-03 12:30:02,034 Verification error= 18.2%, loss= 0.4535\n",
      "2017-09-03 12:30:04,684 Iter 2700, Minibatch Loss= 0.3986, Training Accuracy= 0.8557, Minibatch error= 14.4%\n",
      "2017-09-03 12:30:25,955 Iter 2750, Minibatch Loss= 0.4281, Training Accuracy= 0.8065, Minibatch error= 19.3%\n",
      "2017-09-03 12:30:46,845 Epoch 27, Average loss: 0.2560, learning rate: 0.0010\n",
      "2017-09-03 12:30:46,918 Verification error= 17.6%, loss= 0.4060\n",
      "2017-09-03 12:30:49,455 Iter 2800, Minibatch Loss= 0.3729, Training Accuracy= 0.8341, Minibatch error= 16.6%\n",
      "2017-09-03 12:31:11,164 Iter 2850, Minibatch Loss= 0.4905, Training Accuracy= 0.7839, Minibatch error= 21.6%\n",
      "2017-09-03 12:31:32,464 Epoch 28, Average loss: 0.2534, learning rate: 0.0010\n",
      "2017-09-03 12:31:32,536 Verification error= 17.4%, loss= 0.3981\n",
      "2017-09-03 12:31:35,142 Iter 2900, Minibatch Loss= 0.2971, Training Accuracy= 0.8799, Minibatch error= 12.0%\n",
      "2017-09-03 12:31:57,276 Iter 2950, Minibatch Loss= 0.3799, Training Accuracy= 0.8469, Minibatch error= 15.3%\n",
      "2017-09-03 12:32:19,071 Epoch 29, Average loss: 0.2546, learning rate: 0.0010\n",
      "2017-09-03 12:32:19,142 Verification error= 17.5%, loss= 0.4224\n",
      "2017-09-03 12:32:21,803 Iter 3000, Minibatch Loss= 0.4187, Training Accuracy= 0.8378, Minibatch error= 16.2%\n",
      "2017-09-03 12:32:44,435 Iter 3050, Minibatch Loss= 0.3916, Training Accuracy= 0.8477, Minibatch error= 15.2%\n",
      "2017-09-03 12:33:06,640 Epoch 30, Average loss: 0.2507, learning rate: 0.0010\n",
      "2017-09-03 12:33:06,712 Verification error= 17.9%, loss= 0.4455\n",
      "2017-09-03 12:33:09,412 Iter 3100, Minibatch Loss= 0.3872, Training Accuracy= 0.8630, Minibatch error= 13.7%\n",
      "2017-09-03 12:33:32,445 Iter 3150, Minibatch Loss= 0.4997, Training Accuracy= 0.8044, Minibatch error= 19.6%\n",
      "2017-09-03 12:33:55,012 Epoch 31, Average loss: 0.2500, learning rate: 0.0010\n",
      "2017-09-03 12:33:55,084 Verification error= 17.6%, loss= 0.4208\n",
      "2017-09-03 12:33:57,818 Iter 3200, Minibatch Loss= 0.4464, Training Accuracy= 0.8185, Minibatch error= 18.2%\n",
      "2017-09-03 12:34:21,223 Iter 3250, Minibatch Loss= 0.4381, Training Accuracy= 0.8229, Minibatch error= 17.7%\n",
      "2017-09-03 12:34:44,177 Epoch 32, Average loss: 0.2445, learning rate: 0.0010\n",
      "2017-09-03 12:34:44,249 Verification error= 18.9%, loss= 0.4810\n",
      "2017-09-03 12:34:47,201 Iter 3300, Minibatch Loss= 0.5677, Training Accuracy= 0.7633, Minibatch error= 23.7%\n",
      "2017-09-03 12:35:11,051 Iter 3350, Minibatch Loss= 0.4463, Training Accuracy= 0.8372, Minibatch error= 16.3%\n",
      "2017-09-03 12:35:34,437 Epoch 33, Average loss: 0.2453, learning rate: 0.0010\n",
      "2017-09-03 12:35:34,509 Verification error= 18.1%, loss= 0.4689\n",
      "2017-09-03 12:35:37,348 Iter 3400, Minibatch Loss= 0.4604, Training Accuracy= 0.8078, Minibatch error= 19.2%\n",
      "2017-09-03 12:36:01,622 Iter 3450, Minibatch Loss= 0.4073, Training Accuracy= 0.8451, Minibatch error= 15.5%\n",
      "2017-09-03 12:36:25,426 Epoch 34, Average loss: 0.2419, learning rate: 0.0010\n",
      "2017-09-03 12:36:25,497 Verification error= 17.2%, loss= 0.4137\n",
      "2017-09-03 12:36:28,359 Iter 3500, Minibatch Loss= 0.5160, Training Accuracy= 0.7846, Minibatch error= 21.5%\n",
      "2017-09-03 12:36:53,098 Iter 3550, Minibatch Loss= 0.3193, Training Accuracy= 0.8703, Minibatch error= 13.0%\n",
      "2017-09-03 12:37:17,398 Epoch 35, Average loss: 0.2427, learning rate: 0.0010\n",
      "2017-09-03 12:37:17,472 Verification error= 17.4%, loss= 0.4383\n",
      "2017-09-03 12:37:20,423 Iter 3600, Minibatch Loss= 0.4031, Training Accuracy= 0.8466, Minibatch error= 15.3%\n",
      "2017-09-03 12:37:45,502 Iter 3650, Minibatch Loss= 0.4574, Training Accuracy= 0.8174, Minibatch error= 18.3%\n",
      "2017-09-03 12:38:10,143 Epoch 36, Average loss: 0.2396, learning rate: 0.0010\n",
      "2017-09-03 12:38:10,215 Verification error= 19.7%, loss= 0.4824\n",
      "2017-09-03 12:38:13,170 Iter 3700, Minibatch Loss= 0.4401, Training Accuracy= 0.8174, Minibatch error= 18.3%\n",
      "2017-09-03 12:38:38,709 Iter 3750, Minibatch Loss= 0.4168, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 12:39:03,740 Epoch 37, Average loss: 0.2375, learning rate: 0.0010\n",
      "2017-09-03 12:39:03,812 Verification error= 17.6%, loss= 0.4425\n",
      "2017-09-03 12:39:06,839 Iter 3800, Minibatch Loss= 0.5231, Training Accuracy= 0.8052, Minibatch error= 19.5%\n",
      "2017-09-03 12:39:32,898 Iter 3850, Minibatch Loss= 0.4894, Training Accuracy= 0.8234, Minibatch error= 17.7%\n",
      "2017-09-03 12:39:58,468 Epoch 38, Average loss: 0.2365, learning rate: 0.0010\n",
      "2017-09-03 12:39:58,539 Verification error= 18.0%, loss= 0.4732\n",
      "2017-09-03 12:40:01,798 Iter 3900, Minibatch Loss= 0.4795, Training Accuracy= 0.8193, Minibatch error= 18.1%\n",
      "2017-09-03 12:40:28,332 Iter 3950, Minibatch Loss= 0.5956, Training Accuracy= 0.7586, Minibatch error= 24.1%\n",
      "2017-09-03 12:40:54,370 Epoch 39, Average loss: 0.2352, learning rate: 0.0010\n",
      "2017-09-03 12:40:54,441 Verification error= 21.0%, loss= 0.5195\n",
      "2017-09-03 12:40:57,559 Iter 4000, Minibatch Loss= 0.4760, Training Accuracy= 0.8208, Minibatch error= 17.9%\n",
      "2017-09-03 12:41:24,585 Iter 4050, Minibatch Loss= 0.5001, Training Accuracy= 0.7857, Minibatch error= 21.4%\n",
      "2017-09-03 12:41:50,997 Epoch 40, Average loss: 0.2324, learning rate: 0.0010\n",
      "2017-09-03 12:41:51,069 Verification error= 19.2%, loss= 0.4667\n",
      "2017-09-03 12:41:54,238 Iter 4100, Minibatch Loss= 0.4289, Training Accuracy= 0.8271, Minibatch error= 17.3%\n",
      "2017-09-03 12:42:21,552 Iter 4150, Minibatch Loss= 0.5388, Training Accuracy= 0.7789, Minibatch error= 22.1%\n",
      "2017-09-03 12:42:48,375 Epoch 41, Average loss: 0.2313, learning rate: 0.0010\n",
      "2017-09-03 12:42:48,447 Verification error= 17.8%, loss= 0.4394\n",
      "2017-09-03 12:42:51,668 Iter 4200, Minibatch Loss= 0.3415, Training Accuracy= 0.8659, Minibatch error= 13.4%\n",
      "2017-09-03 12:43:19,477 Iter 4250, Minibatch Loss= 0.4250, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-09-03 12:43:46,687 Epoch 42, Average loss: 0.2341, learning rate: 0.0010\n",
      "2017-09-03 12:43:46,759 Verification error= 18.6%, loss= 0.4694\n",
      "2017-09-03 12:43:50,023 Iter 4300, Minibatch Loss= 0.4609, Training Accuracy= 0.8208, Minibatch error= 17.9%\n",
      "2017-09-03 12:44:18,268 Iter 4350, Minibatch Loss= 0.4479, Training Accuracy= 0.8109, Minibatch error= 18.9%\n",
      "2017-09-03 12:44:45,923 Epoch 43, Average loss: 0.2301, learning rate: 0.0010\n",
      "2017-09-03 12:44:45,995 Verification error= 19.6%, loss= 0.4747\n",
      "2017-09-03 12:44:49,312 Iter 4400, Minibatch Loss= 0.4018, Training Accuracy= 0.8466, Minibatch error= 15.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 12:45:18,042 Iter 4450, Minibatch Loss= 0.5580, Training Accuracy= 0.8029, Minibatch error= 19.7%\n",
      "2017-09-03 12:45:46,079 Epoch 44, Average loss: 0.2292, learning rate: 0.0010\n",
      "2017-09-03 12:45:46,151 Verification error= 17.3%, loss= 0.4497\n",
      "2017-09-03 12:45:49,718 Iter 4500, Minibatch Loss= 0.4994, Training Accuracy= 0.8232, Minibatch error= 17.7%\n",
      "2017-09-03 12:46:18,816 Iter 4550, Minibatch Loss= 0.4779, Training Accuracy= 0.8263, Minibatch error= 17.4%\n",
      "2017-09-03 12:46:47,330 Epoch 45, Average loss: 0.2276, learning rate: 0.0010\n",
      "2017-09-03 12:46:47,403 Verification error= 17.5%, loss= 0.4943\n",
      "2017-09-03 12:46:50,824 Iter 4600, Minibatch Loss= 0.6313, Training Accuracy= 0.7703, Minibatch error= 23.0%\n",
      "2017-09-03 12:47:20,367 Iter 4650, Minibatch Loss= 0.4436, Training Accuracy= 0.8563, Minibatch error= 14.4%\n",
      "2017-09-03 12:47:49,277 Epoch 46, Average loss: 0.2273, learning rate: 0.0010\n",
      "2017-09-03 12:47:49,349 Verification error= 17.3%, loss= 0.4931\n",
      "2017-09-03 12:47:52,805 Iter 4700, Minibatch Loss= 0.4836, Training Accuracy= 0.8208, Minibatch error= 17.9%\n",
      "2017-09-03 12:48:22,811 Iter 4750, Minibatch Loss= 0.3849, Training Accuracy= 0.8714, Minibatch error= 12.9%\n",
      "2017-09-03 12:48:52,140 Epoch 47, Average loss: 0.2255, learning rate: 0.0010\n",
      "2017-09-03 12:48:52,212 Verification error= 17.0%, loss= 0.4594\n",
      "2017-09-03 12:48:55,721 Iter 4800, Minibatch Loss= 0.5779, Training Accuracy= 0.7820, Minibatch error= 21.8%\n",
      "2017-09-03 12:49:26,057 Iter 4850, Minibatch Loss= 0.3169, Training Accuracy= 0.8922, Minibatch error= 10.8%\n",
      "2017-09-03 12:49:55,890 Epoch 48, Average loss: 0.2249, learning rate: 0.0010\n",
      "2017-09-03 12:49:55,962 Verification error= 17.0%, loss= 0.4761\n",
      "2017-09-03 12:49:59,504 Iter 4900, Minibatch Loss= 0.4491, Training Accuracy= 0.8482, Minibatch error= 15.2%\n",
      "2017-09-03 12:50:30,409 Iter 4950, Minibatch Loss= 0.4382, Training Accuracy= 0.8490, Minibatch error= 15.1%\n",
      "2017-09-03 12:51:00,567 Epoch 49, Average loss: 0.2251, learning rate: 0.0010\n",
      "2017-09-03 12:51:00,638 Verification error= 17.1%, loss= 0.4709\n",
      "2017-09-03 12:51:04,250 Iter 5000, Minibatch Loss= 0.4090, Training Accuracy= 0.8555, Minibatch error= 14.5%\n",
      "2017-09-03 12:51:35,409 Iter 5050, Minibatch Loss= 0.3738, Training Accuracy= 0.8643, Minibatch error= 13.6%\n",
      "2017-09-03 12:52:05,896 Epoch 50, Average loss: 0.2237, learning rate: 0.0010\n",
      "2017-09-03 12:52:05,968 Verification error= 17.1%, loss= 0.4762\n",
      "2017-09-03 12:52:09,581 Iter 5100, Minibatch Loss= 0.5777, Training Accuracy= 0.8055, Minibatch error= 19.5%\n",
      "2017-09-03 12:52:41,142 Iter 5150, Minibatch Loss= 0.5317, Training Accuracy= 0.8247, Minibatch error= 17.5%\n",
      "2017-09-03 12:53:11,998 Epoch 51, Average loss: 0.2210, learning rate: 0.0010\n",
      "2017-09-03 12:53:12,069 Verification error= 17.1%, loss= 0.4839\n",
      "2017-09-03 12:53:15,993 Iter 5200, Minibatch Loss= 0.4959, Training Accuracy= 0.8320, Minibatch error= 16.8%\n",
      "2017-09-03 12:53:47,759 Iter 5250, Minibatch Loss= 0.6336, Training Accuracy= 0.7706, Minibatch error= 22.9%\n",
      "2017-09-03 12:54:18,984 Epoch 52, Average loss: 0.2214, learning rate: 0.0010\n",
      "2017-09-03 12:54:19,055 Verification error= 17.4%, loss= 0.4884\n",
      "2017-09-03 12:54:22,765 Iter 5300, Minibatch Loss= 0.4265, Training Accuracy= 0.8570, Minibatch error= 14.3%\n",
      "2017-09-03 12:54:55,052 Iter 5350, Minibatch Loss= 0.4810, Training Accuracy= 0.8234, Minibatch error= 17.7%\n",
      "2017-09-03 12:55:26,678 Epoch 53, Average loss: 0.2215, learning rate: 0.0010\n",
      "2017-09-03 12:55:26,751 Verification error= 17.5%, loss= 0.4852\n",
      "2017-09-03 12:55:30,490 Iter 5400, Minibatch Loss= 0.4082, Training Accuracy= 0.8589, Minibatch error= 14.1%\n",
      "2017-09-03 12:56:03,120 Iter 5450, Minibatch Loss= 0.5878, Training Accuracy= 0.7891, Minibatch error= 21.1%\n",
      "2017-09-03 12:56:35,103 Epoch 54, Average loss: 0.2198, learning rate: 0.0010\n",
      "2017-09-03 12:56:35,175 Verification error= 16.6%, loss= 0.4674\n",
      "2017-09-03 12:56:38,969 Iter 5500, Minibatch Loss= 0.3264, Training Accuracy= 0.8888, Minibatch error= 11.1%\n",
      "2017-09-03 12:57:12,045 Iter 5550, Minibatch Loss= 0.4446, Training Accuracy= 0.8523, Minibatch error= 14.8%\n",
      "2017-09-03 12:57:44,505 Epoch 55, Average loss: 0.2200, learning rate: 0.0010\n",
      "2017-09-03 12:57:44,577 Verification error= 16.9%, loss= 0.4797\n",
      "2017-09-03 12:57:48,416 Iter 5600, Minibatch Loss= 0.4446, Training Accuracy= 0.8471, Minibatch error= 15.3%\n",
      "2017-09-03 12:58:21,884 Iter 5650, Minibatch Loss= 0.4184, Training Accuracy= 0.8583, Minibatch error= 14.2%\n",
      "2017-09-03 12:58:54,767 Epoch 56, Average loss: 0.2201, learning rate: 0.0010\n",
      "2017-09-03 12:58:54,839 Verification error= 16.8%, loss= 0.4759\n",
      "2017-09-03 12:58:58,752 Iter 5700, Minibatch Loss= 0.3750, Training Accuracy= 0.8750, Minibatch error= 12.5%\n",
      "2017-09-03 12:59:32,791 Iter 5750, Minibatch Loss= 0.5744, Training Accuracy= 0.8128, Minibatch error= 18.7%\n",
      "2017-09-03 13:00:06,132 Epoch 57, Average loss: 0.2178, learning rate: 0.0010\n",
      "2017-09-03 13:00:06,204 Verification error= 16.9%, loss= 0.4711\n",
      "2017-09-03 13:00:10,128 Iter 5800, Minibatch Loss= 0.5273, Training Accuracy= 0.8294, Minibatch error= 17.1%\n",
      "2017-09-03 13:00:44,553 Iter 5850, Minibatch Loss= 0.4920, Training Accuracy= 0.8240, Minibatch error= 17.6%\n",
      "2017-09-03 13:01:18,364 Epoch 58, Average loss: 0.2154, learning rate: 0.0010\n",
      "2017-09-03 13:01:18,436 Verification error= 18.0%, loss= 0.4987\n",
      "2017-09-03 13:01:22,710 Iter 5900, Minibatch Loss= 0.6366, Training Accuracy= 0.7732, Minibatch error= 22.7%\n",
      "2017-09-03 13:01:57,571 Iter 5950, Minibatch Loss= 0.4504, Training Accuracy= 0.8484, Minibatch error= 15.2%\n",
      "2017-09-03 13:02:31,795 Epoch 59, Average loss: 0.2165, learning rate: 0.0010\n",
      "2017-09-03 13:02:31,867 Verification error= 17.1%, loss= 0.4918\n",
      "2017-09-03 13:02:35,925 Iter 6000, Minibatch Loss= 0.4848, Training Accuracy= 0.8172, Minibatch error= 18.3%\n",
      "2017-09-03 13:03:11,303 Iter 6050, Minibatch Loss= 0.4091, Training Accuracy= 0.8596, Minibatch error= 14.0%\n",
      "2017-09-03 13:03:45,964 Epoch 60, Average loss: 0.2148, learning rate: 0.0010\n",
      "2017-09-03 13:03:46,036 Verification error= 16.6%, loss= 0.4723\n",
      "2017-09-03 13:03:50,112 Iter 6100, Minibatch Loss= 0.5996, Training Accuracy= 0.7906, Minibatch error= 20.9%\n",
      "2017-09-03 13:04:25,906 Iter 6150, Minibatch Loss= 0.3325, Training Accuracy= 0.8883, Minibatch error= 11.2%\n",
      "2017-09-03 13:05:00,946 Epoch 61, Average loss: 0.2168, learning rate: 0.0010\n",
      "2017-09-03 13:05:01,018 Verification error= 16.9%, loss= 0.4879\n",
      "2017-09-03 13:05:05,152 Iter 6200, Minibatch Loss= 0.4518, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 13:05:41,334 Iter 6250, Minibatch Loss= 0.4468, Training Accuracy= 0.8490, Minibatch error= 15.1%\n",
      "2017-09-03 13:06:16,784 Epoch 62, Average loss: 0.2161, learning rate: 0.0010\n",
      "2017-09-03 13:06:16,856 Verification error= 17.2%, loss= 0.4921\n",
      "2017-09-03 13:06:21,034 Iter 6300, Minibatch Loss= 0.4342, Training Accuracy= 0.8529, Minibatch error= 14.7%\n",
      "2017-09-03 13:06:57,658 Iter 6350, Minibatch Loss= 0.3701, Training Accuracy= 0.8776, Minibatch error= 12.2%\n",
      "2017-09-03 13:07:33,577 Epoch 63, Average loss: 0.2138, learning rate: 0.0010\n",
      "2017-09-03 13:07:33,649 Verification error= 17.2%, loss= 0.4873\n",
      "2017-09-03 13:07:37,938 Iter 6400, Minibatch Loss= 0.5771, Training Accuracy= 0.8130, Minibatch error= 18.7%\n",
      "2017-09-03 13:08:14,957 Iter 6450, Minibatch Loss= 0.5558, Training Accuracy= 0.8273, Minibatch error= 17.3%\n",
      "2017-09-03 13:08:51,317 Epoch 64, Average loss: 0.2152, learning rate: 0.0010\n",
      "2017-09-03 13:08:51,389 Verification error= 17.2%, loss= 0.5065\n",
      "2017-09-03 13:08:55,671 Iter 6500, Minibatch Loss= 0.5152, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-09-03 13:09:33,125 Iter 6550, Minibatch Loss= 0.6524, Training Accuracy= 0.7750, Minibatch error= 22.5%\n",
      "2017-09-03 13:10:09,901 Epoch 65, Average loss: 0.2147, learning rate: 0.0010\n",
      "2017-09-03 13:10:09,973 Verification error= 16.8%, loss= 0.5048\n",
      "2017-09-03 13:10:14,582 Iter 6600, Minibatch Loss= 0.4205, Training Accuracy= 0.8651, Minibatch error= 13.5%\n",
      "2017-09-03 13:10:52,452 Iter 6650, Minibatch Loss= 0.5373, Training Accuracy= 0.8214, Minibatch error= 17.9%\n",
      "2017-09-03 13:11:29,656 Epoch 66, Average loss: 0.2108, learning rate: 0.0010\n",
      "2017-09-03 13:11:29,729 Verification error= 16.8%, loss= 0.5912\n",
      "2017-09-03 13:11:34,075 Iter 6700, Minibatch Loss= 0.4598, Training Accuracy= 0.8695, Minibatch error= 13.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 13:12:12,375 Iter 6750, Minibatch Loss= 0.7870, Training Accuracy= 0.7797, Minibatch error= 22.0%\n",
      "2017-09-03 13:12:49,919 Epoch 67, Average loss: 0.2140, learning rate: 0.0010\n",
      "2017-09-03 13:12:49,990 Verification error= 16.9%, loss= 0.5699\n",
      "2017-09-03 13:12:54,389 Iter 6800, Minibatch Loss= 0.3514, Training Accuracy= 0.8909, Minibatch error= 10.9%\n",
      "2017-09-03 13:13:33,136 Iter 6850, Minibatch Loss= 0.4899, Training Accuracy= 0.8500, Minibatch error= 15.0%\n",
      "2017-09-03 13:14:11,135 Epoch 68, Average loss: 0.2139, learning rate: 0.0010\n",
      "2017-09-03 13:14:11,207 Verification error= 16.7%, loss= 0.5327\n",
      "2017-09-03 13:14:15,669 Iter 6900, Minibatch Loss= 0.4803, Training Accuracy= 0.8521, Minibatch error= 14.8%\n",
      "2017-09-03 13:14:54,917 Iter 6950, Minibatch Loss= 0.4366, Training Accuracy= 0.8562, Minibatch error= 14.4%\n",
      "2017-09-03 13:15:33,425 Epoch 69, Average loss: 0.2119, learning rate: 0.0010\n",
      "2017-09-03 13:15:33,497 Verification error= 16.7%, loss= 0.5165\n",
      "2017-09-03 13:15:37,999 Iter 7000, Minibatch Loss= 0.3896, Training Accuracy= 0.8758, Minibatch error= 12.4%\n",
      "2017-09-03 13:16:17,594 Iter 7050, Minibatch Loss= 0.5712, Training Accuracy= 0.8133, Minibatch error= 18.7%\n",
      "2017-09-03 13:16:56,419 Epoch 70, Average loss: 0.2108, learning rate: 0.0010\n",
      "2017-09-03 13:16:56,491 Verification error= 16.6%, loss= 0.5166\n",
      "2017-09-03 13:17:01,123 Iter 7100, Minibatch Loss= 0.5323, Training Accuracy= 0.8323, Minibatch error= 16.8%\n",
      "2017-09-03 13:17:41,166 Iter 7150, Minibatch Loss= 0.5257, Training Accuracy= 0.8310, Minibatch error= 16.9%\n",
      "2017-09-03 13:18:20,340 Epoch 71, Average loss: 0.2093, learning rate: 0.0010\n",
      "2017-09-03 13:18:20,412 Verification error= 17.0%, loss= 0.5189\n",
      "2017-09-03 13:18:25,004 Iter 7200, Minibatch Loss= 0.6813, Training Accuracy= 0.7784, Minibatch error= 22.2%\n",
      "2017-09-03 13:19:05,484 Iter 7250, Minibatch Loss= 0.4140, Training Accuracy= 0.8602, Minibatch error= 14.0%\n",
      "2017-09-03 13:19:45,166 Epoch 72, Average loss: 0.2093, learning rate: 0.0010\n",
      "2017-09-03 13:19:45,238 Verification error= 17.0%, loss= 0.4918\n",
      "2017-09-03 13:19:49,895 Iter 7300, Minibatch Loss= 0.5152, Training Accuracy= 0.8185, Minibatch error= 18.2%\n",
      "2017-09-03 13:20:30,830 Iter 7350, Minibatch Loss= 0.3947, Training Accuracy= 0.8622, Minibatch error= 13.8%\n",
      "2017-09-03 13:21:11,036 Epoch 73, Average loss: 0.2078, learning rate: 0.0010\n",
      "2017-09-03 13:21:11,108 Verification error= 16.6%, loss= 0.4792\n",
      "2017-09-03 13:21:16,164 Iter 7400, Minibatch Loss= 0.6215, Training Accuracy= 0.7927, Minibatch error= 20.7%\n",
      "2017-09-03 13:21:57,557 Iter 7450, Minibatch Loss= 0.3143, Training Accuracy= 0.8906, Minibatch error= 10.9%\n",
      "2017-09-03 13:22:38,398 Epoch 74, Average loss: 0.2099, learning rate: 0.0010\n",
      "2017-09-03 13:22:38,470 Verification error= 16.5%, loss= 0.4903\n",
      "2017-09-03 13:22:43,190 Iter 7500, Minibatch Loss= 0.4230, Training Accuracy= 0.8534, Minibatch error= 14.7%\n",
      "2017-09-03 13:23:25,027 Iter 7550, Minibatch Loss= 0.4409, Training Accuracy= 0.8549, Minibatch error= 14.5%\n",
      "2017-09-03 13:24:05,978 Epoch 75, Average loss: 0.2091, learning rate: 0.0010\n",
      "2017-09-03 13:24:06,050 Verification error= 16.6%, loss= 0.4867\n",
      "2017-09-03 13:24:10,824 Iter 7600, Minibatch Loss= 0.4054, Training Accuracy= 0.8570, Minibatch error= 14.3%\n",
      "2017-09-03 13:24:52,988 Iter 7650, Minibatch Loss= 0.3635, Training Accuracy= 0.8766, Minibatch error= 12.3%\n",
      "2017-09-03 13:25:34,377 Epoch 76, Average loss: 0.2086, learning rate: 0.0010\n",
      "2017-09-03 13:25:34,450 Verification error= 16.6%, loss= 0.4933\n",
      "2017-09-03 13:25:39,295 Iter 7700, Minibatch Loss= 0.5429, Training Accuracy= 0.8143, Minibatch error= 18.6%\n",
      "2017-09-03 13:26:22,007 Iter 7750, Minibatch Loss= 0.4783, Training Accuracy= 0.8315, Minibatch error= 16.8%\n",
      "2017-09-03 13:27:03,725 Epoch 77, Average loss: 0.2077, learning rate: 0.0010\n",
      "2017-09-03 13:27:03,797 Verification error= 16.8%, loss= 0.4209\n",
      "2017-09-03 13:27:08,706 Iter 7800, Minibatch Loss= 0.4339, Training Accuracy= 0.8315, Minibatch error= 16.8%\n",
      "2017-09-03 13:27:52,347 Iter 7850, Minibatch Loss= 0.4978, Training Accuracy= 0.7714, Minibatch error= 22.9%\n",
      "2017-09-03 13:28:34,900 Epoch 78, Average loss: 0.2058, learning rate: 0.0010\n",
      "2017-09-03 13:28:34,972 Verification error= 17.5%, loss= 0.3909\n",
      "2017-09-03 13:28:39,822 Iter 7900, Minibatch Loss= 0.3258, Training Accuracy= 0.8557, Minibatch error= 14.4%\n",
      "2017-09-03 13:29:23,374 Iter 7950, Minibatch Loss= 0.4118, Training Accuracy= 0.8099, Minibatch error= 19.0%\n",
      "2017-09-03 13:30:06,063 Epoch 79, Average loss: 0.2081, learning rate: 0.0010\n",
      "2017-09-03 13:30:06,136 Verification error= 16.6%, loss= 0.3708\n",
      "2017-09-03 13:30:11,125 Iter 8000, Minibatch Loss= 0.3343, Training Accuracy= 0.8521, Minibatch error= 14.8%\n",
      "2017-09-03 13:30:55,034 Iter 8050, Minibatch Loss= 0.4782, Training Accuracy= 0.7945, Minibatch error= 20.5%\n",
      "2017-09-03 13:31:38,103 Epoch 80, Average loss: 0.2070, learning rate: 0.0010\n",
      "2017-09-03 13:31:38,175 Verification error= 16.1%, loss= 0.3647\n",
      "2017-09-03 13:31:43,183 Iter 8100, Minibatch Loss= 0.2593, Training Accuracy= 0.8867, Minibatch error= 11.3%\n",
      "2017-09-03 13:32:27,667 Iter 8150, Minibatch Loss= 0.3083, Training Accuracy= 0.8583, Minibatch error= 14.2%\n",
      "2017-09-03 13:33:11,167 Epoch 81, Average loss: 0.2066, learning rate: 0.0010\n",
      "2017-09-03 13:33:11,239 Verification error= 16.2%, loss= 0.3606\n",
      "2017-09-03 13:33:16,660 Iter 8200, Minibatch Loss= 0.3443, Training Accuracy= 0.8495, Minibatch error= 15.1%\n",
      "2017-09-03 13:34:01,552 Iter 8250, Minibatch Loss= 0.3265, Training Accuracy= 0.8547, Minibatch error= 14.5%\n",
      "2017-09-03 13:34:45,621 Epoch 82, Average loss: 0.2066, learning rate: 0.0010\n",
      "2017-09-03 13:34:45,695 Verification error= 16.0%, loss= 0.3669\n",
      "2017-09-03 13:34:50,830 Iter 8300, Minibatch Loss= 0.2939, Training Accuracy= 0.8758, Minibatch error= 12.4%\n",
      "2017-09-03 13:35:36,275 Iter 8350, Minibatch Loss= 0.3855, Training Accuracy= 0.8188, Minibatch error= 18.1%\n",
      "2017-09-03 13:36:20,773 Epoch 83, Average loss: 0.2035, learning rate: 0.0010\n",
      "2017-09-03 13:36:20,845 Verification error= 16.7%, loss= 0.3581\n",
      "2017-09-03 13:36:26,001 Iter 8400, Minibatch Loss= 0.3319, Training Accuracy= 0.8315, Minibatch error= 16.8%\n",
      "2017-09-03 13:37:11,783 Iter 8450, Minibatch Loss= 0.3812, Training Accuracy= 0.8240, Minibatch error= 17.6%\n",
      "2017-09-03 13:37:56,802 Epoch 84, Average loss: 0.2040, learning rate: 0.0010\n",
      "2017-09-03 13:37:56,874 Verification error= 17.6%, loss= 0.3873\n",
      "2017-09-03 13:38:02,089 Iter 8500, Minibatch Loss= 0.4600, Training Accuracy= 0.7680, Minibatch error= 23.2%\n",
      "2017-09-03 13:38:48,240 Iter 8550, Minibatch Loss= 0.3353, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 13:39:33,594 Epoch 85, Average loss: 0.2033, learning rate: 0.0010\n",
      "2017-09-03 13:39:33,666 Verification error= 16.4%, loss= 0.3785\n",
      "2017-09-03 13:39:38,924 Iter 8600, Minibatch Loss= 0.3929, Training Accuracy= 0.8201, Minibatch error= 18.0%\n",
      "2017-09-03 13:40:25,604 Iter 8650, Minibatch Loss= 0.3206, Training Accuracy= 0.8581, Minibatch error= 14.2%\n",
      "2017-09-03 13:41:11,327 Epoch 86, Average loss: 0.2020, learning rate: 0.0010\n",
      "2017-09-03 13:41:11,399 Verification error= 16.0%, loss= 0.3541\n",
      "2017-09-03 13:41:16,710 Iter 8700, Minibatch Loss= 0.4669, Training Accuracy= 0.7948, Minibatch error= 20.5%\n",
      "2017-09-03 13:42:03,860 Iter 8750, Minibatch Loss= 0.2491, Training Accuracy= 0.8888, Minibatch error= 11.1%\n",
      "2017-09-03 13:42:50,010 Epoch 87, Average loss: 0.2041, learning rate: 0.0010\n",
      "2017-09-03 13:42:50,082 Verification error= 16.0%, loss= 0.3586\n",
      "2017-09-03 13:42:55,449 Iter 8800, Minibatch Loss= 0.3028, Training Accuracy= 0.8573, Minibatch error= 14.3%\n",
      "2017-09-03 13:43:42,909 Iter 8850, Minibatch Loss= 0.3499, Training Accuracy= 0.8495, Minibatch error= 15.1%\n",
      "2017-09-03 13:44:29,520 Epoch 88, Average loss: 0.2033, learning rate: 0.0010\n",
      "2017-09-03 13:44:29,592 Verification error= 16.4%, loss= 0.3609\n",
      "2017-09-03 13:44:35,053 Iter 8900, Minibatch Loss= 0.3099, Training Accuracy= 0.8555, Minibatch error= 14.5%\n",
      "2017-09-03 13:45:23,092 Iter 8950, Minibatch Loss= 0.2917, Training Accuracy= 0.8766, Minibatch error= 12.3%\n",
      "2017-09-03 13:46:10,266 Epoch 89, Average loss: 0.2037, learning rate: 0.0010\n",
      "2017-09-03 13:46:10,338 Verification error= 16.1%, loss= 0.3514\n",
      "2017-09-03 13:46:16,150 Iter 9000, Minibatch Loss= 0.3751, Training Accuracy= 0.8227, Minibatch error= 17.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 13:47:04,544 Iter 9050, Minibatch Loss= 0.3232, Training Accuracy= 0.8367, Minibatch error= 16.3%\n",
      "2017-09-03 13:47:52,100 Epoch 90, Average loss: 0.1993, learning rate: 0.0010\n",
      "2017-09-03 13:47:52,172 Verification error= 17.2%, loss= 0.3763\n",
      "2017-09-03 13:47:57,655 Iter 9100, Minibatch Loss= 0.3839, Training Accuracy= 0.8227, Minibatch error= 17.7%\n",
      "2017-09-03 13:48:46,428 Iter 9150, Minibatch Loss= 0.4546, Training Accuracy= 0.7711, Minibatch error= 22.9%\n",
      "2017-09-03 13:49:34,309 Epoch 91, Average loss: 0.2026, learning rate: 0.0010\n",
      "2017-09-03 13:49:34,381 Verification error= 17.4%, loss= 0.3875\n",
      "2017-09-03 13:49:39,942 Iter 9200, Minibatch Loss= 0.3224, Training Accuracy= 0.8599, Minibatch error= 14.0%\n",
      "2017-09-03 13:50:29,195 Iter 9250, Minibatch Loss= 0.3858, Training Accuracy= 0.8211, Minibatch error= 17.9%\n",
      "2017-09-03 13:51:17,524 Epoch 92, Average loss: 0.2018, learning rate: 0.0010\n",
      "2017-09-03 13:51:17,603 Verification error= 16.3%, loss= 0.3608\n",
      "2017-09-03 13:51:23,200 Iter 9300, Minibatch Loss= 0.3252, Training Accuracy= 0.8596, Minibatch error= 14.0%\n",
      "2017-09-03 13:52:13,101 Iter 9350, Minibatch Loss= 0.4565, Training Accuracy= 0.7956, Minibatch error= 20.4%\n",
      "2017-09-03 13:53:01,887 Epoch 93, Average loss: 0.1996, learning rate: 0.0010\n",
      "2017-09-03 13:53:01,964 Verification error= 15.9%, loss= 0.3540\n",
      "2017-09-03 13:53:07,579 Iter 9400, Minibatch Loss= 0.2535, Training Accuracy= 0.8867, Minibatch error= 11.3%\n",
      "2017-09-03 13:53:57,784 Iter 9450, Minibatch Loss= 0.2977, Training Accuracy= 0.8586, Minibatch error= 14.1%\n",
      "2017-09-03 13:54:47,016 Epoch 94, Average loss: 0.2005, learning rate: 0.0010\n",
      "2017-09-03 13:54:47,088 Verification error= 16.0%, loss= 0.3501\n",
      "2017-09-03 13:54:52,750 Iter 9500, Minibatch Loss= 0.3302, Training Accuracy= 0.8523, Minibatch error= 14.8%\n",
      "2017-09-03 13:55:43,440 Iter 9550, Minibatch Loss= 0.3072, Training Accuracy= 0.8570, Minibatch error= 14.3%\n",
      "2017-09-03 13:56:33,065 Epoch 95, Average loss: 0.2002, learning rate: 0.0010\n",
      "2017-09-03 13:56:33,137 Verification error= 15.8%, loss= 0.3544\n",
      "2017-09-03 13:56:38,836 Iter 9600, Minibatch Loss= 0.2767, Training Accuracy= 0.8789, Minibatch error= 12.1%\n",
      "2017-09-03 13:57:29,967 Iter 9650, Minibatch Loss= 0.3974, Training Accuracy= 0.8273, Minibatch error= 17.3%\n",
      "2017-09-03 13:58:19,968 Epoch 96, Average loss: 0.1991, learning rate: 0.0010\n",
      "2017-09-03 13:58:20,039 Verification error= 16.1%, loss= 0.3551\n",
      "2017-09-03 13:58:25,815 Iter 9700, Minibatch Loss= 0.3233, Training Accuracy= 0.8375, Minibatch error= 16.2%\n",
      "2017-09-03 13:59:17,178 Iter 9750, Minibatch Loss= 0.3637, Training Accuracy= 0.8320, Minibatch error= 16.8%\n",
      "2017-09-03 14:00:07,589 Epoch 97, Average loss: 0.1988, learning rate: 0.0010\n",
      "2017-09-03 14:00:07,661 Verification error= 16.4%, loss= 0.3827\n",
      "2017-09-03 14:00:13,847 Iter 9800, Minibatch Loss= 0.4517, Training Accuracy= 0.7792, Minibatch error= 22.1%\n",
      "2017-09-03 14:01:05,776 Iter 9850, Minibatch Loss= 0.3218, Training Accuracy= 0.8635, Minibatch error= 13.6%\n",
      "2017-09-03 14:01:56,832 Epoch 98, Average loss: 0.1983, learning rate: 0.0010\n",
      "2017-09-03 14:01:56,903 Verification error= 15.6%, loss= 0.3593\n",
      "2017-09-03 14:02:02,793 Iter 9900, Minibatch Loss= 0.3677, Training Accuracy= 0.8339, Minibatch error= 16.6%\n",
      "2017-09-03 14:02:55,085 Iter 9950, Minibatch Loss= 0.3145, Training Accuracy= 0.8596, Minibatch error= 14.0%\n",
      "2017-09-03 14:03:46,420 Epoch 99, Average loss: 0.1967, learning rate: 0.0010\n",
      "2017-09-03 14:03:46,492 Verification error= 15.8%, loss= 0.3457\n",
      "2017-09-03 14:03:52,399 Iter 10000, Minibatch Loss= 0.4558, Training Accuracy= 0.7974, Minibatch error= 20.3%\n",
      "2017-09-03 14:04:45,077 Iter 10050, Minibatch Loss= 0.2432, Training Accuracy= 0.8974, Minibatch error= 10.3%\n",
      "2017-09-03 14:05:36,738 Epoch 100, Average loss: 0.1981, learning rate: 0.0010\n",
      "2017-09-03 14:05:36,810 Verification error= 15.7%, loss= 0.3467\n",
      "2017-09-03 14:05:42,789 Iter 10100, Minibatch Loss= 0.2921, Training Accuracy= 0.8602, Minibatch error= 14.0%\n",
      "2017-09-03 14:06:36,010 Iter 10150, Minibatch Loss= 0.3305, Training Accuracy= 0.8531, Minibatch error= 14.7%\n",
      "2017-09-03 14:07:28,122 Epoch 101, Average loss: 0.1967, learning rate: 0.0010\n",
      "2017-09-03 14:07:28,194 Verification error= 15.7%, loss= 0.3469\n",
      "2017-09-03 14:07:34,236 Iter 10200, Minibatch Loss= 0.2846, Training Accuracy= 0.8638, Minibatch error= 13.6%\n",
      "2017-09-03 14:08:27,867 Iter 10250, Minibatch Loss= 0.2733, Training Accuracy= 0.8820, Minibatch error= 11.8%\n",
      "2017-09-03 14:09:20,480 Epoch 102, Average loss: 0.1965, learning rate: 0.0010\n",
      "2017-09-03 14:09:20,552 Verification error= 15.9%, loss= 0.3466\n",
      "2017-09-03 14:09:26,638 Iter 10300, Minibatch Loss= 0.3734, Training Accuracy= 0.8227, Minibatch error= 17.7%\n",
      "2017-09-03 14:10:20,792 Iter 10350, Minibatch Loss= 0.3184, Training Accuracy= 0.8359, Minibatch error= 16.4%\n",
      "2017-09-03 14:11:13,904 Epoch 103, Average loss: 0.1960, learning rate: 0.0010\n",
      "2017-09-03 14:11:13,977 Verification error= 15.9%, loss= 0.3514\n",
      "2017-09-03 14:11:20,100 Iter 10400, Minibatch Loss= 0.3575, Training Accuracy= 0.8349, Minibatch error= 16.5%\n",
      "2017-09-03 14:12:14,774 Iter 10450, Minibatch Loss= 0.4384, Training Accuracy= 0.7768, Minibatch error= 22.3%\n",
      "2017-09-03 14:13:08,366 Epoch 104, Average loss: 0.1994, learning rate: 0.0010\n",
      "2017-09-03 14:13:08,437 Verification error= 16.1%, loss= 0.3689\n",
      "2017-09-03 14:13:14,620 Iter 10500, Minibatch Loss= 0.3024, Training Accuracy= 0.8721, Minibatch error= 12.8%\n",
      "2017-09-03 14:14:09,793 Iter 10550, Minibatch Loss= 0.3722, Training Accuracy= 0.8299, Minibatch error= 17.0%\n",
      "2017-09-03 14:15:03,902 Epoch 105, Average loss: 0.1957, learning rate: 0.0010\n",
      "2017-09-03 14:15:03,975 Verification error= 13.2%, loss= 0.3492\n",
      "2017-09-03 14:15:10,170 Iter 10600, Minibatch Loss= 0.3110, Training Accuracy= 0.8693, Minibatch error= 13.1%\n",
      "2017-09-03 14:16:05,793 Iter 10650, Minibatch Loss= 0.4683, Training Accuracy= 0.8185, Minibatch error= 18.2%\n",
      "2017-09-03 14:17:00,346 Epoch 106, Average loss: 0.1974, learning rate: 0.0010\n",
      "2017-09-03 14:17:00,421 Verification error= 13.1%, loss= 0.3367\n",
      "2017-09-03 14:17:07,087 Iter 10700, Minibatch Loss= 0.2432, Training Accuracy= 0.8958, Minibatch error= 10.4%\n",
      "2017-09-03 14:18:03,176 Iter 10750, Minibatch Loss= 0.2869, Training Accuracy= 0.9042, Minibatch error= 9.6%\n",
      "2017-09-03 14:18:58,037 Epoch 107, Average loss: 0.1975, learning rate: 0.0010\n",
      "2017-09-03 14:18:58,109 Verification error= 12.2%, loss= 0.3424\n",
      "2017-09-03 14:19:04,458 Iter 10800, Minibatch Loss= 0.3278, Training Accuracy= 0.8865, Minibatch error= 11.4%\n",
      "2017-09-03 14:20:00,921 Iter 10850, Minibatch Loss= 0.2954, Training Accuracy= 0.8854, Minibatch error= 11.5%\n",
      "2017-09-03 14:20:56,209 Epoch 108, Average loss: 0.1961, learning rate: 0.0010\n",
      "2017-09-03 14:20:56,281 Verification error= 12.1%, loss= 0.3384\n",
      "2017-09-03 14:21:02,680 Iter 10900, Minibatch Loss= 0.2697, Training Accuracy= 0.9117, Minibatch error= 8.8%\n",
      "2017-09-03 14:21:59,221 Iter 10950, Minibatch Loss= 0.3666, Training Accuracy= 0.8745, Minibatch error= 12.6%\n",
      "2017-09-03 14:22:54,672 Epoch 109, Average loss: 0.1972, learning rate: 0.0010\n",
      "2017-09-03 14:22:54,744 Verification error= 12.4%, loss= 0.3347\n",
      "2017-09-03 14:23:01,119 Iter 11000, Minibatch Loss= 0.3023, Training Accuracy= 0.8672, Minibatch error= 13.3%\n",
      "2017-09-03 14:23:58,052 Iter 11050, Minibatch Loss= 0.3639, Training Accuracy= 0.8677, Minibatch error= 13.2%\n",
      "2017-09-03 14:24:53,871 Epoch 110, Average loss: 0.1959, learning rate: 0.0010\n",
      "2017-09-03 14:24:53,943 Verification error= 13.1%, loss= 0.3760\n",
      "2017-09-03 14:25:00,377 Iter 11100, Minibatch Loss= 0.4407, Training Accuracy= 0.8201, Minibatch error= 18.0%\n",
      "2017-09-03 14:25:57,705 Iter 11150, Minibatch Loss= 0.3074, Training Accuracy= 0.8997, Minibatch error= 10.0%\n",
      "2017-09-03 14:26:53,872 Epoch 111, Average loss: 0.1941, learning rate: 0.0010\n",
      "2017-09-03 14:26:53,944 Verification error= 13.5%, loss= 0.3693\n",
      "2017-09-03 14:27:00,482 Iter 11200, Minibatch Loss= 0.3648, Training Accuracy= 0.8560, Minibatch error= 14.4%\n",
      "2017-09-03 14:27:58,454 Iter 11250, Minibatch Loss= 0.3118, Training Accuracy= 0.8755, Minibatch error= 12.4%\n",
      "2017-09-03 14:28:55,405 Epoch 112, Average loss: 0.1938, learning rate: 0.0010\n",
      "2017-09-03 14:28:55,485 Verification error= 12.4%, loss= 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 14:29:02,073 Iter 11300, Minibatch Loss= 0.4524, Training Accuracy= 0.8260, Minibatch error= 17.4%\n",
      "2017-09-03 14:30:00,510 Iter 11350, Minibatch Loss= 0.2353, Training Accuracy= 0.9068, Minibatch error= 9.3%\n",
      "2017-09-03 14:30:57,714 Epoch 113, Average loss: 0.1946, learning rate: 0.0010\n",
      "2017-09-03 14:30:57,785 Verification error= 11.9%, loss= 0.3255\n",
      "2017-09-03 14:31:04,387 Iter 11400, Minibatch Loss= 0.2764, Training Accuracy= 0.9076, Minibatch error= 9.2%\n",
      "2017-09-03 14:32:03,139 Iter 11450, Minibatch Loss= 0.3256, Training Accuracy= 0.8766, Minibatch error= 12.3%\n",
      "2017-09-03 14:33:00,874 Epoch 114, Average loss: 0.1949, learning rate: 0.0010\n",
      "2017-09-03 14:33:00,947 Verification error= 11.8%, loss= 0.3311\n",
      "2017-09-03 14:33:07,971 Iter 11500, Minibatch Loss= 0.2754, Training Accuracy= 0.8904, Minibatch error= 11.0%\n",
      "2017-09-03 14:34:07,353 Iter 11550, Minibatch Loss= 0.2701, Training Accuracy= 0.9109, Minibatch error= 8.9%\n",
      "2017-09-03 14:35:05,503 Epoch 115, Average loss: 0.1907, learning rate: 0.0010\n",
      "2017-09-03 14:35:05,575 Verification error= 12.2%, loss= 0.3264\n",
      "2017-09-03 14:35:12,238 Iter 11600, Minibatch Loss= 0.3496, Training Accuracy= 0.8797, Minibatch error= 12.0%\n",
      "2017-09-03 14:36:12,016 Iter 11650, Minibatch Loss= 0.3086, Training Accuracy= 0.8591, Minibatch error= 14.1%\n",
      "2017-09-03 14:37:10,585 Epoch 116, Average loss: 0.1942, learning rate: 0.0010\n",
      "2017-09-03 14:37:10,656 Verification error= 13.5%, loss= 0.3571\n",
      "2017-09-03 14:37:17,389 Iter 11700, Minibatch Loss= 0.3741, Training Accuracy= 0.8471, Minibatch error= 15.3%\n",
      "2017-09-03 14:38:17,772 Iter 11750, Minibatch Loss= 0.4139, Training Accuracy= 0.8313, Minibatch error= 16.9%\n",
      "2017-09-03 14:39:16,758 Epoch 117, Average loss: 0.1940, learning rate: 0.0010\n",
      "2017-09-03 14:39:16,829 Verification error= 13.0%, loss= 0.3614\n",
      "2017-09-03 14:39:23,628 Iter 11800, Minibatch Loss= 0.2963, Training Accuracy= 0.9026, Minibatch error= 9.7%\n",
      "2017-09-03 14:40:24,480 Iter 11850, Minibatch Loss= 0.3356, Training Accuracy= 0.8630, Minibatch error= 13.7%\n",
      "2017-09-03 14:41:24,157 Epoch 118, Average loss: 0.1944, learning rate: 0.0010\n",
      "2017-09-03 14:41:24,231 Verification error= 12.4%, loss= 0.3286\n",
      "2017-09-03 14:41:31,078 Iter 11900, Minibatch Loss= 0.2875, Training Accuracy= 0.8789, Minibatch error= 12.1%\n",
      "2017-09-03 14:42:32,410 Iter 11950, Minibatch Loss= 0.4478, Training Accuracy= 0.8232, Minibatch error= 17.7%\n",
      "2017-09-03 14:43:32,613 Epoch 119, Average loss: 0.1917, learning rate: 0.0010\n",
      "2017-09-03 14:43:32,685 Verification error= 12.3%, loss= 0.3244\n",
      "2017-09-03 14:43:39,594 Iter 12000, Minibatch Loss= 0.2317, Training Accuracy= 0.9107, Minibatch error= 8.9%\n",
      "2017-09-03 14:44:41,393 Iter 12050, Minibatch Loss= 0.2763, Training Accuracy= 0.9060, Minibatch error= 9.4%\n",
      "2017-09-03 14:45:41,974 Epoch 120, Average loss: 0.1923, learning rate: 0.0010\n",
      "2017-09-03 14:45:42,045 Verification error= 12.7%, loss= 0.3282\n",
      "2017-09-03 14:45:48,965 Iter 12100, Minibatch Loss= 0.3231, Training Accuracy= 0.8771, Minibatch error= 12.3%\n",
      "2017-09-03 14:46:51,107 Iter 12150, Minibatch Loss= 0.2734, Training Accuracy= 0.8909, Minibatch error= 10.9%\n",
      "2017-09-03 14:47:52,175 Epoch 121, Average loss: 0.1930, learning rate: 0.0010\n",
      "2017-09-03 14:47:52,248 Verification error= 12.2%, loss= 0.3209\n",
      "2017-09-03 14:47:59,242 Iter 12200, Minibatch Loss= 0.2506, Training Accuracy= 0.9089, Minibatch error= 9.1%\n",
      "2017-09-03 14:49:01,790 Iter 12250, Minibatch Loss= 0.3341, Training Accuracy= 0.8771, Minibatch error= 12.3%\n",
      "2017-09-03 14:50:03,158 Epoch 122, Average loss: 0.1924, learning rate: 0.0010\n",
      "2017-09-03 14:50:03,230 Verification error= 13.1%, loss= 0.3200\n",
      "2017-09-03 14:50:10,286 Iter 12300, Minibatch Loss= 0.2969, Training Accuracy= 0.8602, Minibatch error= 14.0%\n",
      "2017-09-03 14:51:13,293 Iter 12350, Minibatch Loss= 0.3448, Training Accuracy= 0.8620, Minibatch error= 13.8%\n",
      "2017-09-03 14:52:15,112 Epoch 123, Average loss: 0.1935, learning rate: 0.0010\n",
      "2017-09-03 14:52:15,185 Verification error= 12.8%, loss= 0.3401\n",
      "2017-09-03 14:52:22,714 Iter 12400, Minibatch Loss= 0.4083, Training Accuracy= 0.8216, Minibatch error= 17.8%\n",
      "2017-09-03 14:53:26,207 Iter 12450, Minibatch Loss= 0.2900, Training Accuracy= 0.8971, Minibatch error= 10.3%\n",
      "2017-09-03 14:54:28,419 Epoch 124, Average loss: 0.1909, learning rate: 0.0010\n",
      "2017-09-03 14:54:28,490 Verification error= 13.4%, loss= 0.3541\n",
      "2017-09-03 14:54:35,607 Iter 12500, Minibatch Loss= 0.3424, Training Accuracy= 0.8552, Minibatch error= 14.5%\n",
      "2017-09-03 14:55:39,374 Iter 12550, Minibatch Loss= 0.2938, Training Accuracy= 0.8784, Minibatch error= 12.2%\n",
      "2017-09-03 14:56:41,946 Epoch 125, Average loss: 0.1902, learning rate: 0.0010\n",
      "2017-09-03 14:56:42,017 Verification error= 12.3%, loss= 0.3199\n",
      "2017-09-03 14:56:49,208 Iter 12600, Minibatch Loss= 0.4400, Training Accuracy= 0.8354, Minibatch error= 16.5%\n",
      "2017-09-03 14:57:53,446 Iter 12650, Minibatch Loss= 0.2356, Training Accuracy= 0.9094, Minibatch error= 9.1%\n",
      "2017-09-03 14:58:56,409 Epoch 126, Average loss: 0.1940, learning rate: 0.0010\n",
      "2017-09-03 14:58:56,481 Verification error= 12.2%, loss= 0.3171\n",
      "2017-09-03 14:59:03,704 Iter 12700, Minibatch Loss= 0.2693, Training Accuracy= 0.9044, Minibatch error= 9.6%\n",
      "2017-09-03 15:00:08,316 Iter 12750, Minibatch Loss= 0.3092, Training Accuracy= 0.8862, Minibatch error= 11.4%\n",
      "2017-09-03 15:01:11,646 Epoch 127, Average loss: 0.1920, learning rate: 0.0010\n",
      "2017-09-03 15:01:11,717 Verification error= 12.4%, loss= 0.3231\n",
      "2017-09-03 15:01:19,029 Iter 12800, Minibatch Loss= 0.2684, Training Accuracy= 0.8935, Minibatch error= 10.7%\n",
      "2017-09-03 15:02:24,071 Iter 12850, Minibatch Loss= 0.2645, Training Accuracy= 0.9083, Minibatch error= 9.2%\n",
      "2017-09-03 15:03:27,967 Epoch 128, Average loss: 0.1878, learning rate: 0.0010\n",
      "2017-09-03 15:03:28,039 Verification error= 12.3%, loss= 0.3233\n",
      "2017-09-03 15:03:35,328 Iter 12900, Minibatch Loss= 0.3410, Training Accuracy= 0.8815, Minibatch error= 11.8%\n",
      "2017-09-03 15:04:40,873 Iter 12950, Minibatch Loss= 0.2966, Training Accuracy= 0.8615, Minibatch error= 13.9%\n",
      "2017-09-03 15:05:45,023 Epoch 129, Average loss: 0.1899, learning rate: 0.0010\n",
      "2017-09-03 15:05:45,095 Verification error= 13.4%, loss= 0.3365\n",
      "2017-09-03 15:05:52,463 Iter 13000, Minibatch Loss= 0.3572, Training Accuracy= 0.8451, Minibatch error= 15.5%\n",
      "2017-09-03 15:06:58,445 Iter 13050, Minibatch Loss= 0.4259, Training Accuracy= 0.8104, Minibatch error= 19.0%\n",
      "2017-09-03 15:08:03,031 Epoch 130, Average loss: 0.1882, learning rate: 0.0010\n",
      "2017-09-03 15:08:03,103 Verification error= 12.8%, loss= 0.3446\n",
      "2017-09-03 15:08:10,526 Iter 13100, Minibatch Loss= 0.2799, Training Accuracy= 0.9042, Minibatch error= 9.6%\n",
      "2017-09-03 15:09:17,127 Iter 13150, Minibatch Loss= 0.3288, Training Accuracy= 0.8669, Minibatch error= 13.3%\n",
      "2017-09-03 15:10:22,192 Epoch 131, Average loss: 0.1896, learning rate: 0.0010\n",
      "2017-09-03 15:10:22,264 Verification error= 12.4%, loss= 0.3275\n",
      "2017-09-03 15:10:29,716 Iter 13200, Minibatch Loss= 0.2834, Training Accuracy= 0.8807, Minibatch error= 11.9%\n",
      "2017-09-03 15:11:36,592 Iter 13250, Minibatch Loss= 0.4416, Training Accuracy= 0.8232, Minibatch error= 17.7%\n",
      "2017-09-03 15:12:42,090 Epoch 132, Average loss: 0.1880, learning rate: 0.0010\n",
      "2017-09-03 15:12:42,163 Verification error= 12.9%, loss= 0.3212\n",
      "2017-09-03 15:12:50,124 Iter 13300, Minibatch Loss= 0.2351, Training Accuracy= 0.9021, Minibatch error= 9.8%\n",
      "2017-09-03 15:13:57,434 Iter 13350, Minibatch Loss= 0.2689, Training Accuracy= 0.9089, Minibatch error= 9.1%\n",
      "2017-09-03 15:15:03,343 Epoch 133, Average loss: 0.1891, learning rate: 0.0010\n",
      "2017-09-03 15:15:03,417 Verification error= 12.2%, loss= 0.3106\n",
      "2017-09-03 15:15:10,960 Iter 13400, Minibatch Loss= 0.3055, Training Accuracy= 0.8802, Minibatch error= 12.0%\n",
      "2017-09-03 15:16:18,672 Iter 13450, Minibatch Loss= 0.2740, Training Accuracy= 0.8875, Minibatch error= 11.2%\n",
      "2017-09-03 15:17:25,080 Epoch 134, Average loss: 0.1895, learning rate: 0.0010\n",
      "2017-09-03 15:17:25,152 Verification error= 12.7%, loss= 0.3183\n",
      "2017-09-03 15:17:32,724 Iter 13500, Minibatch Loss= 0.2474, Training Accuracy= 0.9034, Minibatch error= 9.7%\n",
      "2017-09-03 15:18:40,790 Iter 13550, Minibatch Loss= 0.3267, Training Accuracy= 0.8794, Minibatch error= 12.1%\n",
      "2017-09-03 15:19:47,601 Epoch 135, Average loss: 0.1880, learning rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 15:19:47,673 Verification error= 12.6%, loss= 0.3131\n",
      "2017-09-03 15:19:55,308 Iter 13600, Minibatch Loss= 0.2903, Training Accuracy= 0.8620, Minibatch error= 13.8%\n",
      "2017-09-03 15:21:04,031 Iter 13650, Minibatch Loss= 0.3409, Training Accuracy= 0.8620, Minibatch error= 13.8%\n",
      "2017-09-03 15:22:11,288 Epoch 136, Average loss: 0.1876, learning rate: 0.0010\n",
      "2017-09-03 15:22:11,359 Verification error= 13.4%, loss= 0.3389\n",
      "2017-09-03 15:22:19,101 Iter 13700, Minibatch Loss= 0.4047, Training Accuracy= 0.8211, Minibatch error= 17.9%\n",
      "2017-09-03 15:23:28,725 Iter 13750, Minibatch Loss= 0.2691, Training Accuracy= 0.9062, Minibatch error= 9.4%\n",
      "2017-09-03 15:24:36,590 Epoch 137, Average loss: 0.1889, learning rate: 0.0010\n",
      "2017-09-03 15:24:36,661 Verification error= 12.9%, loss= 0.3325\n",
      "2017-09-03 15:24:44,464 Iter 13800, Minibatch Loss= 0.3220, Training Accuracy= 0.8625, Minibatch error= 13.8%\n",
      "2017-09-03 15:25:54,005 Iter 13850, Minibatch Loss= 0.2798, Training Accuracy= 0.8859, Minibatch error= 11.4%\n",
      "2017-09-03 15:27:02,099 Epoch 138, Average loss: 0.1876, learning rate: 0.0010\n",
      "2017-09-03 15:27:02,171 Verification error= 12.9%, loss= 0.3134\n",
      "2017-09-03 15:27:09,987 Iter 13900, Minibatch Loss= 0.4344, Training Accuracy= 0.8266, Minibatch error= 17.3%\n",
      "2017-09-03 15:28:19,992 Iter 13950, Minibatch Loss= 0.2221, Training Accuracy= 0.9125, Minibatch error= 8.8%\n",
      "2017-09-03 15:29:28,531 Epoch 139, Average loss: 0.1883, learning rate: 0.0010\n",
      "2017-09-03 15:29:28,602 Verification error= 12.9%, loss= 0.3215\n",
      "2017-09-03 15:29:36,407 Iter 14000, Minibatch Loss= 0.2736, Training Accuracy= 0.8932, Minibatch error= 10.7%\n",
      "2017-09-03 15:30:46,628 Iter 14050, Minibatch Loss= 0.3057, Training Accuracy= 0.8875, Minibatch error= 11.2%\n",
      "2017-09-03 15:31:55,465 Epoch 140, Average loss: 0.1892, learning rate: 0.0010\n",
      "2017-09-03 15:31:55,536 Verification error= 12.0%, loss= 0.3146\n",
      "2017-09-03 15:32:03,357 Iter 14100, Minibatch Loss= 0.2600, Training Accuracy= 0.8932, Minibatch error= 10.7%\n",
      "2017-09-03 15:33:14,235 Iter 14150, Minibatch Loss= 0.2408, Training Accuracy= 0.9060, Minibatch error= 9.4%\n",
      "2017-09-03 15:34:23,622 Epoch 141, Average loss: 0.1873, learning rate: 0.0010\n",
      "2017-09-03 15:34:23,694 Verification error= 12.5%, loss= 0.3124\n",
      "2017-09-03 15:34:32,115 Iter 14200, Minibatch Loss= 0.3225, Training Accuracy= 0.8792, Minibatch error= 12.1%\n",
      "2017-09-03 15:35:43,212 Iter 14250, Minibatch Loss= 0.2871, Training Accuracy= 0.8703, Minibatch error= 13.0%\n",
      "2017-09-03 15:36:53,001 Epoch 142, Average loss: 0.1846, learning rate: 0.0010\n",
      "2017-09-03 15:36:53,073 Verification error= 13.4%, loss= 0.3277\n",
      "2017-09-03 15:37:01,008 Iter 14300, Minibatch Loss= 0.3431, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 15:38:12,573 Iter 14350, Minibatch Loss= 0.4039, Training Accuracy= 0.8164, Minibatch error= 18.4%\n",
      "2017-09-03 15:39:22,705 Epoch 143, Average loss: 0.1894, learning rate: 0.0010\n",
      "2017-09-03 15:39:22,777 Verification error= 12.8%, loss= 0.3301\n",
      "2017-09-03 15:39:30,787 Iter 14400, Minibatch Loss= 0.2661, Training Accuracy= 0.9070, Minibatch error= 9.3%\n",
      "2017-09-03 15:40:42,886 Iter 14450, Minibatch Loss= 0.2992, Training Accuracy= 0.8651, Minibatch error= 13.5%\n",
      "2017-09-03 15:41:53,459 Epoch 144, Average loss: 0.1849, learning rate: 0.0010\n",
      "2017-09-03 15:41:53,538 Verification error= 13.0%, loss= 0.3233\n",
      "2017-09-03 15:42:01,603 Iter 14500, Minibatch Loss= 0.2769, Training Accuracy= 0.8763, Minibatch error= 12.4%\n",
      "2017-09-03 15:43:14,060 Iter 14550, Minibatch Loss= 0.4358, Training Accuracy= 0.8229, Minibatch error= 17.7%\n",
      "2017-09-03 15:44:25,054 Epoch 145, Average loss: 0.1867, learning rate: 0.0010\n",
      "2017-09-03 15:44:25,125 Verification error= 13.2%, loss= 0.3138\n",
      "2017-09-03 15:44:33,211 Iter 14600, Minibatch Loss= 0.2172, Training Accuracy= 0.9115, Minibatch error= 8.9%\n",
      "2017-09-03 15:45:46,270 Iter 14650, Minibatch Loss= 0.2658, Training Accuracy= 0.8971, Minibatch error= 10.3%\n",
      "2017-09-03 15:46:57,614 Epoch 146, Average loss: 0.1861, learning rate: 0.0010\n",
      "2017-09-03 15:46:57,686 Verification error= 12.5%, loss= 0.3065\n",
      "2017-09-03 15:47:05,852 Iter 14700, Minibatch Loss= 0.3010, Training Accuracy= 0.8784, Minibatch error= 12.2%\n",
      "2017-09-03 15:48:19,301 Iter 14750, Minibatch Loss= 0.2610, Training Accuracy= 0.8839, Minibatch error= 11.6%\n",
      "2017-09-03 15:49:31,053 Epoch 147, Average loss: 0.1866, learning rate: 0.0010\n",
      "2017-09-03 15:49:31,125 Verification error= 12.4%, loss= 0.3068\n",
      "2017-09-03 15:49:39,302 Iter 14800, Minibatch Loss= 0.2324, Training Accuracy= 0.9060, Minibatch error= 9.4%\n",
      "2017-09-03 15:50:53,003 Iter 14850, Minibatch Loss= 0.3148, Training Accuracy= 0.8747, Minibatch error= 12.5%\n",
      "2017-09-03 15:52:05,310 Epoch 148, Average loss: 0.1850, learning rate: 0.0010\n",
      "2017-09-03 15:52:05,382 Verification error= 13.7%, loss= 0.3093\n",
      "2017-09-03 15:52:13,606 Iter 14900, Minibatch Loss= 0.2952, Training Accuracy= 0.8500, Minibatch error= 15.0%\n",
      "2017-09-03 15:53:27,750 Iter 14950, Minibatch Loss= 0.3251, Training Accuracy= 0.8622, Minibatch error= 13.8%\n",
      "2017-09-03 15:54:40,415 Epoch 149, Average loss: 0.1838, learning rate: 0.0010\n",
      "2017-09-03 15:54:40,486 Verification error= 12.6%, loss= 0.3218\n",
      "2017-09-03 15:54:48,774 Iter 15000, Minibatch Loss= 0.3881, Training Accuracy= 0.8250, Minibatch error= 17.5%\n",
      "2017-09-03 15:56:03,493 Iter 15050, Minibatch Loss= 0.2763, Training Accuracy= 0.9036, Minibatch error= 9.6%\n",
      "2017-09-03 15:57:17,780 Epoch 150, Average loss: 0.1846, learning rate: 0.0010\n",
      "2017-09-03 15:57:17,855 Verification error= 12.2%, loss= 0.3122\n",
      "2017-09-03 15:57:26,209 Iter 15100, Minibatch Loss= 0.3089, Training Accuracy= 0.8674, Minibatch error= 13.3%\n",
      "2017-09-03 15:58:41,001 Iter 15150, Minibatch Loss= 0.2696, Training Accuracy= 0.8828, Minibatch error= 11.7%\n",
      "2017-09-03 15:59:54,515 Epoch 151, Average loss: 0.1850, learning rate: 0.0010\n",
      "2017-09-03 15:59:54,589 Verification error= 13.0%, loss= 0.3090\n",
      "2017-09-03 16:00:03,446 Iter 15200, Minibatch Loss= 0.4219, Training Accuracy= 0.8294, Minibatch error= 17.1%\n",
      "2017-09-03 16:01:18,791 Iter 15250, Minibatch Loss= 0.2152, Training Accuracy= 0.9117, Minibatch error= 8.8%\n",
      "2017-09-03 16:02:32,758 Epoch 152, Average loss: 0.1870, learning rate: 0.0010\n",
      "2017-09-03 16:02:32,832 Verification error= 12.7%, loss= 0.3115\n",
      "2017-09-03 16:02:41,290 Iter 15300, Minibatch Loss= 0.2693, Training Accuracy= 0.8924, Minibatch error= 10.8%\n",
      "2017-09-03 16:03:57,172 Iter 15350, Minibatch Loss= 0.2897, Training Accuracy= 0.8826, Minibatch error= 11.7%\n",
      "2017-09-03 16:05:11,713 Epoch 153, Average loss: 0.1842, learning rate: 0.0010\n",
      "2017-09-03 16:05:11,788 Verification error= 12.3%, loss= 0.2996\n",
      "2017-09-03 16:05:20,277 Iter 15400, Minibatch Loss= 0.2586, Training Accuracy= 0.8841, Minibatch error= 11.6%\n",
      "2017-09-03 16:06:36,651 Iter 15450, Minibatch Loss= 0.2271, Training Accuracy= 0.9049, Minibatch error= 9.5%\n",
      "2017-09-03 16:07:51,512 Epoch 154, Average loss: 0.1837, learning rate: 0.0010\n",
      "2017-09-03 16:07:51,587 Verification error= 12.2%, loss= 0.3013\n",
      "2017-09-03 16:08:00,067 Iter 15500, Minibatch Loss= 0.3121, Training Accuracy= 0.8818, Minibatch error= 11.8%\n",
      "2017-09-03 16:09:16,852 Iter 15550, Minibatch Loss= 0.2893, Training Accuracy= 0.8542, Minibatch error= 14.6%\n",
      "2017-09-03 16:10:31,948 Epoch 155, Average loss: 0.1849, learning rate: 0.0010\n",
      "2017-09-03 16:10:32,022 Verification error= 13.2%, loss= 0.3081\n",
      "2017-09-03 16:10:40,541 Iter 15600, Minibatch Loss= 0.3272, Training Accuracy= 0.8547, Minibatch error= 14.5%\n",
      "2017-09-03 16:11:57,694 Iter 15650, Minibatch Loss= 0.3782, Training Accuracy= 0.8253, Minibatch error= 17.5%\n",
      "2017-09-03 16:13:13,323 Epoch 156, Average loss: 0.1823, learning rate: 0.0010\n",
      "2017-09-03 16:13:13,399 Verification error= 12.5%, loss= 0.3213\n",
      "2017-09-03 16:13:22,062 Iter 15700, Minibatch Loss= 0.2609, Training Accuracy= 0.9021, Minibatch error= 9.8%\n",
      "2017-09-03 16:14:39,692 Iter 15750, Minibatch Loss= 0.3000, Training Accuracy= 0.8685, Minibatch error= 13.2%\n",
      "2017-09-03 16:15:55,746 Epoch 157, Average loss: 0.1872, learning rate: 0.0010\n",
      "2017-09-03 16:15:55,820 Verification error= 13.1%, loss= 0.3008\n",
      "2017-09-03 16:16:04,454 Iter 15800, Minibatch Loss= 0.2577, Training Accuracy= 0.8799, Minibatch error= 12.0%\n",
      "2017-09-03 16:17:22,381 Iter 15850, Minibatch Loss= 0.4150, Training Accuracy= 0.8271, Minibatch error= 17.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 16:18:38,788 Epoch 158, Average loss: 0.1841, learning rate: 0.0010\n",
      "2017-09-03 16:18:38,860 Verification error= 12.8%, loss= 0.3005\n",
      "2017-09-03 16:18:47,552 Iter 15900, Minibatch Loss= 0.2205, Training Accuracy= 0.9190, Minibatch error= 8.1%\n",
      "2017-09-03 16:20:05,824 Iter 15950, Minibatch Loss= 0.2555, Training Accuracy= 0.8953, Minibatch error= 10.5%\n",
      "2017-09-03 16:21:22,647 Epoch 159, Average loss: 0.1826, learning rate: 0.0010\n",
      "2017-09-03 16:21:22,719 Verification error= 12.2%, loss= 0.2917\n",
      "2017-09-03 16:21:31,473 Iter 16000, Minibatch Loss= 0.2907, Training Accuracy= 0.8810, Minibatch error= 11.9%\n",
      "2017-09-03 16:22:50,500 Iter 16050, Minibatch Loss= 0.2582, Training Accuracy= 0.8826, Minibatch error= 11.7%\n",
      "2017-09-03 16:24:07,800 Epoch 160, Average loss: 0.1831, learning rate: 0.0010\n",
      "2017-09-03 16:24:07,872 Verification error= 12.4%, loss= 0.2994\n",
      "2017-09-03 16:24:17,234 Iter 16100, Minibatch Loss= 0.2277, Training Accuracy= 0.9078, Minibatch error= 9.2%\n",
      "2017-09-03 16:25:36,494 Iter 16150, Minibatch Loss= 0.3105, Training Accuracy= 0.8667, Minibatch error= 13.3%\n",
      "2017-09-03 16:26:54,205 Epoch 161, Average loss: 0.1826, learning rate: 0.0010\n",
      "2017-09-03 16:26:54,277 Verification error= 13.4%, loss= 0.2974\n",
      "2017-09-03 16:27:03,109 Iter 16200, Minibatch Loss= 0.2912, Training Accuracy= 0.8469, Minibatch error= 15.3%\n",
      "2017-09-03 16:28:22,694 Iter 16250, Minibatch Loss= 0.3165, Training Accuracy= 0.8589, Minibatch error= 14.1%\n",
      "2017-09-03 16:29:40,788 Epoch 162, Average loss: 0.1808, learning rate: 0.0010\n",
      "2017-09-03 16:29:40,860 Verification error= 13.3%, loss= 0.3179\n",
      "2017-09-03 16:29:49,745 Iter 16300, Minibatch Loss= 0.3888, Training Accuracy= 0.8161, Minibatch error= 18.4%\n",
      "2017-09-03 16:31:10,054 Iter 16350, Minibatch Loss= 0.2563, Training Accuracy= 0.8984, Minibatch error= 10.2%\n",
      "2017-09-03 16:32:28,651 Epoch 163, Average loss: 0.1819, learning rate: 0.0010\n",
      "2017-09-03 16:32:28,723 Verification error= 12.9%, loss= 0.3065\n",
      "2017-09-03 16:32:37,628 Iter 16400, Minibatch Loss= 0.2988, Training Accuracy= 0.8648, Minibatch error= 13.5%\n",
      "2017-09-03 16:33:58,365 Iter 16450, Minibatch Loss= 0.2566, Training Accuracy= 0.8794, Minibatch error= 12.1%\n",
      "2017-09-03 16:35:17,432 Epoch 164, Average loss: 0.1815, learning rate: 0.0010\n",
      "2017-09-03 16:35:17,503 Verification error= 14.1%, loss= 0.3063\n",
      "2017-09-03 16:35:26,503 Iter 16500, Minibatch Loss= 0.4191, Training Accuracy= 0.8255, Minibatch error= 17.4%\n",
      "2017-09-03 16:36:47,498 Iter 16550, Minibatch Loss= 0.1985, Training Accuracy= 0.9138, Minibatch error= 8.6%\n",
      "2017-09-03 16:38:06,929 Epoch 165, Average loss: 0.1797, learning rate: 0.0010\n",
      "2017-09-03 16:38:07,000 Verification error= 13.2%, loss= 0.2959\n",
      "2017-09-03 16:38:16,025 Iter 16600, Minibatch Loss= 0.2590, Training Accuracy= 0.8898, Minibatch error= 11.0%\n",
      "2017-09-03 16:39:37,781 Iter 16650, Minibatch Loss= 0.2988, Training Accuracy= 0.8711, Minibatch error= 12.9%\n",
      "2017-09-03 16:40:57,636 Epoch 166, Average loss: 0.1812, learning rate: 0.0010\n",
      "2017-09-03 16:40:57,709 Verification error= 12.3%, loss= 0.2931\n",
      "2017-09-03 16:41:06,832 Iter 16700, Minibatch Loss= 0.2516, Training Accuracy= 0.8849, Minibatch error= 11.5%\n",
      "2017-09-03 16:42:28,810 Iter 16750, Minibatch Loss= 0.2193, Training Accuracy= 0.8940, Minibatch error= 10.6%\n",
      "2017-09-03 16:43:49,160 Epoch 167, Average loss: 0.1808, learning rate: 0.0010\n",
      "2017-09-03 16:43:49,231 Verification error= 11.1%, loss= 0.2676\n",
      "2017-09-03 16:43:58,338 Iter 16800, Minibatch Loss= 0.2702, Training Accuracy= 0.8982, Minibatch error= 10.2%\n",
      "2017-09-03 16:45:20,916 Iter 16850, Minibatch Loss= 0.2883, Training Accuracy= 0.8461, Minibatch error= 15.4%\n",
      "2017-09-03 16:46:41,523 Epoch 168, Average loss: 0.1814, learning rate: 0.0010\n",
      "2017-09-03 16:46:41,595 Verification error= 13.8%, loss= 0.3018\n",
      "2017-09-03 16:46:50,755 Iter 16900, Minibatch Loss= 0.3158, Training Accuracy= 0.8620, Minibatch error= 13.8%\n",
      "2017-09-03 16:48:13,648 Iter 16950, Minibatch Loss= 0.3823, Training Accuracy= 0.8156, Minibatch error= 18.4%\n",
      "2017-09-03 16:49:34,924 Epoch 169, Average loss: 0.1802, learning rate: 0.0010\n",
      "2017-09-03 16:49:34,997 Verification error= 12.6%, loss= 0.2976\n",
      "2017-09-03 16:49:44,816 Iter 17000, Minibatch Loss= 0.2388, Training Accuracy= 0.9047, Minibatch error= 9.5%\n",
      "2017-09-03 16:51:08,417 Iter 17050, Minibatch Loss= 0.2892, Training Accuracy= 0.8680, Minibatch error= 13.2%\n",
      "2017-09-03 16:52:30,183 Epoch 170, Average loss: 0.1826, learning rate: 0.0010\n",
      "2017-09-03 16:52:30,254 Verification error= 13.9%, loss= 0.3067\n",
      "2017-09-03 16:52:39,522 Iter 17100, Minibatch Loss= 0.2511, Training Accuracy= 0.8826, Minibatch error= 11.7%\n",
      "2017-09-03 16:54:03,658 Iter 17150, Minibatch Loss= 0.4318, Training Accuracy= 0.8133, Minibatch error= 18.7%\n",
      "2017-09-03 16:55:26,133 Epoch 171, Average loss: 0.1785, learning rate: 0.0010\n",
      "2017-09-03 16:55:26,204 Verification error= 13.8%, loss= 0.2962\n",
      "2017-09-03 16:55:35,605 Iter 17200, Minibatch Loss= 0.1978, Training Accuracy= 0.9133, Minibatch error= 8.7%\n",
      "2017-09-03 16:57:00,038 Iter 17250, Minibatch Loss= 0.2452, Training Accuracy= 0.8826, Minibatch error= 11.7%\n",
      "2017-09-03 16:58:22,965 Epoch 172, Average loss: 0.1794, learning rate: 0.0010\n",
      "2017-09-03 16:58:23,037 Verification error= 13.1%, loss= 0.2814\n",
      "2017-09-03 16:58:32,423 Iter 17300, Minibatch Loss= 0.2832, Training Accuracy= 0.8719, Minibatch error= 12.8%\n",
      "2017-09-03 16:59:57,306 Iter 17350, Minibatch Loss= 0.2422, Training Accuracy= 0.8789, Minibatch error= 12.1%\n",
      "2017-09-03 17:01:20,488 Epoch 173, Average loss: 0.1817, learning rate: 0.0010\n",
      "2017-09-03 17:01:20,560 Verification error= 13.1%, loss= 0.2794\n",
      "2017-09-03 17:01:29,976 Iter 17400, Minibatch Loss= 0.2054, Training Accuracy= 0.9018, Minibatch error= 9.8%\n",
      "2017-09-03 17:02:55,719 Iter 17450, Minibatch Loss= 0.2964, Training Accuracy= 0.8698, Minibatch error= 13.0%\n",
      "2017-09-03 17:04:19,376 Epoch 174, Average loss: 0.1809, learning rate: 0.0010\n",
      "2017-09-03 17:04:19,447 Verification error= 14.4%, loss= 0.2927\n",
      "2017-09-03 17:04:28,935 Iter 17500, Minibatch Loss= 0.3023, Training Accuracy= 0.8552, Minibatch error= 14.5%\n",
      "2017-09-03 17:05:54,808 Iter 17550, Minibatch Loss= 0.3119, Training Accuracy= 0.8487, Minibatch error= 15.1%\n",
      "2017-09-03 17:07:18,876 Epoch 175, Average loss: 0.1795, learning rate: 0.0010\n",
      "2017-09-03 17:07:18,948 Verification error= 13.1%, loss= 0.2965\n",
      "2017-09-03 17:07:28,485 Iter 17600, Minibatch Loss= 0.3735, Training Accuracy= 0.8122, Minibatch error= 18.8%\n",
      "2017-09-03 17:08:54,753 Iter 17650, Minibatch Loss= 0.2458, Training Accuracy= 0.9000, Minibatch error= 10.0%\n",
      "2017-09-03 17:10:19,377 Epoch 176, Average loss: 0.1800, learning rate: 0.0010\n",
      "2017-09-03 17:10:19,449 Verification error= 14.1%, loss= 0.2975\n",
      "2017-09-03 17:10:29,046 Iter 17700, Minibatch Loss= 0.2780, Training Accuracy= 0.8612, Minibatch error= 13.9%\n",
      "2017-09-03 17:11:56,185 Iter 17750, Minibatch Loss= 0.2357, Training Accuracy= 0.8859, Minibatch error= 11.4%\n",
      "2017-09-03 17:13:21,194 Epoch 177, Average loss: 0.1780, learning rate: 0.0010\n",
      "2017-09-03 17:13:21,269 Verification error= 13.3%, loss= 0.2773\n",
      "2017-09-03 17:13:30,865 Iter 17800, Minibatch Loss= 0.3849, Training Accuracy= 0.8292, Minibatch error= 17.1%\n",
      "2017-09-03 17:14:57,996 Iter 17850, Minibatch Loss= 0.1923, Training Accuracy= 0.9206, Minibatch error= 7.9%\n",
      "2017-09-03 17:16:23,329 Epoch 178, Average loss: 0.1816, learning rate: 0.0010\n",
      "2017-09-03 17:16:23,400 Verification error= 13.0%, loss= 0.2708\n",
      "2017-09-03 17:16:33,085 Iter 17900, Minibatch Loss= 0.2395, Training Accuracy= 0.8836, Minibatch error= 11.6%\n",
      "2017-09-03 17:18:00,465 Iter 17950, Minibatch Loss= 0.2820, Training Accuracy= 0.8680, Minibatch error= 13.2%\n",
      "2017-09-03 17:19:26,194 Epoch 179, Average loss: 0.1784, learning rate: 0.0010\n",
      "2017-09-03 17:19:26,265 Verification error= 12.0%, loss= 0.2627\n",
      "2017-09-03 17:19:36,570 Iter 18000, Minibatch Loss= 0.2216, Training Accuracy= 0.8898, Minibatch error= 11.0%\n",
      "2017-09-03 17:21:04,591 Iter 18050, Minibatch Loss= 0.2049, Training Accuracy= 0.9055, Minibatch error= 9.5%\n",
      "2017-09-03 17:22:30,721 Epoch 180, Average loss: 0.1783, learning rate: 0.0010\n",
      "2017-09-03 17:22:30,793 Verification error= 12.8%, loss= 0.2691\n",
      "2017-09-03 17:22:40,571 Iter 18100, Minibatch Loss= 0.3090, Training Accuracy= 0.8685, Minibatch error= 13.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 17:24:08,927 Iter 18150, Minibatch Loss= 0.3077, Training Accuracy= 0.8594, Minibatch error= 14.1%\n",
      "2017-09-03 17:25:35,620 Epoch 181, Average loss: 0.1801, learning rate: 0.0010\n",
      "2017-09-03 17:25:35,692 Verification error= 13.6%, loss= 0.2913\n",
      "2017-09-03 17:25:45,518 Iter 18200, Minibatch Loss= 0.3138, Training Accuracy= 0.8490, Minibatch error= 15.1%\n",
      "2017-09-03 17:27:14,317 Iter 18250, Minibatch Loss= 0.3818, Training Accuracy= 0.8083, Minibatch error= 19.2%\n",
      "2017-09-03 17:28:41,259 Epoch 182, Average loss: 0.1764, learning rate: 0.0010\n",
      "2017-09-03 17:28:41,331 Verification error= 13.4%, loss= 0.2859\n",
      "2017-09-03 17:28:51,207 Iter 18300, Minibatch Loss= 0.2273, Training Accuracy= 0.8987, Minibatch error= 10.1%\n",
      "2017-09-03 17:30:20,714 Iter 18350, Minibatch Loss= 0.2638, Training Accuracy= 0.8753, Minibatch error= 12.5%\n",
      "2017-09-03 17:31:48,184 Epoch 183, Average loss: 0.1757, learning rate: 0.0010\n",
      "2017-09-03 17:31:48,256 Verification error= 12.8%, loss= 0.2707\n",
      "2017-09-03 17:31:58,113 Iter 18400, Minibatch Loss= 0.2303, Training Accuracy= 0.8844, Minibatch error= 11.6%\n",
      "2017-09-03 17:33:27,649 Iter 18450, Minibatch Loss= 0.3810, Training Accuracy= 0.8328, Minibatch error= 16.7%\n",
      "2017-09-03 17:34:55,557 Epoch 184, Average loss: 0.1776, learning rate: 0.0010\n",
      "2017-09-03 17:34:55,629 Verification error= 13.2%, loss= 0.2762\n",
      "2017-09-03 17:35:05,605 Iter 18500, Minibatch Loss= 0.1937, Training Accuracy= 0.9271, Minibatch error= 7.3%\n",
      "2017-09-03 17:36:35,588 Iter 18550, Minibatch Loss= 0.2273, Training Accuracy= 0.8901, Minibatch error= 11.0%\n",
      "2017-09-03 17:38:04,199 Epoch 185, Average loss: 0.1751, learning rate: 0.0010\n",
      "2017-09-03 17:38:04,270 Verification error= 12.5%, loss= 0.2603\n",
      "2017-09-03 17:38:14,260 Iter 18600, Minibatch Loss= 0.2588, Training Accuracy= 0.8810, Minibatch error= 11.9%\n",
      "2017-09-03 17:39:45,096 Iter 18650, Minibatch Loss= 0.2201, Training Accuracy= 0.8969, Minibatch error= 10.3%\n",
      "2017-09-03 17:41:13,789 Epoch 186, Average loss: 0.1756, learning rate: 0.0010\n",
      "2017-09-03 17:41:13,861 Verification error= 11.7%, loss= 0.2551\n",
      "2017-09-03 17:41:23,914 Iter 18700, Minibatch Loss= 0.1908, Training Accuracy= 0.9195, Minibatch error= 8.0%\n",
      "2017-09-03 17:42:55,250 Iter 18750, Minibatch Loss= 0.3022, Training Accuracy= 0.8669, Minibatch error= 13.3%\n",
      "2017-09-03 17:44:24,526 Epoch 187, Average loss: 0.1764, learning rate: 0.0010\n",
      "2017-09-03 17:44:24,597 Verification error= 12.6%, loss= 0.2639\n",
      "2017-09-03 17:44:34,659 Iter 18800, Minibatch Loss= 0.2898, Training Accuracy= 0.8656, Minibatch error= 13.4%\n",
      "2017-09-03 17:46:06,334 Iter 18850, Minibatch Loss= 0.3090, Training Accuracy= 0.8557, Minibatch error= 14.4%\n",
      "2017-09-03 17:47:35,960 Epoch 188, Average loss: 0.1765, learning rate: 0.0010\n",
      "2017-09-03 17:47:36,031 Verification error= 13.2%, loss= 0.2878\n",
      "2017-09-03 17:47:46,132 Iter 18900, Minibatch Loss= 0.3855, Training Accuracy= 0.8135, Minibatch error= 18.6%\n",
      "2017-09-03 17:49:17,965 Iter 18950, Minibatch Loss= 0.2241, Training Accuracy= 0.9005, Minibatch error= 9.9%\n",
      "2017-09-03 17:50:47,832 Epoch 189, Average loss: 0.1777, learning rate: 0.0010\n",
      "2017-09-03 17:50:47,906 Verification error= 13.4%, loss= 0.2840\n",
      "2017-09-03 17:50:58,602 Iter 19000, Minibatch Loss= 0.2738, Training Accuracy= 0.8766, Minibatch error= 12.3%\n",
      "2017-09-03 17:52:30,651 Iter 19050, Minibatch Loss= 0.2274, Training Accuracy= 0.8901, Minibatch error= 11.0%\n",
      "2017-09-03 17:54:01,033 Epoch 190, Average loss: 0.1740, learning rate: 0.0010\n",
      "2017-09-03 17:54:01,105 Verification error= 13.0%, loss= 0.2796\n",
      "2017-09-03 17:54:11,269 Iter 19100, Minibatch Loss= 0.3767, Training Accuracy= 0.8396, Minibatch error= 16.0%\n",
      "2017-09-03 17:55:43,854 Iter 19150, Minibatch Loss= 0.1898, Training Accuracy= 0.9273, Minibatch error= 7.3%\n",
      "2017-09-03 17:57:14,697 Epoch 191, Average loss: 0.1737, learning rate: 0.0010\n",
      "2017-09-03 17:57:14,769 Verification error= 12.1%, loss= 0.2631\n",
      "2017-09-03 17:57:24,975 Iter 19200, Minibatch Loss= 0.2261, Training Accuracy= 0.8930, Minibatch error= 10.7%\n",
      "2017-09-03 17:58:58,055 Iter 19250, Minibatch Loss= 0.2669, Training Accuracy= 0.8823, Minibatch error= 11.8%\n",
      "2017-09-03 18:00:29,159 Epoch 192, Average loss: 0.1740, learning rate: 0.0010\n",
      "2017-09-03 18:00:29,231 Verification error= 12.0%, loss= 0.2669\n",
      "2017-09-03 18:00:39,700 Iter 19300, Minibatch Loss= 0.2083, Training Accuracy= 0.9094, Minibatch error= 9.1%\n",
      "2017-09-03 18:02:13,038 Iter 19350, Minibatch Loss= 0.1971, Training Accuracy= 0.9135, Minibatch error= 8.6%\n",
      "2017-09-03 18:03:44,587 Epoch 193, Average loss: 0.1712, learning rate: 0.0010\n",
      "2017-09-03 18:03:44,659 Verification error= 12.0%, loss= 0.2596\n",
      "2017-09-03 18:03:54,968 Iter 19400, Minibatch Loss= 0.2773, Training Accuracy= 0.8750, Minibatch error= 12.5%\n",
      "2017-09-03 18:05:28,894 Iter 19450, Minibatch Loss= 0.3053, Training Accuracy= 0.8596, Minibatch error= 14.0%\n",
      "2017-09-03 18:07:01,029 Epoch 194, Average loss: 0.1758, learning rate: 0.0010\n",
      "2017-09-03 18:07:01,103 Verification error= 12.4%, loss= 0.2854\n",
      "2017-09-03 18:07:11,387 Iter 19500, Minibatch Loss= 0.3143, Training Accuracy= 0.8602, Minibatch error= 14.0%\n",
      "2017-09-03 18:08:45,623 Iter 19550, Minibatch Loss= 0.3644, Training Accuracy= 0.8380, Minibatch error= 16.2%\n",
      "2017-09-03 18:10:18,194 Epoch 195, Average loss: 0.1703, learning rate: 0.0010\n",
      "2017-09-03 18:10:18,271 Verification error= 11.3%, loss= 0.2741\n",
      "2017-09-03 18:10:28,646 Iter 19600, Minibatch Loss= 0.2199, Training Accuracy= 0.9057, Minibatch error= 9.4%\n",
      "2017-09-03 18:12:03,360 Iter 19650, Minibatch Loss= 0.2583, Training Accuracy= 0.8841, Minibatch error= 11.6%\n",
      "2017-09-03 18:13:36,350 Epoch 196, Average loss: 0.1712, learning rate: 0.0010\n",
      "2017-09-03 18:13:36,422 Verification error= 11.7%, loss= 0.2750\n",
      "2017-09-03 18:13:46,820 Iter 19700, Minibatch Loss= 0.2175, Training Accuracy= 0.9049, Minibatch error= 9.5%\n",
      "2017-09-03 18:15:21,988 Iter 19750, Minibatch Loss= 0.3862, Training Accuracy= 0.8469, Minibatch error= 15.3%\n",
      "2017-09-03 18:16:55,144 Epoch 197, Average loss: 0.1724, learning rate: 0.0010\n",
      "2017-09-03 18:16:55,216 Verification error= 12.2%, loss= 0.2768\n",
      "2017-09-03 18:17:05,662 Iter 19800, Minibatch Loss= 0.1914, Training Accuracy= 0.9299, Minibatch error= 7.0%\n",
      "2017-09-03 18:18:41,436 Iter 19850, Minibatch Loss= 0.2436, Training Accuracy= 0.8839, Minibatch error= 11.6%\n",
      "2017-09-03 18:20:15,598 Epoch 198, Average loss: 0.1735, learning rate: 0.0010\n",
      "2017-09-03 18:20:15,670 Verification error= 11.9%, loss= 0.2666\n",
      "2017-09-03 18:20:26,877 Iter 19900, Minibatch Loss= 0.2563, Training Accuracy= 0.8924, Minibatch error= 10.8%\n",
      "2017-09-03 18:22:03,013 Iter 19950, Minibatch Loss= 0.2041, Training Accuracy= 0.9201, Minibatch error= 8.0%\n",
      "2017-09-03 18:23:37,041 Epoch 199, Average loss: 0.1743, learning rate: 0.0010\n",
      "2017-09-03 18:23:37,113 Verification error= 12.7%, loss= 0.2742\n",
      "2017-09-03 18:23:47,730 Iter 20000, Minibatch Loss= 0.1892, Training Accuracy= 0.9156, Minibatch error= 8.4%\n",
      "2017-09-03 18:25:24,545 Iter 20050, Minibatch Loss= 0.3123, Training Accuracy= 0.8589, Minibatch error= 14.1%\n",
      "2017-09-03 18:26:58,983 Epoch 200, Average loss: 0.1705, learning rate: 0.0010\n",
      "2017-09-03 18:26:59,056 Verification error= 13.2%, loss= 0.2849\n",
      "2017-09-03 18:27:09,693 Iter 20100, Minibatch Loss= 0.3306, Training Accuracy= 0.8518, Minibatch error= 14.8%\n",
      "2017-09-03 18:28:46,641 Iter 20150, Minibatch Loss= 0.3212, Training Accuracy= 0.8521, Minibatch error= 14.8%\n",
      "2017-09-03 18:30:21,727 Epoch 201, Average loss: 0.1685, learning rate: 0.0010\n",
      "2017-09-03 18:30:21,798 Verification error= 11.9%, loss= 0.2876\n",
      "2017-09-03 18:30:32,512 Iter 20200, Minibatch Loss= 0.4033, Training Accuracy= 0.8313, Minibatch error= 16.9%\n",
      "2017-09-03 18:32:09,996 Iter 20250, Minibatch Loss= 0.2288, Training Accuracy= 0.9018, Minibatch error= 9.8%\n",
      "2017-09-03 18:33:45,389 Epoch 202, Average loss: 0.1724, learning rate: 0.0010\n",
      "2017-09-03 18:33:45,461 Verification error= 11.8%, loss= 0.2787\n",
      "2017-09-03 18:33:56,159 Iter 20300, Minibatch Loss= 0.2644, Training Accuracy= 0.8768, Minibatch error= 12.3%\n",
      "2017-09-03 18:35:34,161 Iter 20350, Minibatch Loss= 0.2171, Training Accuracy= 0.9023, Minibatch error= 9.8%\n",
      "2017-09-03 18:37:09,986 Epoch 203, Average loss: 0.1703, learning rate: 0.0010\n",
      "2017-09-03 18:37:10,057 Verification error= 13.0%, loss= 0.2809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 18:37:20,886 Iter 20400, Minibatch Loss= 0.3738, Training Accuracy= 0.8435, Minibatch error= 15.7%\n",
      "2017-09-03 18:38:58,932 Iter 20450, Minibatch Loss= 0.1911, Training Accuracy= 0.9297, Minibatch error= 7.0%\n",
      "2017-09-03 18:40:35,094 Epoch 204, Average loss: 0.1719, learning rate: 0.0010\n",
      "2017-09-03 18:40:35,166 Verification error= 12.4%, loss= 0.2891\n",
      "2017-09-03 18:40:45,976 Iter 20500, Minibatch Loss= 0.2562, Training Accuracy= 0.8862, Minibatch error= 11.4%\n",
      "2017-09-03 18:42:24,665 Iter 20550, Minibatch Loss= 0.2645, Training Accuracy= 0.8924, Minibatch error= 10.8%\n",
      "2017-09-03 18:44:01,225 Epoch 205, Average loss: 0.1692, learning rate: 0.0010\n",
      "2017-09-03 18:44:01,297 Verification error= 12.1%, loss= 0.2765\n",
      "2017-09-03 18:44:12,192 Iter 20600, Minibatch Loss= 0.2053, Training Accuracy= 0.9151, Minibatch error= 8.5%\n",
      "2017-09-03 18:45:51,587 Iter 20650, Minibatch Loss= 0.1930, Training Accuracy= 0.9188, Minibatch error= 8.1%\n",
      "2017-09-03 18:47:28,729 Epoch 206, Average loss: 0.1696, learning rate: 0.0010\n",
      "2017-09-03 18:47:28,801 Verification error= 12.7%, loss= 0.2885\n",
      "2017-09-03 18:47:39,701 Iter 20700, Minibatch Loss= 0.3256, Training Accuracy= 0.8573, Minibatch error= 14.3%\n",
      "2017-09-03 18:49:19,996 Iter 20750, Minibatch Loss= 0.3559, Training Accuracy= 0.8380, Minibatch error= 16.2%\n",
      "2017-09-03 18:50:57,905 Epoch 207, Average loss: 0.1694, learning rate: 0.0010\n",
      "2017-09-03 18:50:57,977 Verification error= 12.1%, loss= 0.2972\n",
      "2017-09-03 18:51:09,011 Iter 20800, Minibatch Loss= 0.3391, Training Accuracy= 0.8482, Minibatch error= 15.2%\n",
      "2017-09-03 18:52:49,093 Iter 20850, Minibatch Loss= 0.4143, Training Accuracy= 0.8253, Minibatch error= 17.5%\n",
      "2017-09-03 18:54:27,104 Epoch 208, Average loss: 0.1686, learning rate: 0.0010\n",
      "2017-09-03 18:54:27,177 Verification error= 11.6%, loss= 0.2910\n",
      "2017-09-03 18:54:38,890 Iter 20900, Minibatch Loss= 0.2325, Training Accuracy= 0.8997, Minibatch error= 10.0%\n",
      "2017-09-03 18:56:19,334 Iter 20950, Minibatch Loss= 0.2688, Training Accuracy= 0.8786, Minibatch error= 12.1%\n",
      "2017-09-03 18:57:57,741 Epoch 209, Average loss: 0.1693, learning rate: 0.0010\n",
      "2017-09-03 18:57:57,812 Verification error= 12.5%, loss= 0.2953\n",
      "2017-09-03 18:58:08,906 Iter 21000, Minibatch Loss= 0.2181, Training Accuracy= 0.9031, Minibatch error= 9.7%\n",
      "2017-09-03 18:59:49,859 Iter 21050, Minibatch Loss= 0.3882, Training Accuracy= 0.8443, Minibatch error= 15.6%\n",
      "2017-09-03 19:01:28,791 Epoch 210, Average loss: 0.1656, learning rate: 0.0010\n",
      "2017-09-03 19:01:28,862 Verification error= 12.8%, loss= 0.2921\n",
      "2017-09-03 19:01:39,989 Iter 21100, Minibatch Loss= 0.1857, Training Accuracy= 0.9292, Minibatch error= 7.1%\n",
      "2017-09-03 19:03:21,392 Iter 21150, Minibatch Loss= 0.2555, Training Accuracy= 0.8794, Minibatch error= 12.1%\n",
      "2017-09-03 19:05:00,910 Epoch 211, Average loss: 0.1679, learning rate: 0.0010\n",
      "2017-09-03 19:05:00,982 Verification error= 11.9%, loss= 0.2760\n",
      "2017-09-03 19:05:12,239 Iter 21200, Minibatch Loss= 0.2556, Training Accuracy= 0.8958, Minibatch error= 10.4%\n",
      "2017-09-03 19:06:54,184 Iter 21250, Minibatch Loss= 0.2119, Training Accuracy= 0.9141, Minibatch error= 8.6%\n",
      "2017-09-03 19:08:33,864 Epoch 212, Average loss: 0.1707, learning rate: 0.0010\n",
      "2017-09-03 19:08:33,936 Verification error= 12.4%, loss= 0.2908\n",
      "2017-09-03 19:08:45,175 Iter 21300, Minibatch Loss= 0.1896, Training Accuracy= 0.9154, Minibatch error= 8.5%\n",
      "2017-09-03 19:10:27,619 Iter 21350, Minibatch Loss= 0.3260, Training Accuracy= 0.8620, Minibatch error= 13.8%\n",
      "2017-09-03 19:12:07,835 Epoch 213, Average loss: 0.1679, learning rate: 0.0010\n",
      "2017-09-03 19:12:07,907 Verification error= 13.3%, loss= 0.3026\n",
      "2017-09-03 19:12:19,241 Iter 21400, Minibatch Loss= 0.3615, Training Accuracy= 0.8328, Minibatch error= 16.7%\n",
      "2017-09-03 19:14:01,953 Iter 21450, Minibatch Loss= 0.3274, Training Accuracy= 0.8456, Minibatch error= 15.4%\n",
      "2017-09-03 19:15:42,897 Epoch 214, Average loss: 0.1672, learning rate: 0.0010\n",
      "2017-09-03 19:15:42,968 Verification error= 11.7%, loss= 0.2767\n",
      "2017-09-03 19:15:54,327 Iter 21500, Minibatch Loss= 0.3879, Training Accuracy= 0.8391, Minibatch error= 16.1%\n",
      "2017-09-03 19:17:37,616 Iter 21550, Minibatch Loss= 0.2259, Training Accuracy= 0.9021, Minibatch error= 9.8%\n",
      "2017-09-03 19:19:18,613 Epoch 215, Average loss: 0.1683, learning rate: 0.0010\n",
      "2017-09-03 19:19:18,684 Verification error= 11.5%, loss= 0.2879\n",
      "2017-09-03 19:19:30,004 Iter 21600, Minibatch Loss= 0.2659, Training Accuracy= 0.8724, Minibatch error= 12.8%\n",
      "2017-09-03 19:21:13,255 Iter 21650, Minibatch Loss= 0.2084, Training Accuracy= 0.9052, Minibatch error= 9.5%\n",
      "2017-09-03 19:22:54,762 Epoch 216, Average loss: 0.1623, learning rate: 0.0010\n",
      "2017-09-03 19:22:54,834 Verification error= 12.9%, loss= 0.2948\n",
      "2017-09-03 19:23:06,331 Iter 21700, Minibatch Loss= 0.3822, Training Accuracy= 0.8359, Minibatch error= 16.4%\n",
      "2017-09-03 19:24:50,287 Iter 21750, Minibatch Loss= 0.1918, Training Accuracy= 0.9263, Minibatch error= 7.4%\n",
      "2017-09-03 19:26:32,249 Epoch 217, Average loss: 0.1639, learning rate: 0.0010\n",
      "2017-09-03 19:26:32,320 Verification error= 12.2%, loss= 0.2806\n",
      "2017-09-03 19:26:43,810 Iter 21800, Minibatch Loss= 0.2456, Training Accuracy= 0.8896, Minibatch error= 11.0%\n",
      "2017-09-03 19:28:28,141 Iter 21850, Minibatch Loss= 0.2450, Training Accuracy= 0.8984, Minibatch error= 10.2%\n",
      "2017-09-03 19:30:10,533 Epoch 218, Average loss: 0.1632, learning rate: 0.0010\n",
      "2017-09-03 19:30:10,605 Verification error= 11.6%, loss= 0.2668\n",
      "2017-09-03 19:30:22,828 Iter 21900, Minibatch Loss= 0.1907, Training Accuracy= 0.9193, Minibatch error= 8.1%\n",
      "2017-09-03 19:32:07,599 Iter 21950, Minibatch Loss= 0.1851, Training Accuracy= 0.9201, Minibatch error= 8.0%\n",
      "2017-09-03 19:33:50,354 Epoch 219, Average loss: 0.1606, learning rate: 0.0010\n",
      "2017-09-03 19:33:50,426 Verification error= 11.8%, loss= 0.2682\n",
      "2017-09-03 19:34:01,966 Iter 22000, Minibatch Loss= 0.2887, Training Accuracy= 0.8693, Minibatch error= 13.1%\n",
      "2017-09-03 19:35:47,419 Iter 22050, Minibatch Loss= 0.3404, Training Accuracy= 0.8458, Minibatch error= 15.4%\n",
      "2017-09-03 19:37:30,530 Epoch 220, Average loss: 0.1608, learning rate: 0.0010\n",
      "2017-09-03 19:37:30,601 Verification error= 11.3%, loss= 0.2744\n",
      "2017-09-03 19:37:42,146 Iter 22100, Minibatch Loss= 0.3186, Training Accuracy= 0.8549, Minibatch error= 14.5%\n",
      "2017-09-03 19:39:27,781 Iter 22150, Minibatch Loss= 0.3696, Training Accuracy= 0.8565, Minibatch error= 14.3%\n",
      "2017-09-03 19:41:11,548 Epoch 221, Average loss: 0.1610, learning rate: 0.0010\n",
      "2017-09-03 19:41:11,620 Verification error= 10.9%, loss= 0.2598\n",
      "2017-09-03 19:41:23,333 Iter 22200, Minibatch Loss= 0.1929, Training Accuracy= 0.9201, Minibatch error= 8.0%\n",
      "2017-09-03 19:43:09,344 Iter 22250, Minibatch Loss= 0.2420, Training Accuracy= 0.8812, Minibatch error= 11.9%\n",
      "2017-09-03 19:44:53,564 Epoch 222, Average loss: 0.1587, learning rate: 0.0010\n",
      "2017-09-03 19:44:53,636 Verification error= 12.0%, loss= 0.2714\n",
      "2017-09-03 19:45:05,376 Iter 22300, Minibatch Loss= 0.2160, Training Accuracy= 0.9016, Minibatch error= 9.8%\n",
      "2017-09-03 19:46:51,966 Iter 22350, Minibatch Loss= 0.3716, Training Accuracy= 0.8240, Minibatch error= 17.6%\n",
      "2017-09-03 19:48:36,389 Epoch 223, Average loss: 0.1606, learning rate: 0.0010\n",
      "2017-09-03 19:48:36,461 Verification error= 12.4%, loss= 0.2791\n",
      "2017-09-03 19:48:48,176 Iter 22400, Minibatch Loss= 0.1920, Training Accuracy= 0.9253, Minibatch error= 7.5%\n",
      "2017-09-03 19:50:35,400 Iter 22450, Minibatch Loss= 0.2344, Training Accuracy= 0.8943, Minibatch error= 10.6%\n",
      "2017-09-03 19:52:20,367 Epoch 224, Average loss: 0.1584, learning rate: 0.0010\n",
      "2017-09-03 19:52:20,438 Verification error= 11.2%, loss= 0.2475\n",
      "2017-09-03 19:52:32,215 Iter 22500, Minibatch Loss= 0.2269, Training Accuracy= 0.9026, Minibatch error= 9.7%\n",
      "2017-09-03 19:54:19,904 Iter 22550, Minibatch Loss= 0.1852, Training Accuracy= 0.9260, Minibatch error= 7.4%\n",
      "2017-09-03 19:56:05,283 Epoch 225, Average loss: 0.1591, learning rate: 0.0010\n",
      "2017-09-03 19:56:05,355 Verification error= 12.2%, loss= 0.2753\n",
      "2017-09-03 19:56:17,256 Iter 22600, Minibatch Loss= 0.1886, Training Accuracy= 0.9156, Minibatch error= 8.4%\n",
      "2017-09-03 19:58:05,143 Iter 22650, Minibatch Loss= 0.2927, Training Accuracy= 0.8630, Minibatch error= 13.7%\n",
      "2017-09-03 19:59:51,182 Epoch 226, Average loss: 0.1570, learning rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 19:59:51,253 Verification error= 13.0%, loss= 0.2826\n",
      "2017-09-03 20:00:03,213 Iter 22700, Minibatch Loss= 0.3714, Training Accuracy= 0.8154, Minibatch error= 18.5%\n",
      "2017-09-03 20:01:51,846 Iter 22750, Minibatch Loss= 0.3296, Training Accuracy= 0.8516, Minibatch error= 14.8%\n",
      "2017-09-03 20:03:38,081 Epoch 227, Average loss: 0.1574, learning rate: 0.0010\n",
      "2017-09-03 20:03:38,152 Verification error= 11.6%, loss= 0.2737\n",
      "2017-09-03 20:03:50,175 Iter 22800, Minibatch Loss= 0.3816, Training Accuracy= 0.8305, Minibatch error= 17.0%\n",
      "2017-09-03 20:05:39,009 Iter 22850, Minibatch Loss= 0.2080, Training Accuracy= 0.9125, Minibatch error= 8.8%\n",
      "2017-09-03 20:07:25,889 Epoch 228, Average loss: 0.1582, learning rate: 0.0010\n",
      "2017-09-03 20:07:25,961 Verification error= 12.0%, loss= 0.2717\n",
      "2017-09-03 20:07:38,732 Iter 22900, Minibatch Loss= 0.2333, Training Accuracy= 0.8849, Minibatch error= 11.5%\n",
      "2017-09-03 20:09:28,093 Iter 22950, Minibatch Loss= 0.2131, Training Accuracy= 0.8995, Minibatch error= 10.1%\n",
      "2017-09-03 20:11:15,126 Epoch 229, Average loss: 0.1565, learning rate: 0.0010\n",
      "2017-09-03 20:11:15,197 Verification error= 13.1%, loss= 0.2809\n",
      "2017-09-03 20:11:27,284 Iter 23000, Minibatch Loss= 0.3573, Training Accuracy= 0.8211, Minibatch error= 17.9%\n",
      "2017-09-03 20:13:17,036 Iter 23050, Minibatch Loss= 0.1880, Training Accuracy= 0.9276, Minibatch error= 7.2%\n",
      "2017-09-03 20:15:04,547 Epoch 230, Average loss: 0.1545, learning rate: 0.0010\n",
      "2017-09-03 20:15:04,619 Verification error= 12.5%, loss= 0.2860\n",
      "2017-09-03 20:15:16,726 Iter 23100, Minibatch Loss= 0.2307, Training Accuracy= 0.8940, Minibatch error= 10.6%\n",
      "2017-09-03 20:17:07,579 Iter 23150, Minibatch Loss= 0.2305, Training Accuracy= 0.8992, Minibatch error= 10.1%\n",
      "2017-09-03 20:18:56,168 Epoch 231, Average loss: 0.1548, learning rate: 0.0010\n",
      "2017-09-03 20:18:56,239 Verification error= 12.5%, loss= 0.2823\n",
      "2017-09-03 20:19:08,446 Iter 23200, Minibatch Loss= 0.1892, Training Accuracy= 0.9216, Minibatch error= 7.8%\n",
      "2017-09-03 20:20:59,904 Iter 23250, Minibatch Loss= 0.1847, Training Accuracy= 0.9167, Minibatch error= 8.3%\n",
      "2017-09-03 20:22:49,026 Epoch 232, Average loss: 0.1532, learning rate: 0.0010\n",
      "2017-09-03 20:22:49,097 Verification error= 12.8%, loss= 0.3014\n",
      "2017-09-03 20:23:01,313 Iter 23300, Minibatch Loss= 0.3188, Training Accuracy= 0.8633, Minibatch error= 13.7%\n",
      "2017-09-03 20:24:53,194 Iter 23350, Minibatch Loss= 0.3866, Training Accuracy= 0.8154, Minibatch error= 18.5%\n",
      "2017-09-03 20:26:43,170 Epoch 233, Average loss: 0.1549, learning rate: 0.0010\n",
      "2017-09-03 20:26:43,241 Verification error= 11.2%, loss= 0.2752\n",
      "2017-09-03 20:26:55,525 Iter 23400, Minibatch Loss= 0.3253, Training Accuracy= 0.8560, Minibatch error= 14.4%\n",
      "2017-09-03 20:28:47,805 Iter 23450, Minibatch Loss= 0.4128, Training Accuracy= 0.8331, Minibatch error= 16.7%\n",
      "2017-09-03 20:30:38,573 Epoch 234, Average loss: 0.1543, learning rate: 0.0010\n",
      "2017-09-03 20:30:38,645 Verification error= 11.4%, loss= 0.2698\n",
      "2017-09-03 20:30:51,027 Iter 23500, Minibatch Loss= 0.1854, Training Accuracy= 0.9195, Minibatch error= 8.0%\n",
      "2017-09-03 20:32:43,775 Iter 23550, Minibatch Loss= 0.2409, Training Accuracy= 0.8807, Minibatch error= 11.9%\n",
      "2017-09-03 20:34:34,115 Epoch 235, Average loss: 0.1525, learning rate: 0.0010\n",
      "2017-09-03 20:34:34,186 Verification error= 12.3%, loss= 0.2746\n",
      "2017-09-03 20:34:46,568 Iter 23600, Minibatch Loss= 0.2151, Training Accuracy= 0.9005, Minibatch error= 9.9%\n",
      "2017-09-03 20:36:39,931 Iter 23650, Minibatch Loss= 0.3678, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-09-03 20:38:31,272 Epoch 236, Average loss: 0.1543, learning rate: 0.0010\n",
      "2017-09-03 20:38:31,343 Verification error= 12.3%, loss= 0.2819\n",
      "2017-09-03 20:38:43,742 Iter 23700, Minibatch Loss= 0.1849, Training Accuracy= 0.9279, Minibatch error= 7.2%\n",
      "2017-09-03 20:40:37,374 Iter 23750, Minibatch Loss= 0.2382, Training Accuracy= 0.8857, Minibatch error= 11.4%\n",
      "2017-09-03 20:42:28,648 Epoch 237, Average loss: 0.1517, learning rate: 0.0010\n",
      "2017-09-03 20:42:28,720 Verification error= 13.1%, loss= 0.2899\n",
      "2017-09-03 20:42:41,157 Iter 23800, Minibatch Loss= 0.2321, Training Accuracy= 0.8927, Minibatch error= 10.7%\n",
      "2017-09-03 20:44:35,121 Iter 23850, Minibatch Loss= 0.1855, Training Accuracy= 0.9318, Minibatch error= 6.8%\n",
      "2017-09-03 20:46:26,613 Epoch 238, Average loss: 0.1519, learning rate: 0.0010\n",
      "2017-09-03 20:46:26,686 Verification error= 12.2%, loss= 0.2915\n",
      "2017-09-03 20:46:40,101 Iter 23900, Minibatch Loss= 0.1781, Training Accuracy= 0.9229, Minibatch error= 7.7%\n",
      "2017-09-03 20:48:34,601 Iter 23950, Minibatch Loss= 0.3125, Training Accuracy= 0.8664, Minibatch error= 13.4%\n",
      "2017-09-03 20:50:26,922 Epoch 239, Average loss: 0.1533, learning rate: 0.0010\n",
      "2017-09-03 20:50:26,994 Verification error= 12.0%, loss= 0.2829\n",
      "2017-09-03 20:50:39,539 Iter 24000, Minibatch Loss= 0.3537, Training Accuracy= 0.8266, Minibatch error= 17.3%\n",
      "2017-09-03 20:52:34,908 Iter 24050, Minibatch Loss= 0.3389, Training Accuracy= 0.8562, Minibatch error= 14.4%\n",
      "2017-09-03 20:54:27,785 Epoch 240, Average loss: 0.1490, learning rate: 0.0010\n",
      "2017-09-03 20:54:27,856 Verification error= 11.2%, loss= 0.2827\n",
      "2017-09-03 20:54:40,557 Iter 24100, Minibatch Loss= 0.4032, Training Accuracy= 0.8354, Minibatch error= 16.5%\n",
      "2017-09-03 20:56:36,422 Iter 24150, Minibatch Loss= 0.1982, Training Accuracy= 0.9242, Minibatch error= 7.6%\n",
      "2017-09-03 20:58:29,986 Epoch 241, Average loss: 0.1521, learning rate: 0.0010\n",
      "2017-09-03 20:58:30,064 Verification error= 10.2%, loss= 0.2591\n",
      "2017-09-03 20:58:42,725 Iter 24200, Minibatch Loss= 0.2465, Training Accuracy= 0.8898, Minibatch error= 11.0%\n",
      "2017-09-03 21:00:39,037 Iter 24250, Minibatch Loss= 0.2197, Training Accuracy= 0.8984, Minibatch error= 10.2%\n",
      "2017-09-03 21:02:32,997 Epoch 242, Average loss: 0.1510, learning rate: 0.0010\n",
      "2017-09-03 21:02:33,068 Verification error= 12.3%, loss= 0.2776\n",
      "2017-09-03 21:02:46,025 Iter 24300, Minibatch Loss= 0.3456, Training Accuracy= 0.8375, Minibatch error= 16.2%\n",
      "2017-09-03 21:04:42,774 Iter 24350, Minibatch Loss= 0.1879, Training Accuracy= 0.9214, Minibatch error= 7.9%\n",
      "2017-09-03 21:06:37,589 Epoch 243, Average loss: 0.1516, learning rate: 0.0010\n",
      "2017-09-03 21:06:37,668 Verification error= 13.1%, loss= 0.2914\n",
      "2017-09-03 21:06:50,472 Iter 24400, Minibatch Loss= 0.2248, Training Accuracy= 0.8893, Minibatch error= 11.1%\n",
      "2017-09-03 21:08:47,658 Iter 24450, Minibatch Loss= 0.2416, Training Accuracy= 0.8945, Minibatch error= 10.5%\n",
      "2017-09-03 21:10:42,768 Epoch 244, Average loss: 0.1513, learning rate: 0.0010\n",
      "2017-09-03 21:10:42,840 Verification error= 11.4%, loss= 0.2735\n",
      "2017-09-03 21:10:55,821 Iter 24500, Minibatch Loss= 0.1780, Training Accuracy= 0.9305, Minibatch error= 7.0%\n",
      "2017-09-03 21:12:53,627 Iter 24550, Minibatch Loss= 0.1779, Training Accuracy= 0.9245, Minibatch error= 7.6%\n",
      "2017-09-03 21:14:48,828 Epoch 245, Average loss: 0.1505, learning rate: 0.0010\n",
      "2017-09-03 21:14:48,899 Verification error= 12.3%, loss= 0.2931\n",
      "2017-09-03 21:15:01,756 Iter 24600, Minibatch Loss= 0.3088, Training Accuracy= 0.8740, Minibatch error= 12.6%\n",
      "2017-09-03 21:17:00,038 Iter 24650, Minibatch Loss= 0.3849, Training Accuracy= 0.8227, Minibatch error= 17.7%\n",
      "2017-09-03 21:18:55,696 Epoch 246, Average loss: 0.1467, learning rate: 0.0010\n",
      "2017-09-03 21:18:55,768 Verification error= 11.0%, loss= 0.2692\n",
      "2017-09-03 21:19:08,725 Iter 24700, Minibatch Loss= 0.3296, Training Accuracy= 0.8609, Minibatch error= 13.9%\n",
      "2017-09-03 21:21:07,163 Iter 24750, Minibatch Loss= 0.3804, Training Accuracy= 0.8443, Minibatch error= 15.6%\n",
      "2017-09-03 21:23:03,349 Epoch 247, Average loss: 0.1487, learning rate: 0.0010\n",
      "2017-09-03 21:23:03,420 Verification error= 10.9%, loss= 0.2666\n",
      "2017-09-03 21:23:16,519 Iter 24800, Minibatch Loss= 0.1870, Training Accuracy= 0.9219, Minibatch error= 7.8%\n",
      "2017-09-03 21:25:15,500 Iter 24850, Minibatch Loss= 0.2263, Training Accuracy= 0.8948, Minibatch error= 10.5%\n",
      "2017-09-03 21:27:11,872 Epoch 248, Average loss: 0.1468, learning rate: 0.0010\n",
      "2017-09-03 21:27:11,944 Verification error= 12.0%, loss= 0.2740\n",
      "2017-09-03 21:27:25,834 Iter 24900, Minibatch Loss= 0.2028, Training Accuracy= 0.9049, Minibatch error= 9.5%\n",
      "2017-09-03 21:29:25,041 Iter 24950, Minibatch Loss= 0.3310, Training Accuracy= 0.8297, Minibatch error= 17.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 21:31:22,141 Epoch 249, Average loss: 0.1471, learning rate: 0.0010\n",
      "2017-09-03 21:31:22,214 Verification error= 12.1%, loss= 0.2747\n",
      "2017-09-03 21:31:35,239 Iter 25000, Minibatch Loss= 0.1774, Training Accuracy= 0.9258, Minibatch error= 7.4%\n",
      "2017-09-03 21:33:35,014 Iter 25050, Minibatch Loss= 0.2156, Training Accuracy= 0.9052, Minibatch error= 9.5%\n",
      "2017-09-03 21:35:32,337 Epoch 250, Average loss: 0.1451, learning rate: 0.0010\n",
      "2017-09-03 21:35:32,409 Verification error= 12.3%, loss= 0.2860\n",
      "2017-09-03 21:35:45,471 Iter 25100, Minibatch Loss= 0.2186, Training Accuracy= 0.9034, Minibatch error= 9.7%\n",
      "2017-09-03 21:37:45,606 Iter 25150, Minibatch Loss= 0.1688, Training Accuracy= 0.9313, Minibatch error= 6.9%\n",
      "2017-09-03 21:39:43,412 Epoch 251, Average loss: 0.1457, learning rate: 0.0010\n",
      "2017-09-03 21:39:43,483 Verification error= 11.7%, loss= 0.2750\n",
      "2017-09-03 21:39:56,675 Iter 25200, Minibatch Loss= 0.1782, Training Accuracy= 0.9242, Minibatch error= 7.6%\n",
      "2017-09-03 21:41:57,496 Iter 25250, Minibatch Loss= 0.3117, Training Accuracy= 0.8771, Minibatch error= 12.3%\n",
      "2017-09-03 21:43:55,804 Epoch 252, Average loss: 0.1425, learning rate: 0.0010\n",
      "2017-09-03 21:43:55,876 Verification error= 11.0%, loss= 0.2788\n",
      "2017-09-03 21:44:09,046 Iter 25300, Minibatch Loss= 0.3612, Training Accuracy= 0.8411, Minibatch error= 15.9%\n",
      "2017-09-03 21:46:10,207 Iter 25350, Minibatch Loss= 0.3286, Training Accuracy= 0.8536, Minibatch error= 14.6%\n",
      "2017-09-03 21:48:08,895 Epoch 253, Average loss: 0.1438, learning rate: 0.0010\n",
      "2017-09-03 21:48:08,967 Verification error= 9.7%, loss= 0.2507\n",
      "2017-09-03 21:48:22,239 Iter 25400, Minibatch Loss= 0.3443, Training Accuracy= 0.8612, Minibatch error= 13.9%\n",
      "2017-09-03 21:50:23,809 Iter 25450, Minibatch Loss= 0.1695, Training Accuracy= 0.9328, Minibatch error= 6.7%\n",
      "2017-09-03 21:52:22,867 Epoch 254, Average loss: 0.1450, learning rate: 0.0010\n",
      "2017-09-03 21:52:22,938 Verification error= 10.7%, loss= 0.2537\n",
      "2017-09-03 21:52:36,213 Iter 25500, Minibatch Loss= 0.2289, Training Accuracy= 0.8911, Minibatch error= 10.9%\n",
      "2017-09-03 21:54:38,116 Iter 25550, Minibatch Loss= 0.2086, Training Accuracy= 0.9143, Minibatch error= 8.6%\n",
      "2017-09-03 21:56:38,092 Epoch 255, Average loss: 0.1416, learning rate: 0.0010\n",
      "2017-09-03 21:56:38,163 Verification error= 11.9%, loss= 0.2809\n",
      "2017-09-03 21:56:51,585 Iter 25600, Minibatch Loss= 0.3275, Training Accuracy= 0.8534, Minibatch error= 14.7%\n",
      "2017-09-03 21:58:55,867 Iter 25650, Minibatch Loss= 0.1847, Training Accuracy= 0.9198, Minibatch error= 8.0%\n",
      "2017-09-03 22:00:55,937 Epoch 256, Average loss: 0.1431, learning rate: 0.0010\n",
      "2017-09-03 22:00:56,009 Verification error= 11.2%, loss= 0.2678\n",
      "2017-09-03 22:01:09,444 Iter 25700, Minibatch Loss= 0.2092, Training Accuracy= 0.9122, Minibatch error= 8.8%\n",
      "2017-09-03 22:03:12,610 Iter 25750, Minibatch Loss= 0.2135, Training Accuracy= 0.9104, Minibatch error= 9.0%\n",
      "2017-09-03 22:05:13,263 Epoch 257, Average loss: 0.1410, learning rate: 0.0010\n",
      "2017-09-03 22:05:13,334 Verification error= 11.6%, loss= 0.2734\n",
      "2017-09-03 22:05:26,841 Iter 25800, Minibatch Loss= 0.1693, Training Accuracy= 0.9229, Minibatch error= 7.7%\n",
      "2017-09-03 22:07:30,167 Iter 25850, Minibatch Loss= 0.1666, Training Accuracy= 0.9331, Minibatch error= 6.7%\n",
      "2017-09-03 22:09:31,038 Epoch 258, Average loss: 0.1408, learning rate: 0.0010\n",
      "2017-09-03 22:09:31,110 Verification error= 12.1%, loss= 0.2973\n",
      "2017-09-03 22:09:44,592 Iter 25900, Minibatch Loss= 0.3373, Training Accuracy= 0.8812, Minibatch error= 11.9%\n",
      "2017-09-03 22:11:48,326 Iter 25950, Minibatch Loss= 0.3839, Training Accuracy= 0.8263, Minibatch error= 17.4%\n",
      "2017-09-03 22:13:49,825 Epoch 259, Average loss: 0.1402, learning rate: 0.0010\n",
      "2017-09-03 22:13:49,900 Verification error= 10.1%, loss= 0.2564\n",
      "2017-09-03 22:14:04,216 Iter 26000, Minibatch Loss= 0.3107, Training Accuracy= 0.8755, Minibatch error= 12.4%\n",
      "2017-09-03 22:16:08,508 Iter 26050, Minibatch Loss= 0.3750, Training Accuracy= 0.8526, Minibatch error= 14.7%\n",
      "2017-09-03 22:18:10,339 Epoch 260, Average loss: 0.1414, learning rate: 0.0010\n",
      "2017-09-03 22:18:10,413 Verification error= 9.3%, loss= 0.2473\n",
      "2017-09-03 22:18:24,017 Iter 26100, Minibatch Loss= 0.1718, Training Accuracy= 0.9352, Minibatch error= 6.5%\n",
      "2017-09-03 22:20:29,270 Iter 26150, Minibatch Loss= 0.2240, Training Accuracy= 0.8966, Minibatch error= 10.3%\n",
      "2017-09-03 22:22:31,460 Epoch 261, Average loss: 0.1398, learning rate: 0.0010\n",
      "2017-09-03 22:22:31,532 Verification error= 11.2%, loss= 0.2692\n",
      "2017-09-03 22:22:45,102 Iter 26200, Minibatch Loss= 0.2039, Training Accuracy= 0.9167, Minibatch error= 8.3%\n",
      "2017-09-03 22:24:50,360 Iter 26250, Minibatch Loss= 0.2915, Training Accuracy= 0.8703, Minibatch error= 13.0%\n",
      "2017-09-03 22:26:52,859 Epoch 262, Average loss: 0.1396, learning rate: 0.0010\n",
      "2017-09-03 22:26:52,931 Verification error= 13.0%, loss= 0.3110\n",
      "2017-09-03 22:27:06,632 Iter 26300, Minibatch Loss= 0.1815, Training Accuracy= 0.9177, Minibatch error= 8.2%\n",
      "2017-09-03 22:29:12,580 Iter 26350, Minibatch Loss= 0.1991, Training Accuracy= 0.9143, Minibatch error= 8.6%\n",
      "2017-09-03 22:31:15,900 Epoch 263, Average loss: 0.1412, learning rate: 0.0010\n",
      "2017-09-03 22:31:15,980 Verification error= 11.0%, loss= 0.2592\n",
      "2017-09-03 22:31:29,701 Iter 26400, Minibatch Loss= 0.1972, Training Accuracy= 0.9242, Minibatch error= 7.6%\n",
      "2017-09-03 22:33:35,986 Iter 26450, Minibatch Loss= 0.1691, Training Accuracy= 0.9341, Minibatch error= 6.6%\n",
      "2017-09-03 22:35:39,546 Epoch 264, Average loss: 0.1423, learning rate: 0.0010\n",
      "2017-09-03 22:35:39,617 Verification error= 11.3%, loss= 0.2738\n",
      "2017-09-03 22:35:53,428 Iter 26500, Minibatch Loss= 0.1780, Training Accuracy= 0.9302, Minibatch error= 7.0%\n",
      "2017-09-03 22:38:00,012 Iter 26550, Minibatch Loss= 0.2707, Training Accuracy= 0.8951, Minibatch error= 10.5%\n",
      "2017-09-03 22:40:03,961 Epoch 265, Average loss: 0.1387, learning rate: 0.0010\n",
      "2017-09-03 22:40:04,033 Verification error= 10.6%, loss= 0.2645\n",
      "2017-09-03 22:40:17,808 Iter 26600, Minibatch Loss= 0.3566, Training Accuracy= 0.8341, Minibatch error= 16.6%\n",
      "2017-09-03 22:42:24,656 Iter 26650, Minibatch Loss= 0.3293, Training Accuracy= 0.8609, Minibatch error= 13.9%\n",
      "2017-09-03 22:44:28,823 Epoch 266, Average loss: 0.1388, learning rate: 0.0010\n",
      "2017-09-03 22:44:28,896 Verification error= 9.3%, loss= 0.2515\n",
      "2017-09-03 22:44:42,780 Iter 26700, Minibatch Loss= 0.3605, Training Accuracy= 0.8555, Minibatch error= 14.1%\n",
      "2017-09-03 22:46:49,945 Iter 26750, Minibatch Loss= 0.1660, Training Accuracy= 0.9307, Minibatch error= 5.8%\n",
      "2017-09-03 22:48:54,542 Epoch 267, Average loss: 0.1390, learning rate: 0.0010\n",
      "2017-09-03 22:48:54,613 Verification error= 9.4%, loss= 0.2358\n",
      "2017-09-03 22:49:08,559 Iter 26800, Minibatch Loss= 0.1956, Training Accuracy= 0.9161, Minibatch error= 8.2%\n",
      "2017-09-03 22:51:16,342 Iter 26850, Minibatch Loss= 0.1777, Training Accuracy= 0.9039, Minibatch error= 7.4%\n",
      "2017-09-03 22:53:21,753 Epoch 268, Average loss: 0.1379, learning rate: 0.0010\n",
      "2017-09-03 22:53:21,825 Verification error= 11.7%, loss= 0.2792\n",
      "2017-09-03 22:53:35,843 Iter 26900, Minibatch Loss= 0.2998, Training Accuracy= 0.8635, Minibatch error= 12.7%\n",
      "2017-09-03 22:55:43,925 Iter 26950, Minibatch Loss= 0.1733, Training Accuracy= 0.8904, Minibatch error= 8.1%\n",
      "2017-09-03 22:57:50,098 Epoch 269, Average loss: 0.1394, learning rate: 0.0010\n",
      "2017-09-03 22:57:50,171 Verification error= 13.8%, loss= 0.3253\n",
      "2017-09-03 22:58:05,041 Iter 27000, Minibatch Loss= 0.2078, Training Accuracy= 0.8898, Minibatch error= 9.2%\n",
      "2017-09-03 23:00:13,882 Iter 27050, Minibatch Loss= 0.2152, Training Accuracy= 0.8992, Minibatch error= 9.1%\n",
      "2017-09-03 23:02:19,962 Epoch 270, Average loss: 0.1398, learning rate: 0.0010\n",
      "2017-09-03 23:02:20,034 Verification error= 10.4%, loss= 0.2563\n",
      "2017-09-03 23:02:34,108 Iter 27100, Minibatch Loss= 0.1529, Training Accuracy= 0.9224, Minibatch error= 5.3%\n",
      "2017-09-03 23:04:43,569 Iter 27150, Minibatch Loss= 0.1646, Training Accuracy= 0.9328, Minibatch error= 6.6%\n",
      "2017-09-03 23:06:50,085 Epoch 271, Average loss: 0.1368, learning rate: 0.0010\n",
      "2017-09-03 23:06:50,157 Verification error= 9.5%, loss= 0.2390\n",
      "2017-09-03 23:07:04,267 Iter 27200, Minibatch Loss= 0.2394, Training Accuracy= 0.8990, Minibatch error= 8.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-03 23:09:13,669 Iter 27250, Minibatch Loss= 0.3685, Training Accuracy= 0.8039, Minibatch error= 16.9%\n",
      "2017-09-03 23:11:20,619 Epoch 272, Average loss: 0.1372, learning rate: 0.0010\n",
      "2017-09-03 23:11:20,691 Verification error= 9.8%, loss= 0.2609\n",
      "2017-09-03 23:11:34,890 Iter 27300, Minibatch Loss= 0.3208, Training Accuracy= 0.8367, Minibatch error= 13.4%\n",
      "2017-09-03 23:13:44,888 Iter 27350, Minibatch Loss= 0.3516, Training Accuracy= 0.8294, Minibatch error= 13.6%\n",
      "2017-09-03 23:15:52,109 Epoch 273, Average loss: 0.1377, learning rate: 0.0010\n",
      "2017-09-03 23:15:52,180 Verification error= 9.0%, loss= 0.2396\n",
      "2017-09-03 23:16:06,623 Iter 27400, Minibatch Loss= 0.1681, Training Accuracy= 0.9057, Minibatch error= 5.9%\n",
      "2017-09-03 23:18:16,969 Iter 27450, Minibatch Loss= 0.2032, Training Accuracy= 0.8898, Minibatch error= 8.4%\n",
      "2017-09-03 23:20:24,739 Epoch 274, Average loss: 0.1364, learning rate: 0.0010\n",
      "2017-09-03 23:20:24,810 Verification error= 10.8%, loss= 0.2747\n",
      "2017-09-03 23:20:39,125 Iter 27500, Minibatch Loss= 0.1919, Training Accuracy= 0.8924, Minibatch error= 7.4%\n",
      "2017-09-03 23:22:49,987 Iter 27550, Minibatch Loss= 0.3042, Training Accuracy= 0.8388, Minibatch error= 13.3%\n",
      "2017-09-03 23:24:58,247 Epoch 275, Average loss: 0.1365, learning rate: 0.0010\n",
      "2017-09-03 23:24:58,319 Verification error= 12.5%, loss= 0.2977\n",
      "2017-09-03 23:25:12,661 Iter 27600, Minibatch Loss= 0.1828, Training Accuracy= 0.8789, Minibatch error= 8.1%\n",
      "2017-09-03 23:27:24,066 Iter 27650, Minibatch Loss= 0.1910, Training Accuracy= 0.8810, Minibatch error= 8.3%\n",
      "2017-09-03 23:29:32,644 Epoch 276, Average loss: 0.1381, learning rate: 0.0010\n",
      "2017-09-03 23:29:32,715 Verification error= 12.5%, loss= 0.3073\n",
      "2017-09-03 23:29:47,139 Iter 27700, Minibatch Loss= 0.2239, Training Accuracy= 0.8651, Minibatch error= 9.7%\n",
      "2017-09-03 23:31:59,086 Iter 27750, Minibatch Loss= 0.1900, Training Accuracy= 0.8878, Minibatch error= 7.0%\n",
      "2017-09-03 23:34:08,093 Epoch 277, Average loss: 0.1359, learning rate: 0.0010\n",
      "2017-09-03 23:34:08,165 Verification error= 9.8%, loss= 0.2435\n",
      "2017-09-03 23:34:22,520 Iter 27800, Minibatch Loss= 0.1649, Training Accuracy= 0.9062, Minibatch error= 6.0%\n",
      "2017-09-03 23:36:35,163 Iter 27850, Minibatch Loss= 0.2586, Training Accuracy= 0.8737, Minibatch error= 8.8%\n",
      "2017-09-03 23:38:45,242 Epoch 278, Average loss: 0.1377, learning rate: 0.0010\n",
      "2017-09-03 23:38:45,314 Verification error= 10.5%, loss= 0.2661\n",
      "2017-09-03 23:38:59,713 Iter 27900, Minibatch Loss= 0.4008, Training Accuracy= 0.8060, Minibatch error= 15.5%\n",
      "2017-09-03 23:41:12,459 Iter 27950, Minibatch Loss= 0.3321, Training Accuracy= 0.8260, Minibatch error= 13.5%\n",
      "2017-09-03 23:43:22,639 Epoch 279, Average loss: 0.1347, learning rate: 0.0010\n",
      "2017-09-03 23:43:22,711 Verification error= 9.7%, loss= 0.2514\n",
      "2017-09-03 23:43:38,111 Iter 28000, Minibatch Loss= 0.3634, Training Accuracy= 0.8198, Minibatch error= 14.2%\n",
      "2017-09-03 23:45:51,394 Iter 28050, Minibatch Loss= 0.1748, Training Accuracy= 0.9044, Minibatch error= 5.7%\n",
      "2017-09-03 23:48:01,936 Epoch 280, Average loss: 0.1356, learning rate: 0.0010\n",
      "2017-09-03 23:48:02,007 Verification error= 9.6%, loss= 0.2476\n",
      "2017-09-03 23:48:16,643 Iter 28100, Minibatch Loss= 0.1866, Training Accuracy= 0.8867, Minibatch error= 7.3%\n",
      "2017-09-03 23:50:30,354 Iter 28150, Minibatch Loss= 0.1915, Training Accuracy= 0.8734, Minibatch error= 8.4%\n",
      "2017-09-03 23:52:41,323 Epoch 281, Average loss: 0.1347, learning rate: 0.0010\n",
      "2017-09-03 23:52:41,395 Verification error= 12.1%, loss= 0.2902\n",
      "2017-09-03 23:52:55,943 Iter 28200, Minibatch Loss= 0.3292, Training Accuracy= 0.8146, Minibatch error= 14.5%\n",
      "2017-09-03 23:55:10,242 Iter 28250, Minibatch Loss= 0.1737, Training Accuracy= 0.8617, Minibatch error= 7.6%\n",
      "2017-09-03 23:57:21,681 Epoch 282, Average loss: 0.1363, learning rate: 0.0010\n",
      "2017-09-03 23:57:21,755 Verification error= 12.3%, loss= 0.2988\n",
      "2017-09-03 23:57:36,401 Iter 28300, Minibatch Loss= 0.1916, Training Accuracy= 0.8638, Minibatch error= 8.4%\n",
      "2017-09-03 23:59:50,721 Iter 28350, Minibatch Loss= 0.1998, Training Accuracy= 0.8508, Minibatch error= 8.0%\n",
      "2017-09-04 00:02:02,380 Epoch 283, Average loss: 0.1348, learning rate: 0.0010\n",
      "2017-09-04 00:02:02,452 Verification error= 11.9%, loss= 0.2920\n",
      "2017-09-04 00:02:17,121 Iter 28400, Minibatch Loss= 0.1740, Training Accuracy= 0.8779, Minibatch error= 6.9%\n",
      "2017-09-04 00:04:32,125 Iter 28450, Minibatch Loss= 0.1785, Training Accuracy= 0.8859, Minibatch error= 7.2%\n",
      "2017-09-04 00:06:44,519 Epoch 284, Average loss: 0.1331, learning rate: 0.0010\n",
      "2017-09-04 00:06:44,592 Verification error= 9.3%, loss= 0.2380\n",
      "2017-09-04 00:06:59,326 Iter 28500, Minibatch Loss= 0.2560, Training Accuracy= 0.8667, Minibatch error= 8.6%\n",
      "2017-09-04 00:09:14,738 Iter 28550, Minibatch Loss= 0.2875, Training Accuracy= 0.8086, Minibatch error= 14.1%\n",
      "2017-09-04 00:11:27,906 Epoch 285, Average loss: 0.1350, learning rate: 0.0010\n",
      "2017-09-04 00:11:27,977 Verification error= 8.6%, loss= 0.2350\n",
      "2017-09-04 00:11:42,755 Iter 28600, Minibatch Loss= 0.2881, Training Accuracy= 0.8391, Minibatch error= 11.2%\n",
      "2017-09-04 00:13:58,731 Iter 28650, Minibatch Loss= 0.3728, Training Accuracy= 0.8148, Minibatch error= 13.4%\n",
      "2017-09-04 00:16:11,953 Epoch 286, Average loss: 0.1329, learning rate: 0.0010\n",
      "2017-09-04 00:16:12,025 Verification error= 8.6%, loss= 0.2422\n",
      "2017-09-04 00:16:26,917 Iter 28700, Minibatch Loss= 0.1602, Training Accuracy= 0.8854, Minibatch error= 5.6%\n",
      "2017-09-04 00:18:43,513 Iter 28750, Minibatch Loss= 0.1923, Training Accuracy= 0.8701, Minibatch error= 8.1%\n",
      "2017-09-04 00:20:57,396 Epoch 287, Average loss: 0.1319, learning rate: 0.0010\n",
      "2017-09-04 00:20:57,467 Verification error= 10.3%, loss= 0.2786\n",
      "2017-09-04 00:21:12,371 Iter 28800, Minibatch Loss= 0.2156, Training Accuracy= 0.8263, Minibatch error= 8.4%\n",
      "2017-09-04 00:23:29,367 Iter 28850, Minibatch Loss= 0.3838, Training Accuracy= 0.8221, Minibatch error= 12.5%\n",
      "2017-09-04 00:25:43,634 Epoch 288, Average loss: 0.1306, learning rate: 0.0010\n",
      "2017-09-04 00:25:43,708 Verification error= 11.5%, loss= 0.2818\n",
      "2017-09-04 00:25:58,672 Iter 28900, Minibatch Loss= 0.1779, Training Accuracy= 0.8484, Minibatch error= 7.9%\n",
      "2017-09-04 00:28:16,070 Iter 28950, Minibatch Loss= 0.1952, Training Accuracy= 0.8414, Minibatch error= 8.6%\n",
      "2017-09-04 00:30:30,732 Epoch 289, Average loss: 0.1321, learning rate: 0.0010\n",
      "2017-09-04 00:30:30,804 Verification error= 10.7%, loss= 0.2739\n",
      "2017-09-04 00:30:46,701 Iter 29000, Minibatch Loss= 0.1981, Training Accuracy= 0.8169, Minibatch error= 7.8%\n",
      "2017-09-04 00:33:04,746 Iter 29050, Minibatch Loss= 0.1831, Training Accuracy= 0.8005, Minibatch error= 6.7%\n",
      "2017-09-04 00:35:19,926 Epoch 290, Average loss: 0.1314, learning rate: 0.0010\n",
      "2017-09-04 00:35:19,998 Verification error= 10.4%, loss= 0.2668\n",
      "2017-09-04 00:35:35,133 Iter 29100, Minibatch Loss= 0.1597, Training Accuracy= 0.8505, Minibatch error= 5.8%\n",
      "2017-09-04 00:37:53,467 Iter 29150, Minibatch Loss= 0.3487, Training Accuracy= 0.8091, Minibatch error= 9.7%\n",
      "2017-09-04 00:40:09,587 Epoch 291, Average loss: 0.1306, learning rate: 0.0010\n",
      "2017-09-04 00:40:09,660 Verification error= 10.1%, loss= 0.2616\n",
      "2017-09-04 00:40:24,677 Iter 29200, Minibatch Loss= 0.3428, Training Accuracy= 0.7529, Minibatch error= 15.6%\n",
      "2017-09-04 00:42:43,346 Iter 29250, Minibatch Loss= 0.3212, Training Accuracy= 0.7810, Minibatch error= 12.7%\n",
      "2017-09-04 00:44:59,268 Epoch 292, Average loss: 0.1310, learning rate: 0.0010\n",
      "2017-09-04 00:44:59,340 Verification error= 8.3%, loss= 0.2312\n",
      "2017-09-04 00:45:14,427 Iter 29300, Minibatch Loss= 0.3516, Training Accuracy= 0.7747, Minibatch error= 12.5%\n",
      "2017-09-04 00:47:33,914 Iter 29350, Minibatch Loss= 0.1537, Training Accuracy= 0.8375, Minibatch error= 6.0%\n",
      "2017-09-04 00:49:50,213 Epoch 293, Average loss: 0.1311, learning rate: 0.0010\n",
      "2017-09-04 00:49:50,285 Verification error= 10.7%, loss= 0.3010\n",
      "2017-09-04 00:50:05,469 Iter 29400, Minibatch Loss= 0.1960, Training Accuracy= 0.8042, Minibatch error= 7.9%\n",
      "2017-09-04 00:52:25,394 Iter 29450, Minibatch Loss= 0.1993, Training Accuracy= 0.7732, Minibatch error= 8.8%\n",
      "2017-09-04 00:54:41,773 Epoch 294, Average loss: 0.1277, learning rate: 0.0010\n",
      "2017-09-04 00:54:41,853 Verification error= 11.9%, loss= 0.3063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 00:54:57,036 Iter 29500, Minibatch Loss= 0.4004, Training Accuracy= 0.7758, Minibatch error= 11.5%\n",
      "2017-09-04 00:57:17,310 Iter 29550, Minibatch Loss= 0.1986, Training Accuracy= 0.8005, Minibatch error= 8.7%\n",
      "2017-09-04 00:59:34,534 Epoch 295, Average loss: 0.1292, learning rate: 0.0010\n",
      "2017-09-04 00:59:34,606 Verification error= 11.9%, loss= 0.2904\n",
      "2017-09-04 00:59:49,895 Iter 29600, Minibatch Loss= 0.1971, Training Accuracy= 0.7872, Minibatch error= 8.5%\n",
      "2017-09-04 01:02:11,552 Iter 29650, Minibatch Loss= 0.2274, Training Accuracy= 0.7589, Minibatch error= 9.7%\n",
      "2017-09-04 01:04:29,092 Epoch 296, Average loss: 0.1302, learning rate: 0.0010\n",
      "2017-09-04 01:04:29,164 Verification error= 12.0%, loss= 0.3534\n",
      "2017-09-04 01:04:44,427 Iter 29700, Minibatch Loss= 0.2247, Training Accuracy= 0.7419, Minibatch error= 7.3%\n",
      "2017-09-04 01:07:05,229 Iter 29750, Minibatch Loss= 0.1938, Training Accuracy= 0.7870, Minibatch error= 8.0%\n",
      "2017-09-04 01:09:23,720 Epoch 297, Average loss: 0.1300, learning rate: 0.0010\n",
      "2017-09-04 01:09:23,792 Verification error= 9.8%, loss= 0.2510\n",
      "2017-09-04 01:09:39,124 Iter 29800, Minibatch Loss= 0.3824, Training Accuracy= 0.7799, Minibatch error= 9.2%\n",
      "2017-09-04 01:12:00,876 Iter 29850, Minibatch Loss= 0.3979, Training Accuracy= 0.7224, Minibatch error= 16.1%\n",
      "2017-09-04 01:14:19,624 Epoch 298, Average loss: 0.1292, learning rate: 0.0010\n",
      "2017-09-04 01:14:19,696 Verification error= 9.2%, loss= 0.2447\n",
      "2017-09-04 01:14:35,114 Iter 29900, Minibatch Loss= 0.3090, Training Accuracy= 0.7674, Minibatch error= 11.9%\n",
      "2017-09-04 01:16:56,757 Iter 29950, Minibatch Loss= 0.3592, Training Accuracy= 0.7552, Minibatch error= 12.5%\n",
      "2017-09-04 01:19:15,644 Epoch 299, Average loss: 0.1308, learning rate: 0.0010\n",
      "2017-09-04 01:19:15,716 Verification error= 9.9%, loss= 0.2741\n",
      "2017-09-04 01:19:31,220 Iter 30000, Minibatch Loss= 0.1610, Training Accuracy= 0.8109, Minibatch error= 6.5%\n",
      "2017-09-04 01:21:53,369 Iter 30050, Minibatch Loss= 0.1849, Training Accuracy= 0.8102, Minibatch error= 7.0%\n",
      "2017-09-04 01:24:12,852 Epoch 300, Average loss: 0.1277, learning rate: 0.0010\n",
      "2017-09-04 01:24:12,924 Verification error= 10.8%, loss= 0.2674\n",
      "2017-09-04 01:24:29,361 Iter 30100, Minibatch Loss= 0.1856, Training Accuracy= 0.7802, Minibatch error= 7.9%\n",
      "2017-09-04 01:26:52,627 Iter 30150, Minibatch Loss= 0.2846, Training Accuracy= 0.7797, Minibatch error= 11.6%\n",
      "2017-09-04 01:29:12,536 Epoch 301, Average loss: 0.1294, learning rate: 0.0010\n",
      "2017-09-04 01:29:12,610 Verification error= 12.7%, loss= 0.3249\n",
      "2017-09-04 01:29:28,226 Iter 30200, Minibatch Loss= 0.1830, Training Accuracy= 0.8018, Minibatch error= 8.2%\n",
      "2017-09-04 01:31:51,461 Iter 30250, Minibatch Loss= 0.1944, Training Accuracy= 0.7917, Minibatch error= 8.8%\n",
      "2017-09-04 01:34:11,813 Epoch 302, Average loss: 0.1281, learning rate: 0.0010\n",
      "2017-09-04 01:34:11,885 Verification error= 10.8%, loss= 0.2839\n",
      "2017-09-04 01:34:27,449 Iter 30300, Minibatch Loss= 0.2035, Training Accuracy= 0.7742, Minibatch error= 8.3%\n",
      "2017-09-04 01:36:51,180 Iter 30350, Minibatch Loss= 0.1842, Training Accuracy= 0.7701, Minibatch error= 6.4%\n",
      "2017-09-04 01:39:12,059 Epoch 303, Average loss: 0.1293, learning rate: 0.0010\n",
      "2017-09-04 01:39:12,131 Verification error= 11.1%, loss= 0.2862\n",
      "2017-09-04 01:39:27,844 Iter 30400, Minibatch Loss= 0.1766, Training Accuracy= 0.8000, Minibatch error= 7.8%\n",
      "2017-09-04 01:41:51,945 Iter 30450, Minibatch Loss= 0.2922, Training Accuracy= 0.7711, Minibatch error= 10.1%\n",
      "2017-09-04 01:44:13,024 Epoch 304, Average loss: 0.1268, learning rate: 0.0010\n",
      "2017-09-04 01:44:13,096 Verification error= 9.9%, loss= 0.2778\n",
      "2017-09-04 01:44:28,801 Iter 30500, Minibatch Loss= 0.4394, Training Accuracy= 0.7268, Minibatch error= 15.5%\n",
      "2017-09-04 01:46:53,268 Iter 30550, Minibatch Loss= 0.3372, Training Accuracy= 0.7456, Minibatch error= 13.7%\n",
      "2017-09-04 01:49:14,924 Epoch 305, Average loss: 0.1297, learning rate: 0.0010\n",
      "2017-09-04 01:49:14,998 Verification error= 10.0%, loss= 0.2603\n",
      "2017-09-04 01:49:30,808 Iter 30600, Minibatch Loss= 0.3899, Training Accuracy= 0.7401, Minibatch error= 14.7%\n",
      "2017-09-04 01:51:55,807 Iter 30650, Minibatch Loss= 0.1436, Training Accuracy= 0.8232, Minibatch error= 4.9%\n",
      "2017-09-04 01:54:18,100 Epoch 306, Average loss: 0.1274, learning rate: 0.0010\n",
      "2017-09-04 01:54:18,172 Verification error= 11.1%, loss= 0.3117\n",
      "2017-09-04 01:54:34,031 Iter 30700, Minibatch Loss= 0.1918, Training Accuracy= 0.8055, Minibatch error= 6.8%\n",
      "2017-09-04 01:56:59,628 Iter 30750, Minibatch Loss= 0.1869, Training Accuracy= 0.7659, Minibatch error= 8.0%\n",
      "2017-09-04 01:59:22,237 Epoch 307, Average loss: 0.1287, learning rate: 0.0010\n",
      "2017-09-04 01:59:22,310 Verification error= 11.1%, loss= 0.2905\n",
      "2017-09-04 01:59:38,167 Iter 30800, Minibatch Loss= 0.3371, Training Accuracy= 0.7656, Minibatch error= 11.0%\n",
      "2017-09-04 02:02:04,222 Iter 30850, Minibatch Loss= 0.1863, Training Accuracy= 0.7781, Minibatch error= 8.7%\n",
      "2017-09-04 02:04:27,461 Epoch 308, Average loss: 0.1272, learning rate: 0.0010\n",
      "2017-09-04 02:04:27,532 Verification error= 12.1%, loss= 0.3263\n",
      "2017-09-04 02:04:43,469 Iter 30900, Minibatch Loss= 0.1966, Training Accuracy= 0.7742, Minibatch error= 8.0%\n",
      "2017-09-04 02:07:10,259 Iter 30950, Minibatch Loss= 0.2199, Training Accuracy= 0.7409, Minibatch error= 9.1%\n",
      "2017-09-04 02:09:33,631 Epoch 309, Average loss: 0.1267, learning rate: 0.0010\n",
      "2017-09-04 02:09:33,702 Verification error= 10.8%, loss= 0.2816\n",
      "2017-09-04 02:09:49,677 Iter 31000, Minibatch Loss= 0.1779, Training Accuracy= 0.7625, Minibatch error= 6.2%\n",
      "2017-09-04 02:12:16,408 Iter 31050, Minibatch Loss= 0.1803, Training Accuracy= 0.7760, Minibatch error= 7.1%\n",
      "2017-09-04 02:14:40,542 Epoch 310, Average loss: 0.1274, learning rate: 0.0010\n",
      "2017-09-04 02:14:40,613 Verification error= 11.2%, loss= 0.2981\n",
      "2017-09-04 02:14:57,600 Iter 31100, Minibatch Loss= 0.2987, Training Accuracy= 0.7490, Minibatch error= 10.2%\n",
      "2017-09-04 02:17:24,788 Iter 31150, Minibatch Loss= 0.3905, Training Accuracy= 0.7208, Minibatch error= 15.2%\n",
      "2017-09-04 02:19:48,875 Epoch 311, Average loss: 0.1232, learning rate: 0.0010\n",
      "2017-09-04 02:19:48,947 Verification error= 9.3%, loss= 0.2567\n",
      "2017-09-04 02:20:05,063 Iter 31200, Minibatch Loss= 0.3409, Training Accuracy= 0.7328, Minibatch error= 12.2%\n",
      "2017-09-04 02:22:32,854 Iter 31250, Minibatch Loss= 0.4098, Training Accuracy= 0.7542, Minibatch error= 13.6%\n",
      "2017-09-04 02:24:57,652 Epoch 312, Average loss: 0.1257, learning rate: 0.0010\n",
      "2017-09-04 02:24:57,725 Verification error= 8.8%, loss= 0.2433\n",
      "2017-09-04 02:25:13,893 Iter 31300, Minibatch Loss= 0.1354, Training Accuracy= 0.7883, Minibatch error= 5.2%\n",
      "2017-09-04 02:27:41,983 Iter 31350, Minibatch Loss= 0.1698, Training Accuracy= 0.7786, Minibatch error= 6.3%\n",
      "2017-09-04 02:30:06,906 Epoch 313, Average loss: 0.1240, learning rate: 0.0010\n",
      "2017-09-04 02:30:06,977 Verification error= 10.2%, loss= 0.2803\n",
      "2017-09-04 02:30:23,087 Iter 31400, Minibatch Loss= 0.1747, Training Accuracy= 0.7432, Minibatch error= 7.2%\n",
      "2017-09-04 02:32:51,628 Iter 31450, Minibatch Loss= 0.4357, Training Accuracy= 0.7323, Minibatch error= 12.0%\n",
      "2017-09-04 02:35:17,163 Epoch 314, Average loss: 0.1241, learning rate: 0.0010\n",
      "2017-09-04 02:35:17,235 Verification error= 10.6%, loss= 0.2830\n",
      "2017-09-04 02:35:33,460 Iter 31500, Minibatch Loss= 0.1814, Training Accuracy= 0.7862, Minibatch error= 7.9%\n",
      "2017-09-04 02:38:02,496 Iter 31550, Minibatch Loss= 0.1776, Training Accuracy= 0.7570, Minibatch error= 7.7%\n",
      "2017-09-04 02:40:28,514 Epoch 315, Average loss: 0.1232, learning rate: 0.0010\n",
      "2017-09-04 02:40:28,585 Verification error= 11.0%, loss= 0.3302\n",
      "2017-09-04 02:40:44,824 Iter 31600, Minibatch Loss= 0.1870, Training Accuracy= 0.7589, Minibatch error= 7.1%\n",
      "2017-09-04 02:43:14,285 Iter 31650, Minibatch Loss= 0.1611, Training Accuracy= 0.7359, Minibatch error= 6.2%\n",
      "2017-09-04 02:45:41,017 Epoch 316, Average loss: 0.1205, learning rate: 0.0010\n",
      "2017-09-04 02:45:41,088 Verification error= 10.0%, loss= 0.3329\n",
      "2017-09-04 02:45:57,591 Iter 31700, Minibatch Loss= 0.1888, Training Accuracy= 0.7380, Minibatch error= 6.6%\n",
      "2017-09-04 02:48:27,287 Iter 31750, Minibatch Loss= 0.4346, Training Accuracy= 0.7406, Minibatch error= 9.2%\n",
      "2017-09-04 02:50:54,250 Epoch 317, Average loss: 0.1193, learning rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 02:50:54,323 Verification error= 8.6%, loss= 0.2533\n",
      "2017-09-04 02:51:11,069 Iter 31800, Minibatch Loss= 0.3950, Training Accuracy= 0.7411, Minibatch error= 13.0%\n",
      "2017-09-04 02:53:41,407 Iter 31850, Minibatch Loss= 0.2792, Training Accuracy= 0.7654, Minibatch error= 10.0%\n",
      "2017-09-04 02:56:08,836 Epoch 318, Average loss: 0.1207, learning rate: 0.0010\n",
      "2017-09-04 02:56:08,912 Verification error= 8.0%, loss= 0.2344\n",
      "2017-09-04 02:56:25,882 Iter 31900, Minibatch Loss= 0.3782, Training Accuracy= 0.7310, Minibatch error= 13.0%\n",
      "2017-09-04 02:58:56,707 Iter 31950, Minibatch Loss= 0.1546, Training Accuracy= 0.7878, Minibatch error= 6.3%\n",
      "2017-09-04 03:01:24,869 Epoch 319, Average loss: 0.1208, learning rate: 0.0010\n",
      "2017-09-04 03:01:24,950 Verification error= 9.0%, loss= 0.2820\n",
      "2017-09-04 03:01:42,101 Iter 32000, Minibatch Loss= 0.1813, Training Accuracy= 0.7784, Minibatch error= 5.9%\n",
      "2017-09-04 03:04:13,452 Iter 32050, Minibatch Loss= 0.2325, Training Accuracy= 0.7073, Minibatch error= 8.6%\n",
      "2017-09-04 03:06:41,543 Epoch 320, Average loss: 0.1199, learning rate: 0.0010\n",
      "2017-09-04 03:06:41,615 Verification error= 11.4%, loss= 0.3879\n",
      "2017-09-04 03:06:58,865 Iter 32100, Minibatch Loss= 0.5290, Training Accuracy= 0.7151, Minibatch error= 12.3%\n",
      "2017-09-04 03:09:30,706 Iter 32150, Minibatch Loss= 0.1745, Training Accuracy= 0.7607, Minibatch error= 8.0%\n",
      "2017-09-04 03:11:59,309 Epoch 321, Average loss: 0.1181, learning rate: 0.0010\n",
      "2017-09-04 03:11:59,380 Verification error= 12.7%, loss= 0.3877\n",
      "2017-09-04 03:12:17,965 Iter 32200, Minibatch Loss= 0.2008, Training Accuracy= 0.7255, Minibatch error= 9.1%\n",
      "2017-09-04 03:14:49,820 Iter 32250, Minibatch Loss= 0.2038, Training Accuracy= 0.7451, Minibatch error= 8.1%\n",
      "2017-09-04 03:17:19,228 Epoch 322, Average loss: 0.1175, learning rate: 0.0010\n",
      "2017-09-04 03:17:19,300 Verification error= 11.1%, loss= 0.3565\n",
      "2017-09-04 03:17:36,809 Iter 32300, Minibatch Loss= 0.1770, Training Accuracy= 0.7326, Minibatch error= 6.9%\n",
      "2017-09-04 03:20:09,230 Iter 32350, Minibatch Loss= 0.1684, Training Accuracy= 0.7622, Minibatch error= 6.0%\n",
      "2017-09-04 03:22:38,725 Epoch 323, Average loss: 0.1169, learning rate: 0.0010\n",
      "2017-09-04 03:22:38,797 Verification error= 8.8%, loss= 0.2682\n",
      "2017-09-04 03:22:56,379 Iter 32400, Minibatch Loss= 0.3807, Training Accuracy= 0.7456, Minibatch error= 8.7%\n",
      "2017-09-04 03:25:29,683 Iter 32450, Minibatch Loss= 0.3864, Training Accuracy= 0.7245, Minibatch error= 13.2%\n",
      "2017-09-04 03:27:59,955 Epoch 324, Average loss: 0.1182, learning rate: 0.0010\n",
      "2017-09-04 03:28:00,027 Verification error= 9.0%, loss= 0.2782\n",
      "2017-09-04 03:28:17,704 Iter 32500, Minibatch Loss= 0.3864, Training Accuracy= 0.7198, Minibatch error= 12.9%\n",
      "2017-09-04 03:30:51,159 Iter 32550, Minibatch Loss= 0.4382, Training Accuracy= 0.7172, Minibatch error= 13.4%\n",
      "2017-09-04 03:33:21,766 Epoch 325, Average loss: 0.1175, learning rate: 0.0010\n",
      "2017-09-04 03:33:21,838 Verification error= 7.2%, loss= 0.2172\n",
      "2017-09-04 03:33:38,833 Iter 32600, Minibatch Loss= 0.1343, Training Accuracy= 0.7896, Minibatch error= 4.9%\n",
      "2017-09-04 03:36:12,949 Iter 32650, Minibatch Loss= 0.1721, Training Accuracy= 0.7781, Minibatch error= 5.4%\n",
      "2017-09-04 03:38:44,557 Epoch 326, Average loss: 0.1156, learning rate: 0.0010\n",
      "2017-09-04 03:38:44,629 Verification error= 9.3%, loss= 0.2895\n",
      "2017-09-04 03:39:01,740 Iter 32700, Minibatch Loss= 0.2080, Training Accuracy= 0.7148, Minibatch error= 8.0%\n",
      "2017-09-04 03:41:36,359 Iter 32750, Minibatch Loss= 0.5526, Training Accuracy= 0.7336, Minibatch error= 10.8%\n",
      "2017-09-04 03:44:07,730 Epoch 327, Average loss: 0.1157, learning rate: 0.0010\n",
      "2017-09-04 03:44:07,802 Verification error= 10.5%, loss= 0.3325\n",
      "2017-09-04 03:44:24,762 Iter 32800, Minibatch Loss= 0.1902, Training Accuracy= 0.7513, Minibatch error= 8.4%\n",
      "2017-09-04 03:46:59,563 Iter 32850, Minibatch Loss= 0.1968, Training Accuracy= 0.7414, Minibatch error= 9.1%\n",
      "2017-09-04 03:49:31,108 Epoch 328, Average loss: 0.1155, learning rate: 0.0010\n",
      "2017-09-04 03:49:31,179 Verification error= 9.8%, loss= 0.4065\n",
      "2017-09-04 03:49:48,171 Iter 32900, Minibatch Loss= 0.2033, Training Accuracy= 0.7312, Minibatch error= 7.5%\n",
      "2017-09-04 03:52:23,752 Iter 32950, Minibatch Loss= 0.1613, Training Accuracy= 0.7302, Minibatch error= 5.7%\n",
      "2017-09-04 03:54:55,672 Epoch 329, Average loss: 0.1170, learning rate: 0.0010\n",
      "2017-09-04 03:54:55,746 Verification error= 9.4%, loss= 0.3479\n",
      "2017-09-04 03:55:12,812 Iter 33000, Minibatch Loss= 0.1827, Training Accuracy= 0.7336, Minibatch error= 6.6%\n",
      "2017-09-04 03:57:48,486 Iter 33050, Minibatch Loss= 0.6289, Training Accuracy= 0.7375, Minibatch error= 8.5%\n",
      "2017-09-04 04:00:21,179 Epoch 330, Average loss: 0.1159, learning rate: 0.0010\n",
      "2017-09-04 04:00:21,253 Verification error= 9.1%, loss= 0.4684\n",
      "2017-09-04 04:00:38,308 Iter 33100, Minibatch Loss= 0.7527, Training Accuracy= 0.6940, Minibatch error= 14.2%\n",
      "2017-09-04 04:03:14,793 Iter 33150, Minibatch Loss= 0.3150, Training Accuracy= 0.7477, Minibatch error= 10.2%\n",
      "2017-09-04 04:05:47,907 Epoch 331, Average loss: 0.1154, learning rate: 0.0010\n",
      "2017-09-04 04:05:47,979 Verification error= 7.3%, loss= 0.2324\n",
      "2017-09-04 04:06:06,049 Iter 33200, Minibatch Loss= 0.4024, Training Accuracy= 0.7320, Minibatch error= 11.9%\n",
      "2017-09-04 04:08:42,714 Iter 33250, Minibatch Loss= 0.1476, Training Accuracy= 0.7997, Minibatch error= 4.9%\n",
      "2017-09-04 04:11:16,327 Epoch 332, Average loss: 0.1136, learning rate: 0.0010\n",
      "2017-09-04 04:11:16,399 Verification error= 8.5%, loss= 0.2943\n",
      "2017-09-04 04:11:33,647 Iter 33300, Minibatch Loss= 0.1793, Training Accuracy= 0.7737, Minibatch error= 6.2%\n",
      "2017-09-04 04:14:11,010 Iter 33350, Minibatch Loss= 0.2254, Training Accuracy= 0.7081, Minibatch error= 8.0%\n",
      "2017-09-04 04:16:44,931 Epoch 333, Average loss: 0.1128, learning rate: 0.0010\n",
      "2017-09-04 04:16:45,004 Verification error= 10.6%, loss= 0.3666\n",
      "2017-09-04 04:17:02,181 Iter 33400, Minibatch Loss= 0.5719, Training Accuracy= 0.7221, Minibatch error= 11.2%\n",
      "2017-09-04 04:19:39,764 Iter 33450, Minibatch Loss= 0.1736, Training Accuracy= 0.7617, Minibatch error= 7.9%\n",
      "2017-09-04 04:22:14,382 Epoch 334, Average loss: 0.1117, learning rate: 0.0010\n",
      "2017-09-04 04:22:14,454 Verification error= 11.6%, loss= 0.5336\n",
      "2017-09-04 04:22:31,693 Iter 33500, Minibatch Loss= 0.1971, Training Accuracy= 0.7328, Minibatch error= 8.3%\n",
      "2017-09-04 04:25:10,126 Iter 33550, Minibatch Loss= 0.2220, Training Accuracy= 0.7245, Minibatch error= 8.4%\n",
      "2017-09-04 04:27:45,174 Epoch 335, Average loss: 0.1116, learning rate: 0.0010\n",
      "2017-09-04 04:27:45,245 Verification error= 10.2%, loss= 0.3449\n",
      "2017-09-04 04:28:02,485 Iter 33600, Minibatch Loss= 0.1762, Training Accuracy= 0.7323, Minibatch error= 6.5%\n",
      "2017-09-04 04:30:40,881 Iter 33650, Minibatch Loss= 0.1559, Training Accuracy= 0.7378, Minibatch error= 6.0%\n",
      "2017-09-04 04:33:16,085 Epoch 336, Average loss: 0.1121, learning rate: 0.0010\n",
      "2017-09-04 04:33:16,160 Verification error= 9.7%, loss= 0.3411\n",
      "2017-09-04 04:33:33,451 Iter 33700, Minibatch Loss= 0.5305, Training Accuracy= 0.7253, Minibatch error= 9.8%\n",
      "2017-09-04 04:36:12,351 Iter 33750, Minibatch Loss= 0.7346, Training Accuracy= 0.6987, Minibatch error= 14.2%\n",
      "2017-09-04 04:38:48,407 Epoch 337, Average loss: 0.1108, learning rate: 0.0010\n",
      "2017-09-04 04:38:48,479 Verification error= 7.6%, loss= 0.3088\n",
      "2017-09-04 04:39:05,838 Iter 33800, Minibatch Loss= 0.3662, Training Accuracy= 0.7198, Minibatch error= 12.0%\n",
      "2017-09-04 04:41:44,994 Iter 33850, Minibatch Loss= 0.4854, Training Accuracy= 0.7219, Minibatch error= 12.1%\n",
      "2017-09-04 04:44:21,023 Epoch 338, Average loss: 0.1079, learning rate: 0.0010\n",
      "2017-09-04 04:44:21,095 Verification error= 7.5%, loss= 0.2778\n",
      "2017-09-04 04:44:38,751 Iter 33900, Minibatch Loss= 0.1400, Training Accuracy= 0.7646, Minibatch error= 5.1%\n",
      "2017-09-04 04:47:18,608 Iter 33950, Minibatch Loss= 0.1721, Training Accuracy= 0.7620, Minibatch error= 5.9%\n",
      "2017-09-04 04:49:55,492 Epoch 339, Average loss: 0.1092, learning rate: 0.0010\n",
      "2017-09-04 04:49:55,563 Verification error= 10.1%, loss= 0.4170\n",
      "2017-09-04 04:50:13,015 Iter 34000, Minibatch Loss= 0.2813, Training Accuracy= 0.6826, Minibatch error= 8.8%\n",
      "2017-09-04 04:52:53,227 Iter 34050, Minibatch Loss= 0.7254, Training Accuracy= 0.6914, Minibatch error= 13.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 04:55:30,522 Epoch 340, Average loss: 0.1094, learning rate: 0.0010\n",
      "2017-09-04 04:55:30,601 Verification error= 11.3%, loss= 0.4128\n",
      "2017-09-04 04:55:48,131 Iter 34100, Minibatch Loss= 0.2293, Training Accuracy= 0.7417, Minibatch error= 9.0%\n",
      "2017-09-04 04:58:28,865 Iter 34150, Minibatch Loss= 0.1605, Training Accuracy= 0.7685, Minibatch error= 7.0%\n",
      "2017-09-04 05:01:06,259 Epoch 341, Average loss: 0.1100, learning rate: 0.0010\n",
      "2017-09-04 05:01:06,331 Verification error= 8.5%, loss= 0.2820\n",
      "2017-09-04 05:01:23,918 Iter 34200, Minibatch Loss= 0.1770, Training Accuracy= 0.7490, Minibatch error= 6.4%\n",
      "2017-09-04 05:04:05,537 Iter 34250, Minibatch Loss= 0.1484, Training Accuracy= 0.7419, Minibatch error= 6.0%\n",
      "2017-09-04 05:06:43,447 Epoch 342, Average loss: 0.1062, learning rate: 0.0010\n",
      "2017-09-04 05:06:43,519 Verification error= 9.2%, loss= 0.2842\n",
      "2017-09-04 05:07:02,252 Iter 34300, Minibatch Loss= 0.1517, Training Accuracy= 0.7427, Minibatch error= 5.8%\n",
      "2017-09-04 05:09:44,146 Iter 34350, Minibatch Loss= 0.3626, Training Accuracy= 0.7451, Minibatch error= 9.2%\n",
      "2017-09-04 05:12:23,172 Epoch 343, Average loss: 0.1087, learning rate: 0.0010\n",
      "2017-09-04 05:12:23,247 Verification error= 6.9%, loss= 0.2365\n",
      "2017-09-04 05:12:41,060 Iter 34400, Minibatch Loss= 0.3901, Training Accuracy= 0.7375, Minibatch error= 10.9%\n",
      "2017-09-04 05:15:23,117 Iter 34450, Minibatch Loss= 0.3049, Training Accuracy= 0.7576, Minibatch error= 9.2%\n",
      "2017-09-04 05:18:01,688 Epoch 344, Average loss: 0.1059, learning rate: 0.0010\n",
      "2017-09-04 05:18:01,760 Verification error= 6.9%, loss= 0.2230\n",
      "2017-09-04 05:18:19,547 Iter 34500, Minibatch Loss= 0.3489, Training Accuracy= 0.7302, Minibatch error= 11.5%\n",
      "2017-09-04 05:21:01,650 Iter 34550, Minibatch Loss= 0.1336, Training Accuracy= 0.7685, Minibatch error= 5.1%\n",
      "2017-09-04 05:23:40,753 Epoch 345, Average loss: 0.1052, learning rate: 0.0010\n",
      "2017-09-04 05:23:40,825 Verification error= 8.4%, loss= 0.3259\n",
      "2017-09-04 05:23:58,632 Iter 34600, Minibatch Loss= 0.1757, Training Accuracy= 0.7659, Minibatch error= 5.9%\n",
      "2017-09-04 05:26:41,800 Iter 34650, Minibatch Loss= 0.2085, Training Accuracy= 0.7047, Minibatch error= 7.7%\n",
      "2017-09-04 05:29:21,359 Epoch 346, Average loss: 0.1040, learning rate: 0.0010\n",
      "2017-09-04 05:29:21,432 Verification error= 10.4%, loss= 0.3746\n",
      "2017-09-04 05:29:39,299 Iter 34700, Minibatch Loss= 0.5197, Training Accuracy= 0.7276, Minibatch error= 10.3%\n",
      "2017-09-04 05:32:22,700 Iter 34750, Minibatch Loss= 0.1821, Training Accuracy= 0.7568, Minibatch error= 8.1%\n",
      "2017-09-04 05:35:03,105 Epoch 347, Average loss: 0.1036, learning rate: 0.0010\n",
      "2017-09-04 05:35:03,177 Verification error= 10.0%, loss= 0.3909\n",
      "2017-09-04 05:35:21,005 Iter 34800, Minibatch Loss= 0.1692, Training Accuracy= 0.7385, Minibatch error= 7.4%\n",
      "2017-09-04 05:38:04,599 Iter 34850, Minibatch Loss= 0.2243, Training Accuracy= 0.7281, Minibatch error= 7.8%\n",
      "2017-09-04 05:40:45,481 Epoch 348, Average loss: 0.1007, learning rate: 0.0010\n",
      "2017-09-04 05:40:45,553 Verification error= 8.5%, loss= 0.3015\n",
      "2017-09-04 05:41:03,535 Iter 34900, Minibatch Loss= 0.1371, Training Accuracy= 0.7445, Minibatch error= 5.6%\n",
      "2017-09-04 05:43:47,634 Iter 34950, Minibatch Loss= 0.1639, Training Accuracy= 0.7393, Minibatch error= 6.0%\n",
      "2017-09-04 05:46:28,689 Epoch 349, Average loss: 0.0999, learning rate: 0.0010\n",
      "2017-09-04 05:46:28,761 Verification error= 7.4%, loss= 0.3329\n",
      "2017-09-04 05:46:46,750 Iter 35000, Minibatch Loss= 0.5685, Training Accuracy= 0.7414, Minibatch error= 7.9%\n",
      "2017-09-04 05:49:31,573 Iter 35050, Minibatch Loss= 0.5022, Training Accuracy= 0.7169, Minibatch error= 12.7%\n",
      "2017-09-04 05:52:12,802 Epoch 350, Average loss: 0.1020, learning rate: 0.0010\n",
      "2017-09-04 05:52:12,875 Verification error= 7.3%, loss= 0.2914\n",
      "2017-09-04 05:52:30,823 Iter 35100, Minibatch Loss= 0.3577, Training Accuracy= 0.7333, Minibatch error= 10.2%\n",
      "2017-09-04 05:55:16,015 Iter 35150, Minibatch Loss= 0.4125, Training Accuracy= 0.7268, Minibatch error= 11.4%\n",
      "2017-09-04 05:57:57,798 Epoch 351, Average loss: 0.1065, learning rate: 0.0010\n",
      "2017-09-04 05:57:57,869 Verification error= 7.0%, loss= 0.3084\n",
      "2017-09-04 05:58:15,967 Iter 35200, Minibatch Loss= 0.1388, Training Accuracy= 0.7836, Minibatch error= 4.9%\n",
      "2017-09-04 06:01:01,999 Iter 35250, Minibatch Loss= 0.1798, Training Accuracy= 0.7688, Minibatch error= 5.7%\n",
      "2017-09-04 06:03:44,959 Epoch 352, Average loss: 0.0998, learning rate: 0.0010\n",
      "2017-09-04 06:03:45,032 Verification error= 8.1%, loss= 0.3842\n",
      "2017-09-04 06:04:04,532 Iter 35300, Minibatch Loss= 0.2115, Training Accuracy= 0.7107, Minibatch error= 6.5%\n",
      "2017-09-04 06:06:51,785 Iter 35350, Minibatch Loss= 0.6948, Training Accuracy= 0.7359, Minibatch error= 9.1%\n",
      "2017-09-04 06:09:35,241 Epoch 353, Average loss: 0.1018, learning rate: 0.0010\n",
      "2017-09-04 06:09:35,313 Verification error= 10.2%, loss= 0.4536\n",
      "2017-09-04 06:09:53,763 Iter 35400, Minibatch Loss= 0.2066, Training Accuracy= 0.7359, Minibatch error= 8.4%\n",
      "2017-09-04 06:12:41,199 Iter 35450, Minibatch Loss= 0.1988, Training Accuracy= 0.7065, Minibatch error= 7.9%\n",
      "2017-09-04 06:15:24,764 Epoch 354, Average loss: 0.1001, learning rate: 0.0010\n",
      "2017-09-04 06:15:24,844 Verification error= 8.8%, loss= 0.4148\n",
      "2017-09-04 06:15:43,100 Iter 35500, Minibatch Loss= 0.1974, Training Accuracy= 0.7333, Minibatch error= 7.6%\n",
      "2017-09-04 06:18:30,677 Iter 35550, Minibatch Loss= 0.1362, Training Accuracy= 0.7586, Minibatch error= 5.0%\n",
      "2017-09-04 06:21:14,384 Epoch 355, Average loss: 0.1002, learning rate: 0.0010\n",
      "2017-09-04 06:21:14,455 Verification error= 7.6%, loss= 0.3263\n",
      "2017-09-04 06:21:32,754 Iter 35600, Minibatch Loss= 0.1554, Training Accuracy= 0.7508, Minibatch error= 6.0%\n",
      "2017-09-04 06:24:20,779 Iter 35650, Minibatch Loss= 0.3972, Training Accuracy= 0.7482, Minibatch error= 7.8%\n",
      "2017-09-04 06:27:05,356 Epoch 356, Average loss: 0.0973, learning rate: 0.0010\n",
      "2017-09-04 06:27:05,430 Verification error= 6.8%, loss= 0.3127\n",
      "2017-09-04 06:27:23,835 Iter 35700, Minibatch Loss= 0.6495, Training Accuracy= 0.7232, Minibatch error= 12.0%\n",
      "2017-09-04 06:30:12,254 Iter 35750, Minibatch Loss= 0.3753, Training Accuracy= 0.7273, Minibatch error= 10.8%\n",
      "2017-09-04 06:32:56,957 Epoch 357, Average loss: 0.0975, learning rate: 0.0010\n",
      "2017-09-04 06:32:57,029 Verification error= 7.8%, loss= 0.4110\n",
      "2017-09-04 06:33:15,449 Iter 35800, Minibatch Loss= 0.5853, Training Accuracy= 0.7206, Minibatch error= 12.2%\n",
      "2017-09-04 06:36:04,434 Iter 35850, Minibatch Loss= 0.1227, Training Accuracy= 0.7807, Minibatch error= 4.7%\n",
      "2017-09-04 06:38:49,839 Epoch 358, Average loss: 0.0961, learning rate: 0.0010\n",
      "2017-09-04 06:38:49,910 Verification error= 8.3%, loss= 0.3348\n",
      "2017-09-04 06:39:08,400 Iter 35900, Minibatch Loss= 0.1701, Training Accuracy= 0.7648, Minibatch error= 6.1%\n",
      "2017-09-04 06:41:57,280 Iter 35950, Minibatch Loss= 0.2297, Training Accuracy= 0.7068, Minibatch error= 7.4%\n",
      "2017-09-04 06:44:42,813 Epoch 359, Average loss: 0.0966, learning rate: 0.0010\n",
      "2017-09-04 06:44:42,884 Verification error= 9.7%, loss= 0.5110\n",
      "2017-09-04 06:45:01,685 Iter 36000, Minibatch Loss= 0.6870, Training Accuracy= 0.7323, Minibatch error= 9.4%\n",
      "2017-09-04 06:47:51,200 Iter 36050, Minibatch Loss= 0.1706, Training Accuracy= 0.7523, Minibatch error= 7.9%\n",
      "2017-09-04 06:50:37,344 Epoch 360, Average loss: 0.0977, learning rate: 0.0010\n",
      "2017-09-04 06:50:37,417 Verification error= 9.3%, loss= 0.4179\n",
      "2017-09-04 06:50:55,967 Iter 36100, Minibatch Loss= 0.1605, Training Accuracy= 0.7505, Minibatch error= 6.5%\n",
      "2017-09-04 06:53:46,064 Iter 36150, Minibatch Loss= 0.2509, Training Accuracy= 0.7190, Minibatch error= 8.2%\n",
      "2017-09-04 06:56:32,763 Epoch 361, Average loss: 0.0944, learning rate: 0.0010\n",
      "2017-09-04 06:56:32,834 Verification error= 6.4%, loss= 0.2879\n",
      "2017-09-04 06:56:51,345 Iter 36200, Minibatch Loss= 0.1114, Training Accuracy= 0.7534, Minibatch error= 4.5%\n",
      "2017-09-04 06:59:41,836 Iter 36250, Minibatch Loss= 0.1528, Training Accuracy= 0.7367, Minibatch error= 5.3%\n",
      "2017-09-04 07:02:29,114 Epoch 362, Average loss: 0.0943, learning rate: 0.0010\n",
      "2017-09-04 07:02:29,186 Verification error= 6.6%, loss= 0.3076\n",
      "2017-09-04 07:02:47,756 Iter 36300, Minibatch Loss= 0.5310, Training Accuracy= 0.7445, Minibatch error= 7.3%\n",
      "2017-09-04 07:05:39,005 Iter 36350, Minibatch Loss= 0.5151, Training Accuracy= 0.7326, Minibatch error= 10.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 07:08:26,691 Epoch 363, Average loss: 0.0931, learning rate: 0.0010\n",
      "2017-09-04 07:08:26,762 Verification error= 6.3%, loss= 0.2653\n",
      "2017-09-04 07:08:46,531 Iter 36400, Minibatch Loss= 0.3427, Training Accuracy= 0.7185, Minibatch error= 9.9%\n",
      "2017-09-04 07:11:38,215 Iter 36450, Minibatch Loss= 0.5085, Training Accuracy= 0.7148, Minibatch error= 11.5%\n",
      "2017-09-04 07:14:26,348 Epoch 364, Average loss: 0.0934, learning rate: 0.0010\n",
      "2017-09-04 07:14:26,419 Verification error= 6.6%, loss= 0.2841\n",
      "2017-09-04 07:14:45,142 Iter 36500, Minibatch Loss= 0.1167, Training Accuracy= 0.7734, Minibatch error= 4.2%\n",
      "2017-09-04 07:17:36,878 Iter 36550, Minibatch Loss= 0.1809, Training Accuracy= 0.7549, Minibatch error= 5.8%\n",
      "2017-09-04 07:20:25,299 Epoch 365, Average loss: 0.0906, learning rate: 0.0010\n",
      "2017-09-04 07:20:25,370 Verification error= 8.9%, loss= 0.5342\n",
      "2017-09-04 07:20:44,158 Iter 36600, Minibatch Loss= 0.2610, Training Accuracy= 0.6674, Minibatch error= 7.5%\n",
      "2017-09-04 07:23:36,159 Iter 36650, Minibatch Loss= 0.7337, Training Accuracy= 0.7284, Minibatch error= 8.2%\n",
      "2017-09-04 07:26:24,847 Epoch 366, Average loss: 0.0929, learning rate: 0.0010\n",
      "2017-09-04 07:26:24,918 Verification error= 8.5%, loss= 0.3999\n",
      "2017-09-04 07:26:43,593 Iter 36700, Minibatch Loss= 0.1573, Training Accuracy= 0.7315, Minibatch error= 7.4%\n",
      "2017-09-04 07:29:36,134 Iter 36750, Minibatch Loss= 0.1599, Training Accuracy= 0.7245, Minibatch error= 6.6%\n",
      "2017-09-04 07:32:25,021 Epoch 367, Average loss: 0.0924, learning rate: 0.0010\n",
      "2017-09-04 07:32:25,101 Verification error= 7.3%, loss= 0.3417\n",
      "2017-09-04 07:32:43,926 Iter 36800, Minibatch Loss= 0.1724, Training Accuracy= 0.7284, Minibatch error= 6.9%\n",
      "2017-09-04 07:35:36,908 Iter 36850, Minibatch Loss= 0.1160, Training Accuracy= 0.7302, Minibatch error= 4.5%\n",
      "2017-09-04 07:38:26,524 Epoch 368, Average loss: 0.0888, learning rate: 0.0010\n",
      "2017-09-04 07:38:26,595 Verification error= 6.2%, loss= 0.2858\n",
      "2017-09-04 07:38:45,466 Iter 36900, Minibatch Loss= 0.1307, Training Accuracy= 0.7307, Minibatch error= 5.0%\n",
      "2017-09-04 07:41:38,938 Iter 36950, Minibatch Loss= 0.5912, Training Accuracy= 0.7352, Minibatch error= 7.2%\n",
      "2017-09-04 07:44:29,085 Epoch 369, Average loss: 0.0903, learning rate: 0.0010\n",
      "2017-09-04 07:44:29,156 Verification error= 6.1%, loss= 0.3047\n",
      "2017-09-04 07:44:48,124 Iter 37000, Minibatch Loss= 0.6791, Training Accuracy= 0.7299, Minibatch error= 9.8%\n",
      "2017-09-04 07:47:41,891 Iter 37050, Minibatch Loss= 0.3362, Training Accuracy= 0.7201, Minibatch error= 9.9%\n",
      "2017-09-04 07:50:32,314 Epoch 370, Average loss: 0.0881, learning rate: 0.0010\n",
      "2017-09-04 07:50:32,386 Verification error= 7.1%, loss= 0.3994\n",
      "2017-09-04 07:50:51,355 Iter 37100, Minibatch Loss= 0.5147, Training Accuracy= 0.7102, Minibatch error= 11.4%\n",
      "2017-09-04 07:53:46,229 Iter 37150, Minibatch Loss= 0.1016, Training Accuracy= 0.7724, Minibatch error= 3.4%\n",
      "2017-09-04 07:56:37,157 Epoch 371, Average loss: 0.0879, learning rate: 0.0010\n",
      "2017-09-04 07:56:37,228 Verification error= 7.8%, loss= 0.4285\n",
      "2017-09-04 07:56:56,326 Iter 37200, Minibatch Loss= 0.1751, Training Accuracy= 0.7565, Minibatch error= 5.6%\n",
      "2017-09-04 07:59:51,341 Iter 37250, Minibatch Loss= 0.2234, Training Accuracy= 0.6958, Minibatch error= 7.6%\n",
      "2017-09-04 08:02:42,662 Epoch 372, Average loss: 0.0883, learning rate: 0.0010\n",
      "2017-09-04 08:02:42,742 Verification error= 7.5%, loss= 0.3141\n",
      "2017-09-04 08:03:01,897 Iter 37300, Minibatch Loss= 0.5885, Training Accuracy= 0.7437, Minibatch error= 7.9%\n",
      "2017-09-04 08:05:57,415 Iter 37350, Minibatch Loss= 0.1826, Training Accuracy= 0.7313, Minibatch error= 8.2%\n",
      "2017-09-04 08:08:49,465 Epoch 373, Average loss: 0.0898, learning rate: 0.0010\n",
      "2017-09-04 08:08:49,537 Verification error= 6.8%, loss= 0.3311\n",
      "2017-09-04 08:09:09,775 Iter 37400, Minibatch Loss= 0.1594, Training Accuracy= 0.7427, Minibatch error= 6.1%\n",
      "2017-09-04 08:12:05,455 Iter 37450, Minibatch Loss= 0.1469, Training Accuracy= 0.7357, Minibatch error= 6.7%\n",
      "2017-09-04 08:14:57,716 Epoch 374, Average loss: 0.0885, learning rate: 0.0010\n",
      "2017-09-04 08:14:57,788 Verification error= 6.1%, loss= 0.2070\n",
      "2017-09-04 08:15:16,969 Iter 37500, Minibatch Loss= 0.1255, Training Accuracy= 0.7411, Minibatch error= 4.3%\n",
      "2017-09-04 08:18:13,043 Iter 37550, Minibatch Loss= 0.1346, Training Accuracy= 0.7310, Minibatch error= 5.4%\n",
      "2017-09-04 08:21:05,739 Epoch 375, Average loss: 0.0859, learning rate: 0.0010\n",
      "2017-09-04 08:21:05,811 Verification error= 5.4%, loss= 0.2044\n",
      "2017-09-04 08:21:25,344 Iter 37600, Minibatch Loss= 0.4562, Training Accuracy= 0.7479, Minibatch error= 6.6%\n",
      "2017-09-04 08:24:21,794 Iter 37650, Minibatch Loss= 0.4983, Training Accuracy= 0.7307, Minibatch error= 9.6%\n",
      "2017-09-04 08:27:15,144 Epoch 376, Average loss: 0.0837, learning rate: 0.0010\n",
      "2017-09-04 08:27:15,216 Verification error= 6.3%, loss= 0.2926\n",
      "2017-09-04 08:27:34,456 Iter 37700, Minibatch Loss= 0.3606, Training Accuracy= 0.7146, Minibatch error= 9.9%\n",
      "2017-09-04 08:30:31,240 Iter 37750, Minibatch Loss= 0.4083, Training Accuracy= 0.7115, Minibatch error= 10.7%\n",
      "2017-09-04 08:33:24,748 Epoch 377, Average loss: 0.0848, learning rate: 0.0010\n",
      "2017-09-04 08:33:24,822 Verification error= 7.0%, loss= 0.2989\n",
      "2017-09-04 08:33:44,106 Iter 37800, Minibatch Loss= 0.1059, Training Accuracy= 0.7628, Minibatch error= 4.1%\n",
      "2017-09-04 08:36:41,723 Iter 37850, Minibatch Loss= 0.1625, Training Accuracy= 0.7464, Minibatch error= 6.0%\n",
      "2017-09-04 08:39:35,953 Epoch 378, Average loss: 0.0827, learning rate: 0.0010\n",
      "2017-09-04 08:39:36,025 Verification error= 7.8%, loss= 0.3978\n",
      "2017-09-04 08:39:55,841 Iter 37900, Minibatch Loss= 0.2673, Training Accuracy= 0.6646, Minibatch error= 6.7%\n",
      "2017-09-04 08:42:53,703 Iter 37950, Minibatch Loss= 0.7499, Training Accuracy= 0.7216, Minibatch error= 8.9%\n",
      "2017-09-04 08:45:48,109 Epoch 379, Average loss: 0.0838, learning rate: 0.0010\n",
      "2017-09-04 08:45:48,181 Verification error= 7.1%, loss= 0.3707\n",
      "2017-09-04 08:46:07,662 Iter 38000, Minibatch Loss= 0.1556, Training Accuracy= 0.7310, Minibatch error= 7.2%\n",
      "2017-09-04 08:49:05,680 Iter 38050, Minibatch Loss= 0.1251, Training Accuracy= 0.7497, Minibatch error= 5.4%\n",
      "2017-09-04 08:52:00,413 Epoch 380, Average loss: 0.0831, learning rate: 0.0010\n",
      "2017-09-04 08:52:00,486 Verification error= 6.0%, loss= 0.2378\n",
      "2017-09-04 08:52:20,018 Iter 38100, Minibatch Loss= 0.1494, Training Accuracy= 0.7326, Minibatch error= 6.6%\n",
      "2017-09-04 08:55:18,672 Iter 38150, Minibatch Loss= 0.1114, Training Accuracy= 0.7469, Minibatch error= 4.1%\n",
      "2017-09-04 08:58:13,630 Epoch 381, Average loss: 0.0815, learning rate: 0.0010\n",
      "2017-09-04 08:58:13,702 Verification error= 4.8%, loss= 0.1868\n",
      "2017-09-04 08:58:33,214 Iter 38200, Minibatch Loss= 0.1058, Training Accuracy= 0.7318, Minibatch error= 4.2%\n",
      "2017-09-04 09:01:32,283 Iter 38250, Minibatch Loss= 0.4449, Training Accuracy= 0.7422, Minibatch error= 7.5%\n",
      "2017-09-04 09:04:27,718 Epoch 382, Average loss: 0.0831, learning rate: 0.0010\n",
      "2017-09-04 09:04:27,790 Verification error= 5.9%, loss= 0.2312\n",
      "2017-09-04 09:04:47,326 Iter 38300, Minibatch Loss= 0.5158, Training Accuracy= 0.7219, Minibatch error= 11.1%\n",
      "2017-09-04 09:07:47,107 Iter 38350, Minibatch Loss= 0.3102, Training Accuracy= 0.7266, Minibatch error= 9.5%\n",
      "2017-09-04 09:10:43,314 Epoch 383, Average loss: 0.0799, learning rate: 0.0010\n",
      "2017-09-04 09:10:43,393 Verification error= 6.3%, loss= 0.2577\n",
      "2017-09-04 09:11:03,065 Iter 38400, Minibatch Loss= 0.3895, Training Accuracy= 0.7279, Minibatch error= 9.9%\n",
      "2017-09-04 09:14:03,408 Iter 38450, Minibatch Loss= 0.1151, Training Accuracy= 0.7583, Minibatch error= 4.7%\n",
      "2017-09-04 09:16:59,802 Epoch 384, Average loss: 0.0789, learning rate: 0.0010\n",
      "2017-09-04 09:16:59,878 Verification error= 6.7%, loss= 0.3499\n",
      "2017-09-04 09:17:20,722 Iter 38500, Minibatch Loss= 0.1484, Training Accuracy= 0.7560, Minibatch error= 5.5%\n",
      "2017-09-04 09:20:20,882 Iter 38550, Minibatch Loss= 0.2139, Training Accuracy= 0.6898, Minibatch error= 6.9%\n",
      "2017-09-04 09:23:17,849 Epoch 385, Average loss: 0.0815, learning rate: 0.0010\n",
      "2017-09-04 09:23:17,925 Verification error= 6.1%, loss= 0.2264\n",
      "2017-09-04 09:23:37,546 Iter 38600, Minibatch Loss= 0.5105, Training Accuracy= 0.7458, Minibatch error= 7.8%\n",
      "2017-09-04 09:26:38,299 Iter 38650, Minibatch Loss= 0.1329, Training Accuracy= 0.7534, Minibatch error= 6.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 09:29:35,984 Epoch 386, Average loss: 0.0787, learning rate: 0.0010\n",
      "2017-09-04 09:29:36,057 Verification error= 5.6%, loss= 0.2203\n",
      "2017-09-04 09:29:55,663 Iter 38700, Minibatch Loss= 0.1467, Training Accuracy= 0.7576, Minibatch error= 6.3%\n",
      "2017-09-04 09:32:56,815 Iter 38750, Minibatch Loss= 0.1322, Training Accuracy= 0.7497, Minibatch error= 5.4%\n",
      "2017-09-04 09:35:54,423 Epoch 387, Average loss: 0.0761, learning rate: 0.0010\n",
      "2017-09-04 09:35:54,495 Verification error= 5.2%, loss= 0.1884\n",
      "2017-09-04 09:36:14,273 Iter 38800, Minibatch Loss= 0.1088, Training Accuracy= 0.7474, Minibatch error= 4.0%\n",
      "2017-09-04 09:39:18,344 Iter 38850, Minibatch Loss= 0.1191, Training Accuracy= 0.7323, Minibatch error= 5.2%\n",
      "2017-09-04 09:42:17,944 Epoch 388, Average loss: 0.0756, learning rate: 0.0010\n",
      "2017-09-04 09:42:18,018 Verification error= 6.0%, loss= 0.2780\n",
      "2017-09-04 09:42:38,048 Iter 38900, Minibatch Loss= 0.6209, Training Accuracy= 0.7331, Minibatch error= 7.7%\n",
      "2017-09-04 09:45:40,252 Iter 38950, Minibatch Loss= 0.5779, Training Accuracy= 0.7234, Minibatch error= 10.0%\n",
      "2017-09-04 09:48:39,097 Epoch 389, Average loss: 0.0741, learning rate: 0.0010\n",
      "2017-09-04 09:48:39,171 Verification error= 6.2%, loss= 0.3235\n",
      "2017-09-04 09:48:59,055 Iter 39000, Minibatch Loss= 0.4093, Training Accuracy= 0.7065, Minibatch error= 10.3%\n",
      "2017-09-04 09:52:02,285 Iter 39050, Minibatch Loss= 0.3918, Training Accuracy= 0.7286, Minibatch error= 9.3%\n",
      "2017-09-04 09:55:01,277 Epoch 390, Average loss: 0.0773, learning rate: 0.0010\n",
      "2017-09-04 09:55:01,351 Verification error= 6.2%, loss= 0.2356\n",
      "2017-09-04 09:55:21,270 Iter 39100, Minibatch Loss= 0.1225, Training Accuracy= 0.7612, Minibatch error= 4.7%\n",
      "2017-09-04 09:58:24,208 Iter 39150, Minibatch Loss= 0.1587, Training Accuracy= 0.7583, Minibatch error= 5.8%\n",
      "2017-09-04 10:01:23,725 Epoch 391, Average loss: 0.0744, learning rate: 0.0010\n",
      "2017-09-04 10:01:23,808 Verification error= 6.5%, loss= 0.2706\n",
      "2017-09-04 10:01:43,932 Iter 39200, Minibatch Loss= 0.1458, Training Accuracy= 0.7083, Minibatch error= 5.1%\n",
      "2017-09-04 10:04:47,568 Iter 39250, Minibatch Loss= 0.6047, Training Accuracy= 0.7497, Minibatch error= 7.6%\n",
      "2017-09-04 10:07:47,249 Epoch 392, Average loss: 0.0739, learning rate: 0.0010\n",
      "2017-09-04 10:07:47,325 Verification error= 6.2%, loss= 0.2726\n",
      "2017-09-04 10:08:07,619 Iter 39300, Minibatch Loss= 0.1487, Training Accuracy= 0.7576, Minibatch error= 6.6%\n",
      "2017-09-04 10:11:11,823 Iter 39350, Minibatch Loss= 0.1439, Training Accuracy= 0.7419, Minibatch error= 5.6%\n",
      "2017-09-04 10:14:12,365 Epoch 393, Average loss: 0.0715, learning rate: 0.0010\n",
      "2017-09-04 10:14:12,444 Verification error= 5.4%, loss= 0.2177\n",
      "2017-09-04 10:14:32,567 Iter 39400, Minibatch Loss= 0.1314, Training Accuracy= 0.7505, Minibatch error= 5.4%\n",
      "2017-09-04 10:17:37,340 Iter 39450, Minibatch Loss= 0.1120, Training Accuracy= 0.7445, Minibatch error= 3.8%\n",
      "2017-09-04 10:20:38,127 Epoch 394, Average loss: 0.0721, learning rate: 0.0010\n",
      "2017-09-04 10:20:38,202 Verification error= 5.1%, loss= 0.2079\n",
      "2017-09-04 10:20:58,312 Iter 39500, Minibatch Loss= 0.1213, Training Accuracy= 0.7315, Minibatch error= 5.1%\n",
      "2017-09-04 10:24:03,388 Iter 39550, Minibatch Loss= 0.5512, Training Accuracy= 0.7365, Minibatch error= 7.7%\n",
      "2017-09-04 10:27:04,848 Epoch 395, Average loss: 0.0736, learning rate: 0.0010\n",
      "2017-09-04 10:27:04,923 Verification error= 5.4%, loss= 0.2046\n",
      "2017-09-04 10:27:26,396 Iter 39600, Minibatch Loss= 0.5174, Training Accuracy= 0.7349, Minibatch error= 9.0%\n",
      "2017-09-04 10:30:31,716 Iter 39650, Minibatch Loss= 0.3870, Training Accuracy= 0.7081, Minibatch error= 10.2%\n",
      "2017-09-04 10:33:33,603 Epoch 396, Average loss: 0.0724, learning rate: 0.0010\n",
      "2017-09-04 10:33:33,678 Verification error= 5.9%, loss= 0.2038\n",
      "2017-09-04 10:33:53,999 Iter 39700, Minibatch Loss= 0.2942, Training Accuracy= 0.7383, Minibatch error= 8.5%\n",
      "2017-09-04 10:37:00,256 Iter 39750, Minibatch Loss= 0.1622, Training Accuracy= 0.7326, Minibatch error= 6.4%\n",
      "2017-09-04 10:40:02,641 Epoch 397, Average loss: 0.0717, learning rate: 0.0010\n",
      "2017-09-04 10:40:02,717 Verification error= 6.2%, loss= 0.2728\n",
      "2017-09-04 10:40:23,084 Iter 39800, Minibatch Loss= 0.1489, Training Accuracy= 0.7555, Minibatch error= 5.7%\n",
      "2017-09-04 10:43:29,944 Iter 39850, Minibatch Loss= 0.2099, Training Accuracy= 0.7023, Minibatch error= 5.5%\n",
      "2017-09-04 10:46:32,722 Epoch 398, Average loss: 0.0695, learning rate: 0.0010\n",
      "2017-09-04 10:46:32,798 Verification error= 6.1%, loss= 0.2558\n",
      "2017-09-04 10:46:53,083 Iter 39900, Minibatch Loss= 0.6459, Training Accuracy= 0.7484, Minibatch error= 7.3%\n",
      "2017-09-04 10:49:59,591 Iter 39950, Minibatch Loss= 0.1215, Training Accuracy= 0.7552, Minibatch error= 5.7%\n",
      "2017-09-04 10:53:02,422 Epoch 399, Average loss: 0.0716, learning rate: 0.0010\n",
      "2017-09-04 10:53:02,497 Verification error= 5.6%, loss= 0.2377\n",
      "2017-09-04 10:53:22,610 Iter 40000, Minibatch Loss= 0.1564, Training Accuracy= 0.7333, Minibatch error= 6.0%\n",
      "2017-09-04 10:56:29,769 Iter 40050, Minibatch Loss= 0.1525, Training Accuracy= 0.7378, Minibatch error= 5.9%\n",
      "2017-09-04 10:59:32,879 Epoch 400, Average loss: 0.0701, learning rate: 0.0010\n",
      "2017-09-04 10:59:32,953 Verification error= 5.6%, loss= 0.2159\n",
      "2017-09-04 10:59:53,185 Iter 40100, Minibatch Loss= 0.1166, Training Accuracy= 0.7448, Minibatch error= 3.8%\n",
      "2017-09-04 11:03:00,674 Iter 40150, Minibatch Loss= 0.1816, Training Accuracy= 0.7128, Minibatch error= 5.9%\n",
      "2017-09-04 11:06:04,457 Epoch 401, Average loss: 0.0670, learning rate: 0.0010\n",
      "2017-09-04 11:06:04,536 Verification error= 6.2%, loss= 0.2886\n",
      "2017-09-04 11:06:24,744 Iter 40200, Minibatch Loss= 0.5499, Training Accuracy= 0.7346, Minibatch error= 7.3%\n",
      "2017-09-04 11:09:32,850 Iter 40250, Minibatch Loss= 0.7109, Training Accuracy= 0.7005, Minibatch error= 11.5%\n",
      "2017-09-04 11:12:36,986 Epoch 402, Average loss: 0.0677, learning rate: 0.0010\n",
      "2017-09-04 11:12:37,061 Verification error= 6.5%, loss= 0.3282\n",
      "2017-09-04 11:12:57,444 Iter 40300, Minibatch Loss= 0.4155, Training Accuracy= 0.6964, Minibatch error= 10.6%\n",
      "2017-09-04 11:16:06,392 Iter 40350, Minibatch Loss= 0.6327, Training Accuracy= 0.7034, Minibatch error= 10.6%\n",
      "2017-09-04 11:19:11,047 Epoch 403, Average loss: 0.0694, learning rate: 0.0010\n",
      "2017-09-04 11:19:11,125 Verification error= 6.9%, loss= 0.3119\n",
      "2017-09-04 11:19:31,502 Iter 40400, Minibatch Loss= 0.1462, Training Accuracy= 0.7302, Minibatch error= 6.0%\n",
      "2017-09-04 11:22:40,135 Iter 40450, Minibatch Loss= 0.1425, Training Accuracy= 0.7406, Minibatch error= 5.4%\n",
      "2017-09-04 11:25:45,895 Epoch 404, Average loss: 0.0656, learning rate: 0.0010\n",
      "2017-09-04 11:25:45,970 Verification error= 6.7%, loss= 0.3245\n",
      "2017-09-04 11:26:06,378 Iter 40500, Minibatch Loss= 0.2057, Training Accuracy= 0.6440, Minibatch error= 6.9%\n",
      "2017-09-04 11:29:15,573 Iter 40550, Minibatch Loss= 0.8528, Training Accuracy= 0.7404, Minibatch error= 6.5%\n",
      "2017-09-04 11:32:21,045 Epoch 405, Average loss: 0.0661, learning rate: 0.0010\n",
      "2017-09-04 11:32:21,119 Verification error= 4.8%, loss= 0.1409\n",
      "2017-09-04 11:32:42,845 Iter 40600, Minibatch Loss= 0.1072, Training Accuracy= 0.7604, Minibatch error= 4.9%\n",
      "2017-09-04 11:35:52,780 Iter 40650, Minibatch Loss= 0.1646, Training Accuracy= 0.7005, Minibatch error= 6.6%\n",
      "2017-09-04 11:38:58,685 Epoch 406, Average loss: 0.0652, learning rate: 0.0010\n",
      "2017-09-04 11:38:58,768 Verification error= 5.2%, loss= 0.1601\n",
      "2017-09-04 11:39:19,404 Iter 40700, Minibatch Loss= 0.1236, Training Accuracy= 0.7565, Minibatch error= 5.2%\n",
      "2017-09-04 11:42:29,820 Iter 40750, Minibatch Loss= 0.1142, Training Accuracy= 0.7336, Minibatch error= 3.4%\n",
      "2017-09-04 11:45:36,164 Epoch 407, Average loss: 0.0633, learning rate: 0.0010\n",
      "2017-09-04 11:45:36,239 Verification error= 5.5%, loss= 0.2349\n",
      "2017-09-04 11:45:56,690 Iter 40800, Minibatch Loss= 0.1796, Training Accuracy= 0.7102, Minibatch error= 6.0%\n",
      "2017-09-04 11:49:07,513 Iter 40850, Minibatch Loss= 0.5310, Training Accuracy= 0.7315, Minibatch error= 7.6%\n",
      "2017-09-04 11:52:14,489 Epoch 408, Average loss: 0.0628, learning rate: 0.0010\n",
      "2017-09-04 11:52:14,563 Verification error= 6.0%, loss= 0.3011\n",
      "2017-09-04 11:52:35,117 Iter 40900, Minibatch Loss= 0.7178, Training Accuracy= 0.7073, Minibatch error= 11.4%\n",
      "2017-09-04 11:55:46,206 Iter 40950, Minibatch Loss= 0.3914, Training Accuracy= 0.7057, Minibatch error= 10.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 11:58:53,560 Epoch 409, Average loss: 0.0630, learning rate: 0.0010\n",
      "2017-09-04 11:58:53,639 Verification error= 5.5%, loss= 0.2242\n",
      "2017-09-04 11:59:14,294 Iter 41000, Minibatch Loss= 0.3586, Training Accuracy= 0.7341, Minibatch error= 8.3%\n",
      "2017-09-04 12:02:26,674 Iter 41050, Minibatch Loss= 0.1109, Training Accuracy= 0.7505, Minibatch error= 4.4%\n",
      "2017-09-04 12:05:34,342 Epoch 410, Average loss: 0.0628, learning rate: 0.0010\n",
      "2017-09-04 12:05:34,415 Verification error= 5.6%, loss= 0.2369\n",
      "2017-09-04 12:05:55,190 Iter 41100, Minibatch Loss= 0.1309, Training Accuracy= 0.7451, Minibatch error= 5.1%\n",
      "2017-09-04 12:09:07,490 Iter 41150, Minibatch Loss= 0.1364, Training Accuracy= 0.6958, Minibatch error= 4.7%\n",
      "2017-09-04 12:12:15,716 Epoch 411, Average loss: 0.0637, learning rate: 0.0010\n",
      "2017-09-04 12:12:15,788 Verification error= 5.5%, loss= 0.2238\n",
      "2017-09-04 12:12:36,890 Iter 41200, Minibatch Loss= 0.5999, Training Accuracy= 0.7464, Minibatch error= 6.6%\n",
      "2017-09-04 12:15:49,907 Iter 41250, Minibatch Loss= 0.1320, Training Accuracy= 0.7208, Minibatch error= 6.2%\n",
      "2017-09-04 12:18:58,820 Epoch 412, Average loss: 0.0623, learning rate: 0.0010\n",
      "2017-09-04 12:18:58,892 Verification error= 5.9%, loss= 0.2310\n",
      "2017-09-04 12:19:20,049 Iter 41300, Minibatch Loss= 0.1708, Training Accuracy= 0.7096, Minibatch error= 6.5%\n",
      "2017-09-04 12:22:33,104 Iter 41350, Minibatch Loss= 0.1609, Training Accuracy= 0.7276, Minibatch error= 5.7%\n",
      "2017-09-04 12:25:42,929 Epoch 413, Average loss: 0.0612, learning rate: 0.0010\n",
      "2017-09-04 12:25:43,002 Verification error= 5.4%, loss= 0.2115\n",
      "2017-09-04 12:26:03,876 Iter 41400, Minibatch Loss= 0.1240, Training Accuracy= 0.7268, Minibatch error= 4.3%\n",
      "2017-09-04 12:29:17,599 Iter 41450, Minibatch Loss= 0.1452, Training Accuracy= 0.7203, Minibatch error= 5.1%\n",
      "2017-09-04 12:32:27,887 Epoch 414, Average loss: 0.0612, learning rate: 0.0010\n",
      "2017-09-04 12:32:27,960 Verification error= 6.6%, loss= 0.3266\n",
      "2017-09-04 12:32:49,117 Iter 41500, Minibatch Loss= 0.6441, Training Accuracy= 0.7234, Minibatch error= 8.1%\n",
      "2017-09-04 12:36:03,137 Iter 41550, Minibatch Loss= 0.7175, Training Accuracy= 0.7060, Minibatch error= 10.4%\n",
      "2017-09-04 12:39:13,439 Epoch 415, Average loss: 0.0641, learning rate: 0.0010\n",
      "2017-09-04 12:39:13,518 Verification error= 6.0%, loss= 0.2264\n",
      "2017-09-04 12:39:35,030 Iter 41600, Minibatch Loss= 0.2777, Training Accuracy= 0.7271, Minibatch error= 7.9%\n",
      "2017-09-04 12:42:49,553 Iter 41650, Minibatch Loss= 0.4090, Training Accuracy= 0.7297, Minibatch error= 9.0%\n",
      "2017-09-04 12:46:00,125 Epoch 416, Average loss: 0.0615, learning rate: 0.0010\n",
      "2017-09-04 12:46:00,197 Verification error= 5.8%, loss= 0.2522\n",
      "2017-09-04 12:46:23,229 Iter 41700, Minibatch Loss= 0.1189, Training Accuracy= 0.7396, Minibatch error= 5.0%\n",
      "2017-09-04 12:49:38,328 Iter 41750, Minibatch Loss= 0.1341, Training Accuracy= 0.7393, Minibatch error= 5.2%\n",
      "2017-09-04 12:52:49,222 Epoch 417, Average loss: 0.0590, learning rate: 0.0010\n",
      "2017-09-04 12:52:49,294 Verification error= 5.4%, loss= 0.2164\n",
      "2017-09-04 12:53:10,320 Iter 41800, Minibatch Loss= 0.1659, Training Accuracy= 0.6805, Minibatch error= 5.8%\n",
      "2017-09-04 12:56:25,328 Iter 41850, Minibatch Loss= 0.5496, Training Accuracy= 0.7409, Minibatch error= 6.7%\n",
      "2017-09-04 12:59:36,277 Epoch 418, Average loss: 0.0612, learning rate: 0.0010\n",
      "2017-09-04 12:59:36,349 Verification error= 6.6%, loss= 0.2381\n",
      "2017-09-04 12:59:57,424 Iter 41900, Minibatch Loss= 0.1660, Training Accuracy= 0.7130, Minibatch error= 7.1%\n",
      "2017-09-04 13:03:12,700 Iter 41950, Minibatch Loss= 0.1377, Training Accuracy= 0.7143, Minibatch error= 5.6%\n",
      "2017-09-04 13:06:24,733 Epoch 419, Average loss: 0.0597, learning rate: 0.0010\n",
      "2017-09-04 13:06:24,813 Verification error= 5.8%, loss= 0.2568\n",
      "2017-09-04 13:06:45,904 Iter 42000, Minibatch Loss= 0.1413, Training Accuracy= 0.7331, Minibatch error= 5.5%\n",
      "2017-09-04 13:10:01,891 Iter 42050, Minibatch Loss= 0.1109, Training Accuracy= 0.7161, Minibatch error= 4.3%\n",
      "2017-09-04 13:13:13,416 Epoch 420, Average loss: 0.0598, learning rate: 0.0010\n",
      "2017-09-04 13:13:13,488 Verification error= 5.7%, loss= 0.2352\n",
      "2017-09-04 13:13:34,701 Iter 42100, Minibatch Loss= 0.1691, Training Accuracy= 0.6977, Minibatch error= 5.4%\n",
      "2017-09-04 13:16:52,212 Iter 42150, Minibatch Loss= 0.5036, Training Accuracy= 0.7122, Minibatch error= 8.8%\n",
      "2017-09-04 13:20:04,694 Epoch 421, Average loss: 0.0582, learning rate: 0.0010\n",
      "2017-09-04 13:20:04,768 Verification error= 6.7%, loss= 0.3237\n",
      "2017-09-04 13:20:26,220 Iter 42200, Minibatch Loss= 0.7451, Training Accuracy= 0.7008, Minibatch error= 10.8%\n",
      "2017-09-04 13:23:42,979 Iter 42250, Minibatch Loss= 0.3817, Training Accuracy= 0.6969, Minibatch error= 10.1%\n",
      "2017-09-04 13:26:55,403 Epoch 422, Average loss: 0.0573, learning rate: 0.0010\n",
      "2017-09-04 13:26:55,478 Verification error= 6.1%, loss= 0.2621\n",
      "2017-09-04 13:27:16,760 Iter 42300, Minibatch Loss= 0.4274, Training Accuracy= 0.7232, Minibatch error= 8.8%\n",
      "2017-09-04 13:30:34,359 Iter 42350, Minibatch Loss= 0.1376, Training Accuracy= 0.7292, Minibatch error= 5.3%\n",
      "2017-09-04 13:33:47,713 Epoch 423, Average loss: 0.0608, learning rate: 0.0010\n",
      "2017-09-04 13:33:47,787 Verification error= 6.0%, loss= 0.3078\n",
      "2017-09-04 13:34:09,231 Iter 42400, Minibatch Loss= 0.1323, Training Accuracy= 0.7404, Minibatch error= 5.2%\n",
      "2017-09-04 13:37:27,019 Iter 42450, Minibatch Loss= 0.1694, Training Accuracy= 0.6763, Minibatch error= 5.4%\n",
      "2017-09-04 13:40:40,679 Epoch 424, Average loss: 0.0582, learning rate: 0.0010\n",
      "2017-09-04 13:40:40,757 Verification error= 6.6%, loss= 0.2995\n",
      "2017-09-04 13:41:02,067 Iter 42500, Minibatch Loss= 0.6896, Training Accuracy= 0.7289, Minibatch error= 7.1%\n",
      "2017-09-04 13:44:20,277 Iter 42550, Minibatch Loss= 0.1919, Training Accuracy= 0.7013, Minibatch error= 7.6%\n",
      "2017-09-04 13:47:34,532 Epoch 425, Average loss: 0.0592, learning rate: 0.0010\n",
      "2017-09-04 13:47:34,608 Verification error= 6.7%, loss= 0.3027\n",
      "2017-09-04 13:47:56,234 Iter 42600, Minibatch Loss= 0.1779, Training Accuracy= 0.6961, Minibatch error= 7.1%\n",
      "2017-09-04 13:51:14,701 Iter 42650, Minibatch Loss= 0.1991, Training Accuracy= 0.7185, Minibatch error= 6.5%\n",
      "2017-09-04 13:54:29,959 Epoch 426, Average loss: 0.0581, learning rate: 0.0010\n",
      "2017-09-04 13:54:30,033 Verification error= 6.1%, loss= 0.2248\n",
      "2017-09-04 13:54:51,659 Iter 42700, Minibatch Loss= 0.1174, Training Accuracy= 0.7161, Minibatch error= 4.7%\n",
      "2017-09-04 13:58:11,256 Iter 42750, Minibatch Loss= 0.1707, Training Accuracy= 0.7073, Minibatch error= 5.2%\n",
      "2017-09-04 14:01:26,534 Epoch 427, Average loss: 0.0578, learning rate: 0.0010\n",
      "2017-09-04 14:01:26,608 Verification error= 6.3%, loss= 0.2787\n",
      "2017-09-04 14:01:49,624 Iter 42800, Minibatch Loss= 0.5121, Training Accuracy= 0.7229, Minibatch error= 7.8%\n",
      "2017-09-04 14:05:09,428 Iter 42850, Minibatch Loss= 0.8220, Training Accuracy= 0.6797, Minibatch error= 11.2%\n",
      "2017-09-04 14:08:25,500 Epoch 428, Average loss: 0.0566, learning rate: 0.0010\n",
      "2017-09-04 14:08:25,575 Verification error= 6.2%, loss= 0.2942\n",
      "2017-09-04 14:08:47,297 Iter 42900, Minibatch Loss= 0.4087, Training Accuracy= 0.7055, Minibatch error= 9.3%\n",
      "2017-09-04 14:12:07,539 Iter 42950, Minibatch Loss= 0.4963, Training Accuracy= 0.7247, Minibatch error= 9.1%\n",
      "2017-09-04 14:15:23,707 Epoch 429, Average loss: 0.0557, learning rate: 0.0010\n",
      "2017-09-04 14:15:23,790 Verification error= 5.9%, loss= 0.2667\n",
      "2017-09-04 14:15:45,356 Iter 43000, Minibatch Loss= 0.1476, Training Accuracy= 0.7388, Minibatch error= 5.3%\n",
      "2017-09-04 14:19:05,907 Iter 43050, Minibatch Loss= 0.1311, Training Accuracy= 0.7451, Minibatch error= 4.9%\n",
      "2017-09-04 14:22:22,428 Epoch 430, Average loss: 0.0549, learning rate: 0.0010\n",
      "2017-09-04 14:22:22,503 Verification error= 7.6%, loss= 0.3404\n",
      "2017-09-04 14:22:44,271 Iter 43100, Minibatch Loss= 0.2291, Training Accuracy= 0.6599, Minibatch error= 6.6%\n",
      "2017-09-04 14:26:05,791 Iter 43150, Minibatch Loss= 0.5958, Training Accuracy= 0.7211, Minibatch error= 7.6%\n",
      "2017-09-04 14:29:23,086 Epoch 431, Average loss: 0.0549, learning rate: 0.0010\n",
      "2017-09-04 14:29:23,159 Verification error= 6.1%, loss= 0.2620\n",
      "2017-09-04 14:29:44,870 Iter 43200, Minibatch Loss= 0.1582, Training Accuracy= 0.7154, Minibatch error= 6.4%\n",
      "2017-09-04 14:33:06,618 Iter 43250, Minibatch Loss= 0.1511, Training Accuracy= 0.7143, Minibatch error= 6.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 14:36:24,045 Epoch 432, Average loss: 0.0562, learning rate: 0.0010\n",
      "2017-09-04 14:36:24,117 Verification error= 6.2%, loss= 0.2712\n",
      "2017-09-04 14:36:46,015 Iter 43300, Minibatch Loss= 0.1926, Training Accuracy= 0.7112, Minibatch error= 6.4%\n",
      "2017-09-04 14:40:08,257 Iter 43350, Minibatch Loss= 0.1186, Training Accuracy= 0.7078, Minibatch error= 5.1%\n",
      "2017-09-04 14:43:26,116 Epoch 433, Average loss: 0.0564, learning rate: 0.0010\n",
      "2017-09-04 14:43:26,188 Verification error= 6.8%, loss= 0.3150\n",
      "2017-09-04 14:43:48,011 Iter 43400, Minibatch Loss= 0.2054, Training Accuracy= 0.7044, Minibatch error= 6.2%\n",
      "2017-09-04 14:47:10,489 Iter 43450, Minibatch Loss= 0.4859, Training Accuracy= 0.7148, Minibatch error= 8.5%\n",
      "2017-09-04 14:50:28,762 Epoch 434, Average loss: 0.0541, learning rate: 0.0010\n",
      "2017-09-04 14:50:28,833 Verification error= 6.6%, loss= 0.3022\n",
      "2017-09-04 14:50:51,089 Iter 43500, Minibatch Loss= 0.7345, Training Accuracy= 0.6966, Minibatch error= 11.2%\n",
      "2017-09-04 14:54:13,819 Iter 43550, Minibatch Loss= 0.3967, Training Accuracy= 0.7159, Minibatch error= 9.3%\n",
      "2017-09-04 14:57:32,668 Epoch 435, Average loss: 0.0546, learning rate: 0.0010\n",
      "2017-09-04 14:57:32,740 Verification error= 6.5%, loss= 0.2952\n",
      "2017-09-04 14:57:54,578 Iter 43600, Minibatch Loss= 0.4830, Training Accuracy= 0.7318, Minibatch error= 9.1%\n",
      "2017-09-04 15:01:17,489 Iter 43650, Minibatch Loss= 0.1196, Training Accuracy= 0.7391, Minibatch error= 5.2%\n",
      "2017-09-04 15:04:36,789 Epoch 436, Average loss: 0.0544, learning rate: 0.0010\n",
      "2017-09-04 15:04:36,861 Verification error= 6.2%, loss= 0.2180\n",
      "2017-09-04 15:04:58,826 Iter 43700, Minibatch Loss= 0.1283, Training Accuracy= 0.7411, Minibatch error= 5.2%\n",
      "2017-09-04 15:08:22,591 Iter 43750, Minibatch Loss= 0.1580, Training Accuracy= 0.6701, Minibatch error= 5.4%\n",
      "2017-09-04 15:11:42,392 Epoch 437, Average loss: 0.0547, learning rate: 0.0010\n",
      "2017-09-04 15:11:42,467 Verification error= 5.7%, loss= 0.2300\n",
      "2017-09-04 15:12:04,717 Iter 43800, Minibatch Loss= 0.4952, Training Accuracy= 0.7313, Minibatch error= 6.7%\n",
      "2017-09-04 15:15:28,595 Iter 43850, Minibatch Loss= 0.2126, Training Accuracy= 0.7115, Minibatch error= 7.5%\n",
      "2017-09-04 15:18:48,545 Epoch 438, Average loss: 0.0539, learning rate: 0.0010\n",
      "2017-09-04 15:18:48,620 Verification error= 6.5%, loss= 0.2623\n",
      "2017-09-04 15:19:12,321 Iter 43900, Minibatch Loss= 0.2266, Training Accuracy= 0.6734, Minibatch error= 8.3%\n",
      "2017-09-04 15:22:37,017 Iter 43950, Minibatch Loss= 0.1354, Training Accuracy= 0.7219, Minibatch error= 5.7%\n",
      "2017-09-04 15:25:57,490 Epoch 439, Average loss: 0.0523, learning rate: 0.0010\n",
      "2017-09-04 15:25:57,562 Verification error= 5.9%, loss= 0.2270\n",
      "2017-09-04 15:26:19,640 Iter 44000, Minibatch Loss= 0.1136, Training Accuracy= 0.7143, Minibatch error= 4.9%\n",
      "2017-09-04 15:29:44,557 Iter 44050, Minibatch Loss= 0.1875, Training Accuracy= 0.7180, Minibatch error= 6.1%\n",
      "2017-09-04 15:33:05,410 Epoch 440, Average loss: 0.0535, learning rate: 0.0010\n",
      "2017-09-04 15:33:05,482 Verification error= 6.3%, loss= 0.2698\n",
      "2017-09-04 15:33:27,650 Iter 44100, Minibatch Loss= 0.5041, Training Accuracy= 0.7193, Minibatch error= 7.9%\n",
      "2017-09-04 15:36:53,302 Iter 44150, Minibatch Loss= 0.7423, Training Accuracy= 0.6974, Minibatch error= 11.2%\n",
      "2017-09-04 15:40:14,528 Epoch 441, Average loss: 0.0526, learning rate: 0.0010\n",
      "2017-09-04 15:40:14,608 Verification error= 6.5%, loss= 0.2933\n",
      "2017-09-04 15:40:36,923 Iter 44200, Minibatch Loss= 0.4951, Training Accuracy= 0.7102, Minibatch error= 9.8%\n",
      "2017-09-04 15:44:02,919 Iter 44250, Minibatch Loss= 0.2427, Training Accuracy= 0.7583, Minibatch error= 6.0%\n",
      "2017-09-04 15:47:24,613 Epoch 442, Average loss: 0.0556, learning rate: 0.0010\n",
      "2017-09-04 15:47:24,684 Verification error= 6.4%, loss= 0.2833\n",
      "2017-09-04 15:47:46,966 Iter 44300, Minibatch Loss= 0.1314, Training Accuracy= 0.7180, Minibatch error= 5.4%\n",
      "2017-09-04 15:51:13,255 Iter 44350, Minibatch Loss= 0.1598, Training Accuracy= 0.7326, Minibatch error= 5.3%\n",
      "2017-09-04 15:54:35,658 Epoch 443, Average loss: 0.0529, learning rate: 0.0010\n",
      "2017-09-04 15:54:35,730 Verification error= 6.6%, loss= 0.2990\n",
      "2017-09-04 15:54:58,132 Iter 44400, Minibatch Loss= 0.2615, Training Accuracy= 0.6404, Minibatch error= 7.2%\n",
      "2017-09-04 15:58:25,373 Iter 44450, Minibatch Loss= 0.5511, Training Accuracy= 0.7307, Minibatch error= 6.6%\n",
      "2017-09-04 16:01:48,365 Epoch 444, Average loss: 0.0547, learning rate: 0.0010\n",
      "2017-09-04 16:01:48,439 Verification error= 6.2%, loss= 0.2932\n",
      "2017-09-04 16:02:10,819 Iter 44500, Minibatch Loss= 0.1963, Training Accuracy= 0.7052, Minibatch error= 7.0%\n",
      "2017-09-04 16:05:37,962 Iter 44550, Minibatch Loss= 0.2356, Training Accuracy= 0.6784, Minibatch error= 7.4%\n",
      "2017-09-04 16:09:01,147 Epoch 445, Average loss: 0.0524, learning rate: 0.0010\n",
      "2017-09-04 16:09:01,220 Verification error= 6.9%, loss= 0.3477\n",
      "2017-09-04 16:09:24,376 Iter 44600, Minibatch Loss= 0.2623, Training Accuracy= 0.6922, Minibatch error= 7.4%\n",
      "2017-09-04 16:12:52,340 Iter 44650, Minibatch Loss= 0.1436, Training Accuracy= 0.7029, Minibatch error= 5.9%\n",
      "2017-09-04 16:16:15,770 Epoch 446, Average loss: 0.0500, learning rate: 0.0010\n",
      "2017-09-04 16:16:15,845 Verification error= 6.9%, loss= 0.3302\n",
      "2017-09-04 16:16:38,639 Iter 44700, Minibatch Loss= 0.2227, Training Accuracy= 0.6896, Minibatch error= 6.3%\n",
      "2017-09-04 16:20:07,458 Iter 44750, Minibatch Loss= 0.5742, Training Accuracy= 0.7096, Minibatch error= 8.5%\n",
      "2017-09-04 16:23:31,271 Epoch 447, Average loss: 0.0504, learning rate: 0.0010\n",
      "2017-09-04 16:23:31,345 Verification error= 6.0%, loss= 0.2590\n",
      "2017-09-04 16:23:54,257 Iter 44800, Minibatch Loss= 0.6942, Training Accuracy= 0.6974, Minibatch error= 10.7%\n",
      "2017-09-04 16:27:23,064 Iter 44850, Minibatch Loss= 0.4492, Training Accuracy= 0.7029, Minibatch error= 9.5%\n",
      "2017-09-04 16:30:47,707 Epoch 448, Average loss: 0.0521, learning rate: 0.0010\n",
      "2017-09-04 16:30:47,783 Verification error= 6.9%, loss= 0.2968\n",
      "2017-09-04 16:31:10,374 Iter 44900, Minibatch Loss= 0.4915, Training Accuracy= 0.7190, Minibatch error= 9.8%\n",
      "2017-09-04 16:34:39,285 Iter 44950, Minibatch Loss= 0.1522, Training Accuracy= 0.7253, Minibatch error= 6.0%\n",
      "2017-09-04 16:38:04,035 Epoch 449, Average loss: 0.0527, learning rate: 0.0010\n",
      "2017-09-04 16:38:04,109 Verification error= 6.3%, loss= 0.2633\n",
      "2017-09-04 16:38:28,287 Iter 45000, Minibatch Loss= 0.1323, Training Accuracy= 0.7349, Minibatch error= 4.8%\n",
      "2017-09-04 16:41:58,308 Iter 45050, Minibatch Loss= 0.1561, Training Accuracy= 0.6753, Minibatch error= 5.0%\n",
      "2017-09-04 16:45:23,644 Epoch 450, Average loss: 0.0515, learning rate: 0.0010\n",
      "2017-09-04 16:45:23,719 Verification error= 7.3%, loss= 0.3022\n",
      "2017-09-04 16:45:46,482 Iter 45100, Minibatch Loss= 0.5453, Training Accuracy= 0.7214, Minibatch error= 7.8%\n",
      "2017-09-04 16:49:16,636 Iter 45150, Minibatch Loss= 0.1854, Training Accuracy= 0.7094, Minibatch error= 7.1%\n",
      "2017-09-04 16:52:42,285 Epoch 451, Average loss: 0.0513, learning rate: 0.0010\n",
      "2017-09-04 16:52:42,360 Verification error= 6.7%, loss= 0.2724\n",
      "2017-09-04 16:53:05,154 Iter 45200, Minibatch Loss= 0.2746, Training Accuracy= 0.6893, Minibatch error= 8.9%\n",
      "2017-09-04 16:56:35,460 Iter 45250, Minibatch Loss= 0.2181, Training Accuracy= 0.7094, Minibatch error= 7.0%\n",
      "2017-09-04 17:00:01,283 Epoch 452, Average loss: 0.0503, learning rate: 0.0010\n",
      "2017-09-04 17:00:01,358 Verification error= 6.4%, loss= 0.3017\n",
      "2017-09-04 17:00:24,056 Iter 45300, Minibatch Loss= 0.1108, Training Accuracy= 0.7299, Minibatch error= 4.4%\n",
      "2017-09-04 17:03:54,946 Iter 45350, Minibatch Loss= 0.2376, Training Accuracy= 0.6995, Minibatch error= 6.0%\n",
      "2017-09-04 17:07:21,522 Epoch 453, Average loss: 0.0483, learning rate: 0.0010\n",
      "2017-09-04 17:07:21,595 Verification error= 6.6%, loss= 0.2903\n",
      "2017-09-04 17:07:44,560 Iter 45400, Minibatch Loss= 0.5732, Training Accuracy= 0.7206, Minibatch error= 8.8%\n",
      "2017-09-04 17:11:17,103 Iter 45450, Minibatch Loss= 0.7348, Training Accuracy= 0.6969, Minibatch error= 10.4%\n",
      "2017-09-04 17:14:44,734 Epoch 454, Average loss: 0.0489, learning rate: 0.0010\n",
      "2017-09-04 17:14:44,809 Verification error= 6.8%, loss= 0.3323\n",
      "2017-09-04 17:15:07,810 Iter 45500, Minibatch Loss= 0.4133, Training Accuracy= 0.6922, Minibatch error= 11.1%\n",
      "2017-09-04 17:18:39,763 Iter 45550, Minibatch Loss= 0.5503, Training Accuracy= 0.7260, Minibatch error= 9.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 17:22:07,027 Epoch 455, Average loss: 0.0477, learning rate: 0.0010\n",
      "2017-09-04 17:22:07,099 Verification error= 6.7%, loss= 0.3339\n",
      "2017-09-04 17:22:30,058 Iter 45600, Minibatch Loss= 0.1659, Training Accuracy= 0.7034, Minibatch error= 6.1%\n",
      "2017-09-04 17:26:02,295 Iter 45650, Minibatch Loss= 0.1295, Training Accuracy= 0.7268, Minibatch error= 5.4%\n",
      "2017-09-04 17:29:30,294 Epoch 456, Average loss: 0.0471, learning rate: 0.0010\n",
      "2017-09-04 17:29:30,366 Verification error= 7.7%, loss= 0.3983\n",
      "2017-09-04 17:29:53,308 Iter 45700, Minibatch Loss= 0.2203, Training Accuracy= 0.6594, Minibatch error= 6.0%\n",
      "2017-09-04 17:33:26,062 Iter 45750, Minibatch Loss= 0.6667, Training Accuracy= 0.7161, Minibatch error= 8.5%\n",
      "2017-09-04 17:36:54,529 Epoch 457, Average loss: 0.0486, learning rate: 0.0010\n",
      "2017-09-04 17:36:54,601 Verification error= 7.3%, loss= 0.3377\n",
      "2017-09-04 17:37:17,722 Iter 45800, Minibatch Loss= 0.2639, Training Accuracy= 0.7036, Minibatch error= 7.6%\n",
      "2017-09-04 17:40:50,754 Iter 45850, Minibatch Loss= 0.2864, Training Accuracy= 0.7055, Minibatch error= 8.6%\n",
      "2017-09-04 17:44:20,074 Epoch 458, Average loss: 0.0487, learning rate: 0.0010\n",
      "2017-09-04 17:44:20,145 Verification error= 6.3%, loss= 0.2769\n",
      "2017-09-04 17:44:43,404 Iter 45900, Minibatch Loss= 0.1667, Training Accuracy= 0.7307, Minibatch error= 6.0%\n",
      "2017-09-04 17:48:17,026 Iter 45950, Minibatch Loss= 0.1652, Training Accuracy= 0.6836, Minibatch error= 6.7%\n",
      "2017-09-04 17:51:46,450 Epoch 459, Average loss: 0.0462, learning rate: 0.0010\n",
      "2017-09-04 17:51:46,529 Verification error= 5.3%, loss= 0.2244\n",
      "2017-09-04 17:52:09,723 Iter 46000, Minibatch Loss= 0.1606, Training Accuracy= 0.7159, Minibatch error= 5.5%\n",
      "2017-09-04 17:55:43,843 Iter 46050, Minibatch Loss= 0.4873, Training Accuracy= 0.7174, Minibatch error= 8.5%\n",
      "2017-09-04 17:59:14,050 Epoch 460, Average loss: 0.0463, learning rate: 0.0010\n",
      "2017-09-04 17:59:14,122 Verification error= 6.1%, loss= 0.2808\n",
      "2017-09-04 17:59:38,929 Iter 46100, Minibatch Loss= 0.7039, Training Accuracy= 0.6870, Minibatch error= 11.5%\n",
      "2017-09-04 18:03:13,804 Iter 46150, Minibatch Loss= 0.4064, Training Accuracy= 0.7182, Minibatch error= 8.5%\n",
      "2017-09-04 18:06:44,046 Epoch 461, Average loss: 0.0462, learning rate: 0.0010\n",
      "2017-09-04 18:06:44,126 Verification error= 6.2%, loss= 0.3105\n",
      "2017-09-04 18:07:07,478 Iter 46200, Minibatch Loss= 0.5178, Training Accuracy= 0.7339, Minibatch error= 8.0%\n",
      "2017-09-04 18:10:43,096 Iter 46250, Minibatch Loss= 0.1488, Training Accuracy= 0.7141, Minibatch error= 5.5%\n",
      "2017-09-04 18:14:14,101 Epoch 462, Average loss: 0.0469, learning rate: 0.0010\n",
      "2017-09-04 18:14:14,172 Verification error= 7.2%, loss= 0.3692\n",
      "2017-09-04 18:14:37,781 Iter 46300, Minibatch Loss= 0.2015, Training Accuracy= 0.7211, Minibatch error= 6.7%\n",
      "2017-09-04 18:18:13,176 Iter 46350, Minibatch Loss= 0.2788, Training Accuracy= 0.6596, Minibatch error= 6.2%\n",
      "2017-09-04 18:21:44,480 Epoch 463, Average loss: 0.0456, learning rate: 0.0010\n",
      "2017-09-04 18:21:44,553 Verification error= 7.6%, loss= 0.4594\n",
      "2017-09-04 18:22:08,356 Iter 46400, Minibatch Loss= 0.8144, Training Accuracy= 0.7120, Minibatch error= 8.1%\n",
      "2017-09-04 18:25:44,437 Iter 46450, Minibatch Loss= 0.2298, Training Accuracy= 0.7130, Minibatch error= 7.3%\n",
      "2017-09-04 18:29:16,154 Epoch 464, Average loss: 0.0452, learning rate: 0.0010\n",
      "2017-09-04 18:29:16,226 Verification error= 5.8%, loss= 0.2608\n",
      "2017-09-04 18:29:39,752 Iter 46500, Minibatch Loss= 0.2747, Training Accuracy= 0.6896, Minibatch error= 7.9%\n",
      "2017-09-04 18:33:17,551 Iter 46550, Minibatch Loss= 0.1935, Training Accuracy= 0.7070, Minibatch error= 6.3%\n",
      "2017-09-04 18:36:49,681 Epoch 465, Average loss: 0.0456, learning rate: 0.0010\n",
      "2017-09-04 18:36:49,753 Verification error= 6.1%, loss= 0.2670\n",
      "2017-09-04 18:37:13,306 Iter 46600, Minibatch Loss= 0.1472, Training Accuracy= 0.6958, Minibatch error= 5.4%\n",
      "2017-09-04 18:40:50,769 Iter 46650, Minibatch Loss= 0.2609, Training Accuracy= 0.6854, Minibatch error= 6.2%\n",
      "2017-09-04 18:44:23,503 Epoch 466, Average loss: 0.0448, learning rate: 0.0010\n",
      "2017-09-04 18:44:23,575 Verification error= 6.6%, loss= 0.3502\n",
      "2017-09-04 18:44:47,432 Iter 46700, Minibatch Loss= 0.6016, Training Accuracy= 0.7044, Minibatch error= 9.0%\n",
      "2017-09-04 18:48:25,186 Iter 46750, Minibatch Loss= 0.8025, Training Accuracy= 0.6880, Minibatch error= 10.8%\n",
      "2017-09-04 18:51:58,200 Epoch 467, Average loss: 0.0457, learning rate: 0.0010\n",
      "2017-09-04 18:51:58,274 Verification error= 5.5%, loss= 0.2324\n",
      "2017-09-04 18:52:22,095 Iter 46800, Minibatch Loss= 0.2934, Training Accuracy= 0.7242, Minibatch error= 7.6%\n",
      "2017-09-04 18:55:59,914 Iter 46850, Minibatch Loss= 0.5370, Training Accuracy= 0.7193, Minibatch error= 9.0%\n",
      "2017-09-04 18:59:33,462 Epoch 468, Average loss: 0.0461, learning rate: 0.0010\n",
      "2017-09-04 18:59:33,534 Verification error= 6.7%, loss= 0.3274\n",
      "2017-09-04 18:59:57,343 Iter 46900, Minibatch Loss= 0.1474, Training Accuracy= 0.7146, Minibatch error= 5.6%\n",
      "2017-09-04 19:03:35,754 Iter 46950, Minibatch Loss= 0.1463, Training Accuracy= 0.7297, Minibatch error= 5.5%\n",
      "2017-09-04 19:07:09,710 Epoch 469, Average loss: 0.0446, learning rate: 0.0010\n",
      "2017-09-04 19:07:09,782 Verification error= 6.4%, loss= 0.3144\n",
      "2017-09-04 19:07:33,555 Iter 47000, Minibatch Loss= 0.1805, Training Accuracy= 0.6695, Minibatch error= 5.3%\n",
      "2017-09-04 19:11:12,269 Iter 47050, Minibatch Loss= 0.5227, Training Accuracy= 0.7292, Minibatch error= 7.4%\n",
      "2017-09-04 19:14:47,166 Epoch 470, Average loss: 0.0447, learning rate: 0.0010\n",
      "2017-09-04 19:14:47,239 Verification error= 6.4%, loss= 0.3640\n",
      "2017-09-04 19:15:12,653 Iter 47100, Minibatch Loss= 0.1977, Training Accuracy= 0.7341, Minibatch error= 5.8%\n",
      "2017-09-04 19:18:52,067 Iter 47150, Minibatch Loss= 0.3057, Training Accuracy= 0.6661, Minibatch error= 8.3%\n",
      "2017-09-04 19:22:27,133 Epoch 471, Average loss: 0.0426, learning rate: 0.0010\n",
      "2017-09-04 19:22:27,205 Verification error= 6.0%, loss= 0.2645\n",
      "2017-09-04 19:22:51,012 Iter 47200, Minibatch Loss= 0.1788, Training Accuracy= 0.7240, Minibatch error= 5.8%\n",
      "2017-09-04 19:26:31,959 Iter 47250, Minibatch Loss= 0.1600, Training Accuracy= 0.6943, Minibatch error= 5.6%\n",
      "2017-09-04 19:30:08,873 Epoch 472, Average loss: 0.0437, learning rate: 0.0010\n",
      "2017-09-04 19:30:08,944 Verification error= 5.9%, loss= 0.2391\n",
      "2017-09-04 19:30:33,100 Iter 47300, Minibatch Loss= 0.2163, Training Accuracy= 0.7005, Minibatch error= 5.9%\n",
      "2017-09-04 19:34:14,700 Iter 47350, Minibatch Loss= 0.5122, Training Accuracy= 0.7258, Minibatch error= 7.9%\n",
      "2017-09-04 19:37:52,163 Epoch 473, Average loss: 0.0440, learning rate: 0.0010\n",
      "2017-09-04 19:37:52,237 Verification error= 5.7%, loss= 0.2336\n",
      "2017-09-04 19:38:16,179 Iter 47400, Minibatch Loss= 0.7915, Training Accuracy= 0.6797, Minibatch error= 11.7%\n",
      "2017-09-04 19:41:58,520 Iter 47450, Minibatch Loss= 0.4515, Training Accuracy= 0.7182, Minibatch error= 8.6%\n",
      "2017-09-04 19:45:36,069 Epoch 474, Average loss: 0.0439, learning rate: 0.0010\n",
      "2017-09-04 19:45:36,141 Verification error= 7.0%, loss= 0.3079\n",
      "2017-09-04 19:46:00,316 Iter 47500, Minibatch Loss= 0.5293, Training Accuracy= 0.7190, Minibatch error= 9.8%\n",
      "2017-09-04 19:49:43,141 Iter 47550, Minibatch Loss= 0.1606, Training Accuracy= 0.7107, Minibatch error= 5.8%\n",
      "2017-09-04 19:53:21,232 Epoch 475, Average loss: 0.0421, learning rate: 0.0010\n",
      "2017-09-04 19:53:21,305 Verification error= 6.7%, loss= 0.3323\n",
      "2017-09-04 19:53:45,563 Iter 47600, Minibatch Loss= 0.1375, Training Accuracy= 0.7138, Minibatch error= 5.2%\n",
      "2017-09-04 19:57:28,514 Iter 47650, Minibatch Loss= 0.1808, Training Accuracy= 0.6898, Minibatch error= 5.1%\n",
      "2017-09-04 20:01:06,955 Epoch 476, Average loss: 0.0414, learning rate: 0.0010\n",
      "2017-09-04 20:01:07,034 Verification error= 7.5%, loss= 0.3674\n",
      "2017-09-04 20:01:31,116 Iter 47700, Minibatch Loss= 0.7801, Training Accuracy= 0.7174, Minibatch error= 8.1%\n",
      "2017-09-04 20:05:15,740 Iter 47750, Minibatch Loss= 0.2707, Training Accuracy= 0.7354, Minibatch error= 6.9%\n",
      "2017-09-04 20:08:54,721 Epoch 477, Average loss: 0.0430, learning rate: 0.0010\n",
      "2017-09-04 20:08:54,797 Verification error= 7.6%, loss= 0.3729\n",
      "2017-09-04 20:09:19,300 Iter 47800, Minibatch Loss= 0.3238, Training Accuracy= 0.6766, Minibatch error= 8.4%\n",
      "2017-09-04 20:13:04,393 Iter 47850, Minibatch Loss= 0.2341, Training Accuracy= 0.7091, Minibatch error= 6.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 20:16:43,700 Epoch 478, Average loss: 0.0429, learning rate: 0.0010\n",
      "2017-09-04 20:16:43,780 Verification error= 7.4%, loss= 0.4211\n",
      "2017-09-04 20:17:08,459 Iter 47900, Minibatch Loss= 0.1843, Training Accuracy= 0.7081, Minibatch error= 5.8%\n",
      "2017-09-04 20:20:53,507 Iter 47950, Minibatch Loss= 0.1772, Training Accuracy= 0.7060, Minibatch error= 5.8%\n",
      "2017-09-04 20:24:33,392 Epoch 479, Average loss: 0.0419, learning rate: 0.0010\n",
      "2017-09-04 20:24:33,464 Verification error= 5.7%, loss= 0.2531\n",
      "2017-09-04 20:24:57,777 Iter 48000, Minibatch Loss= 0.4361, Training Accuracy= 0.7419, Minibatch error= 7.2%\n",
      "2017-09-04 20:28:42,526 Iter 48050, Minibatch Loss= 1.1977, Training Accuracy= 0.6635, Minibatch error= 14.1%\n",
      "2017-09-04 20:32:22,923 Epoch 480, Average loss: 0.0423, learning rate: 0.0010\n",
      "2017-09-04 20:32:22,995 Verification error= 7.1%, loss= 0.3157\n",
      "2017-09-04 20:32:47,282 Iter 48100, Minibatch Loss= 0.4341, Training Accuracy= 0.7091, Minibatch error= 10.3%\n",
      "2017-09-04 20:36:32,805 Iter 48150, Minibatch Loss= 0.4672, Training Accuracy= 0.7346, Minibatch error= 8.6%\n",
      "2017-09-04 20:40:13,574 Epoch 481, Average loss: 0.0392, learning rate: 0.0010\n",
      "2017-09-04 20:40:13,646 Verification error= 6.4%, loss= 0.3142\n",
      "2017-09-04 20:40:39,527 Iter 48200, Minibatch Loss= 0.1512, Training Accuracy= 0.7190, Minibatch error= 5.5%\n",
      "2017-09-04 20:44:25,001 Iter 48250, Minibatch Loss= 0.1713, Training Accuracy= 0.7208, Minibatch error= 6.6%\n",
      "2017-09-04 20:48:06,454 Epoch 482, Average loss: 0.0427, learning rate: 0.0010\n",
      "2017-09-04 20:48:06,526 Verification error= 7.1%, loss= 0.3236\n",
      "2017-09-04 20:48:31,203 Iter 48300, Minibatch Loss= 0.2182, Training Accuracy= 0.6766, Minibatch error= 5.6%\n",
      "2017-09-04 20:52:18,541 Iter 48350, Minibatch Loss= 0.7396, Training Accuracy= 0.7154, Minibatch error= 8.2%\n",
      "2017-09-04 20:56:01,347 Epoch 483, Average loss: 0.0424, learning rate: 0.0010\n",
      "2017-09-04 20:56:01,426 Verification error= 5.9%, loss= 0.2659\n",
      "2017-09-04 20:56:25,908 Iter 48400, Minibatch Loss= 0.1809, Training Accuracy= 0.7115, Minibatch error= 5.8%\n",
      "2017-09-04 21:00:13,960 Iter 48450, Minibatch Loss= 0.2147, Training Accuracy= 0.6977, Minibatch error= 7.1%\n",
      "2017-09-04 21:03:57,282 Epoch 484, Average loss: 0.0416, learning rate: 0.0010\n",
      "2017-09-04 21:03:57,354 Verification error= 5.4%, loss= 0.2455\n",
      "2017-09-04 21:04:22,417 Iter 48500, Minibatch Loss= 0.1729, Training Accuracy= 0.7310, Minibatch error= 5.8%\n",
      "2017-09-04 21:08:10,342 Iter 48550, Minibatch Loss= 0.1262, Training Accuracy= 0.7349, Minibatch error= 4.3%\n",
      "2017-09-04 21:11:53,999 Epoch 485, Average loss: 0.0412, learning rate: 0.0010\n",
      "2017-09-04 21:11:54,074 Verification error= 5.8%, loss= 0.2394\n",
      "2017-09-04 21:12:18,583 Iter 48600, Minibatch Loss= 0.2033, Training Accuracy= 0.7143, Minibatch error= 5.8%\n",
      "2017-09-04 21:16:07,102 Iter 48650, Minibatch Loss= 0.3831, Training Accuracy= 0.7305, Minibatch error= 7.1%\n",
      "2017-09-04 21:19:51,153 Epoch 486, Average loss: 0.0410, learning rate: 0.0010\n",
      "2017-09-04 21:19:51,232 Verification error= 6.6%, loss= 0.3402\n",
      "2017-09-04 21:20:16,196 Iter 48700, Minibatch Loss= 0.9427, Training Accuracy= 0.6888, Minibatch error= 12.0%\n",
      "2017-09-04 21:24:05,696 Iter 48750, Minibatch Loss= 0.4547, Training Accuracy= 0.7224, Minibatch error= 9.2%\n",
      "2017-09-04 21:27:50,440 Epoch 487, Average loss: 0.0393, learning rate: 0.0010\n",
      "2017-09-04 21:27:50,516 Verification error= 6.2%, loss= 0.3149\n",
      "2017-09-04 21:28:15,627 Iter 48800, Minibatch Loss= 0.5019, Training Accuracy= 0.7339, Minibatch error= 8.8%\n",
      "2017-09-04 21:32:05,602 Iter 48850, Minibatch Loss= 0.1731, Training Accuracy= 0.7255, Minibatch error= 5.6%\n",
      "2017-09-04 21:35:50,312 Epoch 488, Average loss: 0.0401, learning rate: 0.0010\n",
      "2017-09-04 21:35:50,395 Verification error= 6.8%, loss= 0.3927\n",
      "2017-09-04 21:36:15,303 Iter 48900, Minibatch Loss= 0.1907, Training Accuracy= 0.7313, Minibatch error= 6.1%\n",
      "2017-09-04 21:40:05,411 Iter 48950, Minibatch Loss= 0.2270, Training Accuracy= 0.6836, Minibatch error= 5.2%\n",
      "2017-09-04 21:43:50,630 Epoch 489, Average loss: 0.0378, learning rate: 0.0010\n",
      "2017-09-04 21:43:50,705 Verification error= 7.1%, loss= 0.3651\n",
      "2017-09-04 21:44:15,763 Iter 49000, Minibatch Loss= 0.6445, Training Accuracy= 0.7307, Minibatch error= 7.6%\n",
      "2017-09-04 21:48:06,306 Iter 49050, Minibatch Loss= 0.1814, Training Accuracy= 0.7307, Minibatch error= 6.0%\n",
      "2017-09-04 21:51:52,457 Epoch 490, Average loss: 0.0398, learning rate: 0.0010\n",
      "2017-09-04 21:51:52,531 Verification error= 7.0%, loss= 0.3565\n",
      "2017-09-04 21:52:17,826 Iter 49100, Minibatch Loss= 0.3323, Training Accuracy= 0.6815, Minibatch error= 8.5%\n",
      "2017-09-04 21:56:08,913 Iter 49150, Minibatch Loss= 0.1699, Training Accuracy= 0.7219, Minibatch error= 5.6%\n",
      "2017-09-04 21:59:55,069 Epoch 491, Average loss: 0.0397, learning rate: 0.0010\n",
      "2017-09-04 21:59:55,148 Verification error= 4.9%, loss= 0.1706\n",
      "2017-09-04 22:00:20,036 Iter 49200, Minibatch Loss= 0.1100, Training Accuracy= 0.7318, Minibatch error= 3.4%\n",
      "2017-09-04 22:04:11,221 Iter 49250, Minibatch Loss= 0.2074, Training Accuracy= 0.6927, Minibatch error= 5.8%\n",
      "2017-09-04 22:07:57,878 Epoch 492, Average loss: 0.0387, learning rate: 0.0010\n",
      "2017-09-04 22:07:57,954 Verification error= 5.9%, loss= 0.2443\n",
      "2017-09-04 22:08:24,565 Iter 49300, Minibatch Loss= 0.4742, Training Accuracy= 0.7349, Minibatch error= 7.4%\n",
      "2017-09-04 22:12:16,245 Iter 49350, Minibatch Loss= 0.9882, Training Accuracy= 0.6945, Minibatch error= 11.2%\n",
      "2017-09-04 22:16:03,237 Epoch 493, Average loss: 0.0386, learning rate: 0.0010\n",
      "2017-09-04 22:16:03,316 Verification error= 6.0%, loss= 0.2492\n",
      "2017-09-04 22:16:28,305 Iter 49400, Minibatch Loss= 0.4196, Training Accuracy= 0.7357, Minibatch error= 7.7%\n",
      "2017-09-04 22:20:20,605 Iter 49450, Minibatch Loss= 0.4150, Training Accuracy= 0.7477, Minibatch error= 7.8%\n",
      "2017-09-04 22:24:07,792 Epoch 494, Average loss: 0.0379, learning rate: 0.0010\n",
      "2017-09-04 22:24:07,864 Verification error= 6.9%, loss= 0.3353\n",
      "2017-09-04 22:24:32,889 Iter 49500, Minibatch Loss= 0.2006, Training Accuracy= 0.7083, Minibatch error= 6.9%\n",
      "2017-09-04 22:28:25,049 Iter 49550, Minibatch Loss= 0.0871, Training Accuracy= 0.7581, Minibatch error= 3.7%\n",
      "2017-09-04 22:32:12,990 Epoch 495, Average loss: 0.0390, learning rate: 0.0010\n",
      "2017-09-04 22:32:13,064 Verification error= 6.1%, loss= 0.2437\n",
      "2017-09-04 22:32:38,187 Iter 49600, Minibatch Loss= 0.1952, Training Accuracy= 0.6786, Minibatch error= 6.1%\n",
      "2017-09-04 22:36:30,624 Iter 49650, Minibatch Loss= 0.5279, Training Accuracy= 0.7234, Minibatch error= 7.0%\n",
      "2017-09-04 22:40:18,965 Epoch 496, Average loss: 0.0396, learning rate: 0.0010\n",
      "2017-09-04 22:40:19,040 Verification error= 5.9%, loss= 0.2378\n",
      "2017-09-04 22:40:44,426 Iter 49700, Minibatch Loss= 0.1418, Training Accuracy= 0.7424, Minibatch error= 5.2%\n",
      "2017-09-04 22:44:37,869 Iter 49750, Minibatch Loss= 0.2028, Training Accuracy= 0.7120, Minibatch error= 7.0%\n",
      "2017-09-04 22:48:27,118 Epoch 497, Average loss: 0.0381, learning rate: 0.0010\n",
      "2017-09-04 22:48:27,201 Verification error= 6.0%, loss= 0.2680\n",
      "2017-09-04 22:48:52,653 Iter 49800, Minibatch Loss= 0.1355, Training Accuracy= 0.7448, Minibatch error= 5.0%\n",
      "2017-09-04 22:52:46,681 Iter 49850, Minibatch Loss= 0.1359, Training Accuracy= 0.7336, Minibatch error= 4.4%\n",
      "2017-09-04 22:56:35,671 Epoch 498, Average loss: 0.0376, learning rate: 0.0010\n",
      "2017-09-04 22:56:35,747 Verification error= 6.1%, loss= 0.2827\n",
      "2017-09-04 22:57:01,072 Iter 49900, Minibatch Loss= 0.2134, Training Accuracy= 0.7023, Minibatch error= 5.7%\n",
      "2017-09-04 23:00:55,385 Iter 49950, Minibatch Loss= 0.6905, Training Accuracy= 0.7180, Minibatch error= 9.1%\n",
      "2017-09-04 23:04:45,319 Epoch 499, Average loss: 0.0374, learning rate: 0.0010\n",
      "2017-09-04 23:04:45,396 Verification error= 6.7%, loss= 0.3365\n",
      "2017-09-04 23:05:11,013 Iter 50000, Minibatch Loss= 1.0910, Training Accuracy= 0.6758, Minibatch error= 11.9%\n",
      "2017-09-04 23:09:06,187 Iter 50050, Minibatch Loss= 0.3839, Training Accuracy= 0.7443, Minibatch error= 7.4%\n",
      "2017-09-04 23:12:57,108 Epoch 500, Average loss: 0.0369, learning rate: 0.0010\n",
      "2017-09-04 23:12:57,184 Verification error= 6.2%, loss= 0.2864\n",
      "2017-09-04 23:13:22,511 Iter 50100, Minibatch Loss= 0.5602, Training Accuracy= 0.7245, Minibatch error= 9.2%\n",
      "2017-09-04 23:17:17,743 Iter 50150, Minibatch Loss= 0.1854, Training Accuracy= 0.7268, Minibatch error= 5.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 23:21:08,446 Epoch 501, Average loss: 0.0370, learning rate: 0.0010\n",
      "2017-09-04 23:21:08,517 Verification error= 6.3%, loss= 0.2818\n",
      "2017-09-04 23:21:34,110 Iter 50200, Minibatch Loss= 0.1498, Training Accuracy= 0.7107, Minibatch error= 5.8%\n",
      "2017-09-04 23:25:29,844 Iter 50250, Minibatch Loss= 0.1844, Training Accuracy= 0.6753, Minibatch error= 4.9%\n",
      "2017-09-04 23:29:21,399 Epoch 502, Average loss: 0.0370, learning rate: 0.0010\n",
      "2017-09-04 23:29:21,476 Verification error= 5.1%, loss= 0.1846\n",
      "2017-09-04 23:29:47,122 Iter 50300, Minibatch Loss= 0.4475, Training Accuracy= 0.7354, Minibatch error= 6.1%\n",
      "2017-09-04 23:33:43,759 Iter 50350, Minibatch Loss= 0.1397, Training Accuracy= 0.7372, Minibatch error= 5.3%\n",
      "2017-09-04 23:37:35,587 Epoch 503, Average loss: 0.0385, learning rate: 0.0010\n",
      "2017-09-04 23:37:35,661 Verification error= 5.3%, loss= 0.2344\n",
      "2017-09-04 23:38:01,270 Iter 50400, Minibatch Loss= 0.1963, Training Accuracy= 0.6833, Minibatch error= 6.8%\n",
      "2017-09-04 23:41:58,139 Iter 50450, Minibatch Loss= 0.1399, Training Accuracy= 0.7266, Minibatch error= 5.5%\n",
      "2017-09-04 23:45:50,400 Epoch 504, Average loss: 0.0412, learning rate: 0.0010\n",
      "2017-09-04 23:45:50,472 Verification error= 5.9%, loss= 0.2523\n",
      "2017-09-04 23:46:17,558 Iter 50500, Minibatch Loss= 0.1460, Training Accuracy= 0.7260, Minibatch error= 5.0%\n",
      "2017-09-04 23:50:14,804 Iter 50550, Minibatch Loss= 0.2427, Training Accuracy= 0.6943, Minibatch error= 6.0%\n",
      "2017-09-04 23:54:07,285 Epoch 505, Average loss: 0.0358, learning rate: 0.0010\n",
      "2017-09-04 23:54:07,357 Verification error= 6.9%, loss= 0.3532\n",
      "2017-09-04 23:54:32,845 Iter 50600, Minibatch Loss= 0.6433, Training Accuracy= 0.7013, Minibatch error= 9.2%\n",
      "2017-09-04 23:58:30,831 Iter 50650, Minibatch Loss= 0.8414, Training Accuracy= 0.7023, Minibatch error= 10.3%\n",
      "2017-09-05 00:02:23,862 Epoch 506, Average loss: 0.0358, learning rate: 0.0010\n",
      "2017-09-05 00:02:23,933 Verification error= 6.2%, loss= 0.2956\n",
      "2017-09-05 00:02:49,454 Iter 50700, Minibatch Loss= 0.3894, Training Accuracy= 0.7245, Minibatch error= 8.5%\n",
      "2017-09-05 00:06:47,532 Iter 50750, Minibatch Loss= 0.4228, Training Accuracy= 0.7539, Minibatch error= 7.3%\n",
      "2017-09-05 00:10:41,394 Epoch 507, Average loss: 0.0355, learning rate: 0.0010\n",
      "2017-09-05 00:10:41,467 Verification error= 5.8%, loss= 0.2416\n",
      "2017-09-05 00:11:07,118 Iter 50800, Minibatch Loss= 0.1713, Training Accuracy= 0.7326, Minibatch error= 5.9%\n",
      "2017-09-05 00:15:05,690 Iter 50850, Minibatch Loss= 0.1289, Training Accuracy= 0.7542, Minibatch error= 4.7%\n",
      "2017-09-05 00:18:59,580 Epoch 508, Average loss: 0.0359, learning rate: 0.0010\n",
      "2017-09-05 00:18:59,652 Verification error= 5.4%, loss= 0.2360\n",
      "2017-09-05 00:19:25,668 Iter 50900, Minibatch Loss= 0.1284, Training Accuracy= 0.6964, Minibatch error= 4.5%\n",
      "2017-09-05 00:23:24,573 Iter 50950, Minibatch Loss= 0.5535, Training Accuracy= 0.7471, Minibatch error= 6.3%\n",
      "2017-09-05 00:27:18,642 Epoch 509, Average loss: 0.0363, learning rate: 0.0010\n",
      "2017-09-05 00:27:18,719 Verification error= 5.8%, loss= 0.2505\n",
      "2017-09-05 00:27:44,505 Iter 51000, Minibatch Loss= 0.1782, Training Accuracy= 0.7557, Minibatch error= 5.8%\n",
      "2017-09-05 00:31:44,454 Iter 51050, Minibatch Loss= 0.2319, Training Accuracy= 0.6922, Minibatch error= 7.4%\n",
      "2017-09-05 00:35:39,181 Epoch 510, Average loss: 0.0374, learning rate: 0.0010\n",
      "2017-09-05 00:35:39,252 Verification error= 5.9%, loss= 0.2894\n",
      "2017-09-05 00:36:05,007 Iter 51100, Minibatch Loss= 0.1696, Training Accuracy= 0.7393, Minibatch error= 5.3%\n",
      "2017-09-05 00:40:05,151 Iter 51150, Minibatch Loss= 0.1323, Training Accuracy= 0.7341, Minibatch error= 4.2%\n",
      "2017-09-05 00:44:00,294 Epoch 511, Average loss: 0.0343, learning rate: 0.0010\n",
      "2017-09-05 00:44:00,367 Verification error= 6.0%, loss= 0.2555\n",
      "2017-09-05 00:44:26,554 Iter 51200, Minibatch Loss= 0.2299, Training Accuracy= 0.7128, Minibatch error= 6.0%\n",
      "2017-09-05 00:48:26,964 Iter 51250, Minibatch Loss= 0.4698, Training Accuracy= 0.7354, Minibatch error= 7.7%\n",
      "2017-09-05 00:52:22,557 Epoch 512, Average loss: 0.0352, learning rate: 0.0010\n",
      "2017-09-05 00:52:22,637 Verification error= 6.6%, loss= 0.3191\n",
      "2017-09-05 00:52:48,558 Iter 51300, Minibatch Loss= 0.9517, Training Accuracy= 0.7102, Minibatch error= 10.3%\n",
      "2017-09-05 00:56:49,707 Iter 51350, Minibatch Loss= 0.5417, Training Accuracy= 0.7349, Minibatch error= 8.8%\n",
      "2017-09-05 01:00:45,810 Epoch 513, Average loss: 0.0355, learning rate: 0.0010\n",
      "2017-09-05 01:00:45,882 Verification error= 6.2%, loss= 0.2913\n",
      "2017-09-05 01:01:11,947 Iter 51400, Minibatch Loss= 0.5832, Training Accuracy= 0.7396, Minibatch error= 8.6%\n",
      "2017-09-05 01:05:13,050 Iter 51450, Minibatch Loss= 0.2217, Training Accuracy= 0.7359, Minibatch error= 6.6%\n",
      "2017-09-05 01:09:09,335 Epoch 514, Average loss: 0.0353, learning rate: 0.0010\n",
      "2017-09-05 01:09:09,408 Verification error= 6.0%, loss= 0.2795\n",
      "2017-09-05 01:09:37,390 Iter 51500, Minibatch Loss= 0.2013, Training Accuracy= 0.7516, Minibatch error= 5.6%\n",
      "2017-09-05 01:13:39,352 Iter 51550, Minibatch Loss= 0.1496, Training Accuracy= 0.7013, Minibatch error= 4.9%\n",
      "2017-09-05 01:17:35,813 Epoch 515, Average loss: 0.0345, learning rate: 0.0010\n",
      "2017-09-05 01:17:35,885 Verification error= 5.3%, loss= 0.2470\n",
      "2017-09-05 01:18:01,875 Iter 51600, Minibatch Loss= 0.4916, Training Accuracy= 0.7672, Minibatch error= 5.9%\n",
      "2017-09-05 01:22:03,678 Iter 51650, Minibatch Loss= 0.2157, Training Accuracy= 0.7464, Minibatch error= 6.6%\n",
      "2017-09-05 01:26:01,451 Epoch 516, Average loss: 0.0363, learning rate: 0.0010\n",
      "2017-09-05 01:26:01,522 Verification error= 6.6%, loss= 0.3090\n",
      "2017-09-05 01:26:27,595 Iter 51700, Minibatch Loss= 0.2428, Training Accuracy= 0.6977, Minibatch error= 7.6%\n",
      "2017-09-05 01:30:30,490 Iter 51750, Minibatch Loss= 0.1939, Training Accuracy= 0.7318, Minibatch error= 6.5%\n",
      "2017-09-05 01:34:28,105 Epoch 517, Average loss: 0.0342, learning rate: 0.0010\n",
      "2017-09-05 01:34:28,176 Verification error= 6.8%, loss= 0.3579\n",
      "2017-09-05 01:34:54,240 Iter 51800, Minibatch Loss= 0.1323, Training Accuracy= 0.7271, Minibatch error= 4.7%\n",
      "2017-09-05 01:38:57,610 Iter 51850, Minibatch Loss= 0.2750, Training Accuracy= 0.6872, Minibatch error= 6.5%\n",
      "2017-09-05 01:42:55,778 Epoch 518, Average loss: 0.0340, learning rate: 0.0010\n",
      "2017-09-05 01:42:55,850 Verification error= 6.2%, loss= 0.2702\n",
      "2017-09-05 01:43:22,029 Iter 51900, Minibatch Loss= 0.4832, Training Accuracy= 0.7336, Minibatch error= 8.7%\n",
      "2017-09-05 01:47:25,275 Iter 51950, Minibatch Loss= 0.8503, Training Accuracy= 0.7172, Minibatch error= 9.6%\n",
      "2017-09-05 01:51:23,831 Epoch 519, Average loss: 0.0343, learning rate: 0.0010\n",
      "2017-09-05 01:51:23,911 Verification error= 6.9%, loss= 0.2970\n",
      "2017-09-05 01:51:49,978 Iter 52000, Minibatch Loss= 0.4187, Training Accuracy= 0.7237, Minibatch error= 10.0%\n",
      "2017-09-05 01:55:53,935 Iter 52050, Minibatch Loss= 0.5454, Training Accuracy= 0.7615, Minibatch error= 7.6%\n",
      "2017-09-05 01:59:52,653 Epoch 520, Average loss: 0.0340, learning rate: 0.0010\n",
      "2017-09-05 01:59:52,725 Verification error= 6.8%, loss= 0.3378\n",
      "2017-09-05 02:00:19,968 Iter 52100, Minibatch Loss= 0.2077, Training Accuracy= 0.7318, Minibatch error= 6.9%\n",
      "2017-09-05 02:04:24,427 Iter 52150, Minibatch Loss= 0.1140, Training Accuracy= 0.7682, Minibatch error= 3.8%\n",
      "2017-09-05 02:08:23,919 Epoch 521, Average loss: 0.0331, learning rate: 0.0010\n",
      "2017-09-05 02:08:23,991 Verification error= 5.7%, loss= 0.2618\n",
      "2017-09-05 02:08:50,167 Iter 52200, Minibatch Loss= 0.1839, Training Accuracy= 0.6927, Minibatch error= 5.6%\n",
      "2017-09-05 02:12:54,740 Iter 52250, Minibatch Loss= 0.7026, Training Accuracy= 0.7424, Minibatch error= 7.4%\n",
      "2017-09-05 02:16:54,004 Epoch 522, Average loss: 0.0323, learning rate: 0.0010\n",
      "2017-09-05 02:16:54,084 Verification error= 6.1%, loss= 0.2733\n",
      "2017-09-05 02:17:20,467 Iter 52300, Minibatch Loss= 0.1870, Training Accuracy= 0.7260, Minibatch error= 6.0%\n",
      "2017-09-05 02:21:25,665 Iter 52350, Minibatch Loss= 0.2371, Training Accuracy= 0.7057, Minibatch error= 7.1%\n",
      "2017-09-05 02:25:26,544 Epoch 523, Average loss: 0.0330, learning rate: 0.0010\n",
      "2017-09-05 02:25:26,616 Verification error= 6.9%, loss= 0.3136\n",
      "2017-09-05 02:25:53,061 Iter 52400, Minibatch Loss= 0.2216, Training Accuracy= 0.7099, Minibatch error= 6.4%\n",
      "2017-09-05 02:29:58,621 Iter 52450, Minibatch Loss= 0.1525, Training Accuracy= 0.7302, Minibatch error= 4.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 02:33:59,917 Epoch 524, Average loss: 0.0332, learning rate: 0.0010\n",
      "2017-09-05 02:33:59,989 Verification error= 5.6%, loss= 0.2473\n",
      "2017-09-05 02:34:26,480 Iter 52500, Minibatch Loss= 0.2313, Training Accuracy= 0.7094, Minibatch error= 6.3%\n",
      "2017-09-05 02:38:33,247 Iter 52550, Minibatch Loss= 0.6045, Training Accuracy= 0.7315, Minibatch error= 9.1%\n",
      "2017-09-05 02:42:35,012 Epoch 525, Average loss: 0.0335, learning rate: 0.0010\n",
      "2017-09-05 02:42:35,085 Verification error= 5.8%, loss= 0.2807\n",
      "2017-09-05 02:43:01,579 Iter 52600, Minibatch Loss= 0.8774, Training Accuracy= 0.7057, Minibatch error= 10.3%\n",
      "2017-09-05 02:47:08,360 Iter 52650, Minibatch Loss= 0.4206, Training Accuracy= 0.7122, Minibatch error= 9.0%\n",
      "2017-09-05 02:51:10,396 Epoch 526, Average loss: 0.0325, learning rate: 0.0010\n",
      "2017-09-05 02:51:10,468 Verification error= 6.8%, loss= 0.3151\n",
      "2017-09-05 02:51:38,496 Iter 52700, Minibatch Loss= 0.6683, Training Accuracy= 0.7276, Minibatch error= 10.6%\n",
      "2017-09-05 02:55:46,319 Iter 52750, Minibatch Loss= 0.1602, Training Accuracy= 0.7305, Minibatch error= 5.8%\n",
      "2017-09-05 02:59:48,574 Epoch 527, Average loss: 0.0322, learning rate: 0.0010\n",
      "2017-09-05 02:59:48,646 Verification error= 6.1%, loss= 0.3037\n",
      "2017-09-05 03:00:15,140 Iter 52800, Minibatch Loss= 0.2120, Training Accuracy= 0.7469, Minibatch error= 5.5%\n",
      "2017-09-05 03:04:22,377 Iter 52850, Minibatch Loss= 0.1591, Training Accuracy= 0.6948, Minibatch error= 4.7%\n",
      "2017-09-05 03:08:25,300 Epoch 528, Average loss: 0.0335, learning rate: 0.0010\n",
      "2017-09-05 03:08:25,373 Verification error= 5.4%, loss= 0.2027\n",
      "2017-09-05 03:08:51,872 Iter 52900, Minibatch Loss= 0.4691, Training Accuracy= 0.7589, Minibatch error= 6.2%\n",
      "2017-09-05 03:12:59,977 Iter 52950, Minibatch Loss= 0.1697, Training Accuracy= 0.7385, Minibatch error= 5.8%\n",
      "2017-09-05 03:17:02,943 Epoch 529, Average loss: 0.0313, learning rate: 0.0010\n",
      "2017-09-05 03:17:03,015 Verification error= 5.9%, loss= 0.2741\n",
      "2017-09-05 03:17:29,568 Iter 53000, Minibatch Loss= 0.2634, Training Accuracy= 0.7023, Minibatch error= 7.7%\n",
      "2017-09-05 03:21:38,481 Iter 53050, Minibatch Loss= 0.2105, Training Accuracy= 0.7260, Minibatch error= 6.4%\n",
      "2017-09-05 03:25:41,860 Epoch 530, Average loss: 0.0327, learning rate: 0.0010\n",
      "2017-09-05 03:25:41,932 Verification error= 5.0%, loss= 0.1879\n",
      "2017-09-05 03:26:08,475 Iter 53100, Minibatch Loss= 0.1406, Training Accuracy= 0.7474, Minibatch error= 3.6%\n",
      "2017-09-05 03:30:17,533 Iter 53150, Minibatch Loss= 0.2695, Training Accuracy= 0.7216, Minibatch error= 6.2%\n",
      "2017-09-05 03:34:21,521 Epoch 531, Average loss: 0.0335, learning rate: 0.0010\n",
      "2017-09-05 03:34:21,597 Verification error= 6.9%, loss= 0.3335\n",
      "2017-09-05 03:34:48,396 Iter 53200, Minibatch Loss= 0.4895, Training Accuracy= 0.7378, Minibatch error= 8.8%\n",
      "2017-09-05 03:38:58,134 Iter 53250, Minibatch Loss= 1.1977, Training Accuracy= 0.7042, Minibatch error= 11.3%\n",
      "2017-09-05 03:43:02,684 Epoch 532, Average loss: 0.0325, learning rate: 0.0010\n",
      "2017-09-05 03:43:02,756 Verification error= 5.2%, loss= 0.2320\n",
      "2017-09-05 03:43:29,595 Iter 53300, Minibatch Loss= 0.3126, Training Accuracy= 0.7430, Minibatch error= 8.0%\n",
      "2017-09-05 03:47:38,959 Iter 53350, Minibatch Loss= 0.6897, Training Accuracy= 0.7234, Minibatch error= 9.4%\n",
      "2017-09-05 03:51:43,883 Epoch 533, Average loss: 0.0331, learning rate: 0.0010\n",
      "2017-09-05 03:51:43,959 Verification error= 5.9%, loss= 0.2540\n",
      "2017-09-05 03:52:10,806 Iter 53400, Minibatch Loss= 0.1489, Training Accuracy= 0.7521, Minibatch error= 5.6%\n",
      "2017-09-05 03:56:20,576 Iter 53450, Minibatch Loss= 0.1460, Training Accuracy= 0.7534, Minibatch error= 4.8%\n",
      "2017-09-05 04:00:25,463 Epoch 534, Average loss: 0.0325, learning rate: 0.0010\n",
      "2017-09-05 04:00:25,534 Verification error= 6.4%, loss= 0.3105\n",
      "2017-09-05 04:00:52,302 Iter 53500, Minibatch Loss= 0.2250, Training Accuracy= 0.6935, Minibatch error= 6.1%\n",
      "2017-09-05 04:05:02,664 Iter 53550, Minibatch Loss= 0.6735, Training Accuracy= 0.7440, Minibatch error= 7.6%\n",
      "2017-09-05 04:09:08,796 Epoch 535, Average loss: 0.0324, learning rate: 0.0010\n",
      "2017-09-05 04:09:08,876 Verification error= 7.3%, loss= 0.4679\n",
      "2017-09-05 04:09:35,847 Iter 53600, Minibatch Loss= 0.2602, Training Accuracy= 0.7125, Minibatch error= 6.6%\n",
      "2017-09-05 04:13:47,356 Iter 53650, Minibatch Loss= 0.3345, Training Accuracy= 0.6932, Minibatch error= 8.5%\n",
      "2017-09-05 04:17:53,859 Epoch 536, Average loss: 0.0308, learning rate: 0.0010\n",
      "2017-09-05 04:17:53,931 Verification error= 6.4%, loss= 0.3067\n",
      "2017-09-05 04:18:20,882 Iter 53700, Minibatch Loss= 0.2295, Training Accuracy= 0.7237, Minibatch error= 6.2%\n",
      "2017-09-05 04:22:34,287 Iter 53750, Minibatch Loss= 0.1946, Training Accuracy= 0.7109, Minibatch error= 4.9%\n",
      "2017-09-05 04:26:40,890 Epoch 537, Average loss: 0.0320, learning rate: 0.0010\n",
      "2017-09-05 04:26:40,970 Verification error= 6.5%, loss= 0.3546\n",
      "2017-09-05 04:27:08,068 Iter 53800, Minibatch Loss= 0.2730, Training Accuracy= 0.6852, Minibatch error= 6.7%\n",
      "2017-09-05 04:31:20,397 Iter 53850, Minibatch Loss= 0.4407, Training Accuracy= 0.7484, Minibatch error= 7.1%\n",
      "2017-09-05 04:35:27,013 Epoch 538, Average loss: 0.0318, learning rate: 0.0010\n",
      "2017-09-05 04:35:27,085 Verification error= 6.6%, loss= 0.3382\n",
      "2017-09-05 04:35:54,303 Iter 53900, Minibatch Loss= 1.0739, Training Accuracy= 0.7122, Minibatch error= 10.4%\n",
      "2017-09-05 04:40:07,014 Iter 53950, Minibatch Loss= 0.4004, Training Accuracy= 0.7388, Minibatch error= 8.6%\n",
      "2017-09-05 04:44:14,523 Epoch 539, Average loss: 0.0324, learning rate: 0.0010\n",
      "2017-09-05 04:44:14,603 Verification error= 6.4%, loss= 0.3190\n",
      "2017-09-05 04:44:41,827 Iter 54000, Minibatch Loss= 0.5685, Training Accuracy= 0.7456, Minibatch error= 8.8%\n",
      "2017-09-05 04:48:54,838 Iter 54050, Minibatch Loss= 0.1967, Training Accuracy= 0.7359, Minibatch error= 6.4%\n",
      "2017-09-05 04:53:03,073 Epoch 540, Average loss: 0.0308, learning rate: 0.0010\n",
      "2017-09-05 04:53:03,145 Verification error= 6.9%, loss= 0.3776\n",
      "2017-09-05 04:53:30,436 Iter 54100, Minibatch Loss= 0.1946, Training Accuracy= 0.7383, Minibatch error= 5.9%\n",
      "2017-09-05 04:57:43,926 Iter 54150, Minibatch Loss= 0.1626, Training Accuracy= 0.7185, Minibatch error= 5.0%\n",
      "2017-09-05 05:01:51,938 Epoch 541, Average loss: 0.0314, learning rate: 0.0010\n",
      "2017-09-05 05:01:52,019 Verification error= 6.3%, loss= 0.3246\n",
      "2017-09-05 05:02:19,393 Iter 54200, Minibatch Loss= 0.5979, Training Accuracy= 0.7552, Minibatch error= 6.4%\n",
      "2017-09-05 05:06:33,206 Iter 54250, Minibatch Loss= 0.2256, Training Accuracy= 0.7091, Minibatch error= 6.1%\n",
      "2017-09-05 05:10:42,355 Epoch 542, Average loss: 0.0314, learning rate: 0.0010\n",
      "2017-09-05 05:10:42,429 Verification error= 6.8%, loss= 0.3592\n",
      "2017-09-05 05:11:09,715 Iter 54300, Minibatch Loss= 0.2607, Training Accuracy= 0.6940, Minibatch error= 7.5%\n",
      "2017-09-05 05:15:23,965 Iter 54350, Minibatch Loss= 0.2537, Training Accuracy= 0.7091, Minibatch error= 6.5%\n",
      "2017-09-05 05:19:32,845 Epoch 543, Average loss: 0.0298, learning rate: 0.0010\n",
      "2017-09-05 05:19:32,925 Verification error= 6.7%, loss= 0.3677\n",
      "2017-09-05 05:20:00,184 Iter 54400, Minibatch Loss= 0.2084, Training Accuracy= 0.7068, Minibatch error= 4.8%\n",
      "2017-09-05 05:24:14,955 Iter 54450, Minibatch Loss= 0.2445, Training Accuracy= 0.6984, Minibatch error= 6.0%\n",
      "2017-09-05 05:28:24,257 Epoch 544, Average loss: 0.0324, learning rate: 0.0010\n",
      "2017-09-05 05:28:24,329 Verification error= 6.6%, loss= 0.3322\n",
      "2017-09-05 05:28:51,579 Iter 54500, Minibatch Loss= 0.5550, Training Accuracy= 0.7315, Minibatch error= 9.2%\n",
      "2017-09-05 05:33:06,670 Iter 54550, Minibatch Loss= 0.9070, Training Accuracy= 0.7151, Minibatch error= 9.5%\n",
      "2017-09-05 05:37:16,426 Epoch 545, Average loss: 0.0302, learning rate: 0.0010\n",
      "2017-09-05 05:37:16,506 Verification error= 5.6%, loss= 0.2512\n",
      "2017-09-05 05:37:43,898 Iter 54600, Minibatch Loss= 0.4219, Training Accuracy= 0.7440, Minibatch error= 7.3%\n",
      "2017-09-05 05:41:59,659 Iter 54650, Minibatch Loss= 0.4355, Training Accuracy= 0.7529, Minibatch error= 7.8%\n",
      "2017-09-05 05:46:10,488 Epoch 546, Average loss: 0.0313, learning rate: 0.0010\n",
      "2017-09-05 05:46:10,560 Verification error= 5.2%, loss= 0.2059\n",
      "2017-09-05 05:46:37,983 Iter 54700, Minibatch Loss= 0.1345, Training Accuracy= 0.7643, Minibatch error= 4.8%\n",
      "2017-09-05 05:50:54,417 Iter 54750, Minibatch Loss= 0.1066, Training Accuracy= 0.7604, Minibatch error= 4.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 05:55:05,915 Epoch 547, Average loss: 0.0313, learning rate: 0.0010\n",
      "2017-09-05 05:55:05,995 Verification error= 6.1%, loss= 0.3328\n",
      "2017-09-05 05:55:35,255 Iter 54800, Minibatch Loss= 0.1631, Training Accuracy= 0.7091, Minibatch error= 4.8%\n",
      "2017-09-05 05:59:51,678 Iter 54850, Minibatch Loss= 0.6310, Training Accuracy= 0.7495, Minibatch error= 7.5%\n",
      "2017-09-05 06:04:03,611 Epoch 548, Average loss: 0.0309, learning rate: 0.0010\n",
      "2017-09-05 06:04:03,684 Verification error= 6.4%, loss= 0.3255\n",
      "2017-09-05 06:04:31,940 Iter 54900, Minibatch Loss= 0.2108, Training Accuracy= 0.7302, Minibatch error= 5.8%\n",
      "2017-09-05 06:08:50,354 Iter 54950, Minibatch Loss= 0.2685, Training Accuracy= 0.7018, Minibatch error= 6.5%\n",
      "2017-09-05 06:13:02,324 Epoch 549, Average loss: 0.0315, learning rate: 0.0010\n",
      "2017-09-05 06:13:02,404 Verification error= 6.9%, loss= 0.3587\n",
      "2017-09-05 06:13:30,648 Iter 55000, Minibatch Loss= 0.2398, Training Accuracy= 0.7094, Minibatch error= 6.7%\n",
      "2017-09-05 06:17:47,811 Iter 55050, Minibatch Loss= 0.1240, Training Accuracy= 0.7326, Minibatch error= 4.4%\n",
      "2017-09-05 06:22:00,694 Epoch 550, Average loss: 0.0308, learning rate: 0.0010\n",
      "2017-09-05 06:22:00,774 Verification error= 6.7%, loss= 0.3643\n",
      "2017-09-05 06:22:28,597 Iter 55100, Minibatch Loss= 0.2650, Training Accuracy= 0.7076, Minibatch error= 6.0%\n",
      "2017-09-05 06:26:46,262 Iter 55150, Minibatch Loss= 0.7425, Training Accuracy= 0.7305, Minibatch error= 9.2%\n",
      "2017-09-05 06:30:58,930 Epoch 551, Average loss: 0.0298, learning rate: 0.0010\n",
      "2017-09-05 06:30:59,006 Verification error= 5.8%, loss= 0.2967\n",
      "2017-09-05 06:31:26,907 Iter 55200, Minibatch Loss= 1.0917, Training Accuracy= 0.7109, Minibatch error= 9.8%\n",
      "2017-09-05 06:35:45,672 Iter 55250, Minibatch Loss= 0.4812, Training Accuracy= 0.7388, Minibatch error= 8.8%\n",
      "2017-09-05 06:39:59,025 Epoch 552, Average loss: 0.0296, learning rate: 0.0010\n",
      "2017-09-05 06:39:59,097 Verification error= 6.2%, loss= 0.2880\n",
      "2017-09-05 06:40:26,896 Iter 55300, Minibatch Loss= 0.5403, Training Accuracy= 0.7427, Minibatch error= 9.0%\n",
      "2017-09-05 06:44:45,512 Iter 55350, Minibatch Loss= 0.1980, Training Accuracy= 0.7315, Minibatch error= 6.1%\n",
      "2017-09-05 06:48:59,011 Epoch 553, Average loss: 0.0304, learning rate: 0.0010\n",
      "2017-09-05 06:48:59,087 Verification error= 6.0%, loss= 0.3033\n",
      "2017-09-05 06:49:27,171 Iter 55400, Minibatch Loss= 0.1460, Training Accuracy= 0.7354, Minibatch error= 5.3%\n",
      "2017-09-05 06:53:47,344 Iter 55450, Minibatch Loss= 0.2165, Training Accuracy= 0.6841, Minibatch error= 6.1%\n",
      "2017-09-05 06:58:01,228 Epoch 554, Average loss: 0.0292, learning rate: 0.0010\n",
      "2017-09-05 06:58:01,301 Verification error= 7.0%, loss= 0.3921\n",
      "2017-09-05 06:58:29,542 Iter 55500, Minibatch Loss= 0.7267, Training Accuracy= 0.7464, Minibatch error= 8.1%\n",
      "2017-09-05 07:02:49,047 Iter 55550, Minibatch Loss= 0.2525, Training Accuracy= 0.7000, Minibatch error= 6.4%\n",
      "2017-09-05 07:07:03,706 Epoch 555, Average loss: 0.0294, learning rate: 0.0010\n",
      "2017-09-05 07:07:03,782 Verification error= 7.1%, loss= 0.4396\n",
      "2017-09-05 07:07:31,751 Iter 55600, Minibatch Loss= 0.2416, Training Accuracy= 0.7000, Minibatch error= 6.9%\n",
      "2017-09-05 07:11:51,848 Iter 55650, Minibatch Loss= 0.3366, Training Accuracy= 0.7021, Minibatch error= 7.8%\n",
      "2017-09-05 07:16:06,797 Epoch 556, Average loss: 0.0292, learning rate: 0.0010\n",
      "2017-09-05 07:16:06,869 Verification error= 6.9%, loss= 0.4499\n",
      "2017-09-05 07:16:35,146 Iter 55700, Minibatch Loss= 0.2123, Training Accuracy= 0.7099, Minibatch error= 4.9%\n",
      "2017-09-05 07:20:55,891 Iter 55750, Minibatch Loss= 0.2062, Training Accuracy= 0.7216, Minibatch error= 5.4%\n",
      "2017-09-05 07:25:13,133 Epoch 557, Average loss: 0.0289, learning rate: 0.0010\n",
      "2017-09-05 07:25:13,205 Verification error= 6.8%, loss= 0.4040\n",
      "2017-09-05 07:25:41,173 Iter 55800, Minibatch Loss= 0.5219, Training Accuracy= 0.7388, Minibatch error= 8.5%\n",
      "2017-09-05 07:30:02,802 Iter 55850, Minibatch Loss= 1.0454, Training Accuracy= 0.7240, Minibatch error= 9.8%\n",
      "2017-09-05 07:34:18,741 Epoch 558, Average loss: 0.0307, learning rate: 0.0010\n",
      "2017-09-05 07:34:18,813 Verification error= 6.5%, loss= 0.3283\n",
      "2017-09-05 07:34:46,890 Iter 55900, Minibatch Loss= 0.3883, Training Accuracy= 0.7258, Minibatch error= 9.1%\n",
      "2017-09-05 07:39:08,074 Iter 55950, Minibatch Loss= 0.5846, Training Accuracy= 0.7497, Minibatch error= 8.9%\n",
      "2017-09-05 07:43:24,356 Epoch 559, Average loss: 0.0283, learning rate: 0.0010\n",
      "2017-09-05 07:43:24,432 Verification error= 7.0%, loss= 0.4098\n",
      "2017-09-05 07:43:54,464 Iter 56000, Minibatch Loss= 0.2630, Training Accuracy= 0.7414, Minibatch error= 7.1%\n",
      "2017-09-05 07:48:16,547 Iter 56050, Minibatch Loss= 0.1532, Training Accuracy= 0.7581, Minibatch error= 4.9%\n",
      "2017-09-05 07:52:33,271 Epoch 560, Average loss: 0.0286, learning rate: 0.0010\n",
      "2017-09-05 07:52:33,343 Verification error= 6.8%, loss= 0.3759\n",
      "2017-09-05 07:53:01,484 Iter 56100, Minibatch Loss= 0.1995, Training Accuracy= 0.7198, Minibatch error= 5.7%\n",
      "2017-09-05 07:57:24,847 Iter 56150, Minibatch Loss= 0.7878, Training Accuracy= 0.7581, Minibatch error= 8.6%\n",
      "2017-09-05 08:01:42,334 Epoch 561, Average loss: 0.0292, learning rate: 0.0010\n",
      "2017-09-05 08:01:42,406 Verification error= 7.0%, loss= 0.3688\n",
      "2017-09-05 08:02:10,713 Iter 56200, Minibatch Loss= 0.2004, Training Accuracy= 0.7240, Minibatch error= 6.0%\n",
      "2017-09-05 08:06:33,518 Iter 56250, Minibatch Loss= 0.2451, Training Accuracy= 0.7031, Minibatch error= 8.2%\n",
      "2017-09-05 08:10:51,246 Epoch 562, Average loss: 0.0290, learning rate: 0.0010\n",
      "2017-09-05 08:10:51,320 Verification error= 6.4%, loss= 0.3582\n",
      "2017-09-05 08:11:19,864 Iter 56300, Minibatch Loss= 0.2386, Training Accuracy= 0.7268, Minibatch error= 6.6%\n",
      "2017-09-05 08:15:43,040 Iter 56350, Minibatch Loss= 0.1814, Training Accuracy= 0.7331, Minibatch error= 4.7%\n",
      "2017-09-05 08:20:00,839 Epoch 563, Average loss: 0.0269, learning rate: 0.0010\n",
      "2017-09-05 08:20:00,918 Verification error= 6.4%, loss= 0.3457\n",
      "2017-09-05 08:20:29,389 Iter 56400, Minibatch Loss= 0.2665, Training Accuracy= 0.7000, Minibatch error= 6.7%\n",
      "2017-09-05 08:24:52,855 Iter 56450, Minibatch Loss= 0.4383, Training Accuracy= 0.7581, Minibatch error= 7.1%\n",
      "2017-09-05 08:29:11,254 Epoch 564, Average loss: 0.0281, learning rate: 0.0010\n",
      "2017-09-05 08:29:11,326 Verification error= 6.0%, loss= 0.2767\n",
      "2017-09-05 08:29:39,692 Iter 56500, Minibatch Loss= 0.9499, Training Accuracy= 0.7299, Minibatch error= 9.3%\n",
      "2017-09-05 08:34:04,827 Iter 56550, Minibatch Loss= 0.4970, Training Accuracy= 0.7445, Minibatch error= 8.8%\n",
      "2017-09-05 08:38:24,088 Epoch 565, Average loss: 0.0283, learning rate: 0.0010\n",
      "2017-09-05 08:38:24,163 Verification error= 5.8%, loss= 0.2934\n",
      "2017-09-05 08:38:52,498 Iter 56600, Minibatch Loss= 0.5320, Training Accuracy= 0.7690, Minibatch error= 8.1%\n",
      "2017-09-05 08:43:17,603 Iter 56650, Minibatch Loss= 0.1942, Training Accuracy= 0.7518, Minibatch error= 6.4%\n",
      "2017-09-05 08:47:37,044 Epoch 566, Average loss: 0.0277, learning rate: 0.0010\n",
      "2017-09-05 08:47:37,115 Verification error= 6.1%, loss= 0.2597\n",
      "2017-09-05 08:48:05,457 Iter 56700, Minibatch Loss= 0.1263, Training Accuracy= 0.7677, Minibatch error= 4.3%\n",
      "2017-09-05 08:52:30,326 Iter 56750, Minibatch Loss= 0.2993, Training Accuracy= 0.6906, Minibatch error= 7.1%\n",
      "2017-09-05 08:56:50,293 Epoch 567, Average loss: 0.0282, learning rate: 0.0010\n",
      "2017-09-05 08:56:50,368 Verification error= 7.3%, loss= 0.4163\n",
      "2017-09-05 08:57:18,812 Iter 56800, Minibatch Loss= 0.7218, Training Accuracy= 0.7378, Minibatch error= 7.6%\n",
      "2017-09-05 09:01:44,309 Iter 56850, Minibatch Loss= 0.2137, Training Accuracy= 0.6857, Minibatch error= 6.1%\n",
      "2017-09-05 09:06:05,209 Epoch 568, Average loss: 0.0291, learning rate: 0.0010\n",
      "2017-09-05 09:06:05,281 Verification error= 6.2%, loss= 0.3089\n",
      "2017-09-05 09:06:33,823 Iter 56900, Minibatch Loss= 0.2712, Training Accuracy= 0.6992, Minibatch error= 7.7%\n",
      "2017-09-05 09:10:59,756 Iter 56950, Minibatch Loss= 0.2607, Training Accuracy= 0.7052, Minibatch error= 6.6%\n",
      "2017-09-05 09:15:20,302 Epoch 569, Average loss: 0.0281, learning rate: 0.0010\n",
      "2017-09-05 09:15:20,374 Verification error= 6.9%, loss= 0.3558\n",
      "2017-09-05 09:15:49,000 Iter 57000, Minibatch Loss= 0.2054, Training Accuracy= 0.7328, Minibatch error= 5.1%\n",
      "2017-09-05 09:20:15,497 Iter 57050, Minibatch Loss= 0.3007, Training Accuracy= 0.6862, Minibatch error= 6.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 09:24:36,856 Epoch 570, Average loss: 0.0284, learning rate: 0.0010\n",
      "2017-09-05 09:24:36,929 Verification error= 6.6%, loss= 0.3288\n",
      "2017-09-05 09:25:07,580 Iter 57100, Minibatch Loss= 0.4463, Training Accuracy= 0.7518, Minibatch error= 8.2%\n",
      "2017-09-05 09:29:34,750 Iter 57150, Minibatch Loss= 1.0899, Training Accuracy= 0.7133, Minibatch error= 9.3%\n",
      "2017-09-05 09:33:56,899 Epoch 571, Average loss: 0.0272, learning rate: 0.0010\n",
      "2017-09-05 09:33:56,973 Verification error= 6.3%, loss= 0.3408\n",
      "2017-09-05 09:34:25,572 Iter 57200, Minibatch Loss= 0.4855, Training Accuracy= 0.7247, Minibatch error= 8.5%\n",
      "2017-09-05 09:38:53,505 Iter 57250, Minibatch Loss= 0.7909, Training Accuracy= 0.7312, Minibatch error= 9.7%\n",
      "2017-09-05 09:43:15,615 Epoch 572, Average loss: 0.0276, learning rate: 0.0010\n",
      "2017-09-05 09:43:15,691 Verification error= 5.7%, loss= 0.2746\n",
      "2017-09-05 09:43:44,339 Iter 57300, Minibatch Loss= 0.1542, Training Accuracy= 0.7568, Minibatch error= 5.7%\n",
      "2017-09-05 09:48:12,110 Iter 57350, Minibatch Loss= 0.1252, Training Accuracy= 0.7727, Minibatch error= 4.5%\n",
      "2017-09-05 09:52:34,667 Epoch 573, Average loss: 0.0275, learning rate: 0.0010\n",
      "2017-09-05 09:52:34,747 Verification error= 5.7%, loss= 0.2702\n",
      "2017-09-05 09:53:03,404 Iter 57400, Minibatch Loss= 0.1737, Training Accuracy= 0.7185, Minibatch error= 4.7%\n",
      "2017-09-05 09:57:31,605 Iter 57450, Minibatch Loss= 0.6542, Training Accuracy= 0.7549, Minibatch error= 8.1%\n",
      "2017-09-05 10:01:54,893 Epoch 574, Average loss: 0.0276, learning rate: 0.0010\n",
      "2017-09-05 10:01:54,965 Verification error= 6.4%, loss= 0.3413\n",
      "2017-09-05 10:02:23,943 Iter 57500, Minibatch Loss= 0.2788, Training Accuracy= 0.7221, Minibatch error= 6.6%\n",
      "2017-09-05 10:06:53,011 Iter 57550, Minibatch Loss= 0.2849, Training Accuracy= 0.6997, Minibatch error= 7.1%\n",
      "2017-09-05 10:11:16,615 Epoch 575, Average loss: 0.0264, learning rate: 0.0010\n",
      "2017-09-05 10:11:16,691 Verification error= 5.2%, loss= 0.2192\n",
      "2017-09-05 10:11:45,470 Iter 57600, Minibatch Loss= 0.2204, Training Accuracy= 0.7294, Minibatch error= 5.7%\n",
      "2017-09-05 10:16:14,626 Iter 57650, Minibatch Loss= 0.1988, Training Accuracy= 0.7201, Minibatch error= 6.1%\n",
      "2017-09-05 10:20:38,990 Epoch 576, Average loss: 0.0291, learning rate: 0.0010\n",
      "2017-09-05 10:20:39,070 Verification error= 5.8%, loss= 0.3146\n",
      "2017-09-05 10:21:07,919 Iter 57700, Minibatch Loss= 0.2666, Training Accuracy= 0.7091, Minibatch error= 6.1%\n",
      "2017-09-05 10:25:37,713 Iter 57750, Minibatch Loss= 0.5239, Training Accuracy= 0.7445, Minibatch error= 8.5%\n",
      "2017-09-05 10:30:01,839 Epoch 577, Average loss: 0.0277, learning rate: 0.0010\n",
      "2017-09-05 10:30:01,919 Verification error= 6.1%, loss= 0.3659\n",
      "2017-09-05 10:30:30,838 Iter 57800, Minibatch Loss= 1.0580, Training Accuracy= 0.7250, Minibatch error= 9.8%\n",
      "2017-09-05 10:35:01,340 Iter 57850, Minibatch Loss= 0.5447, Training Accuracy= 0.7294, Minibatch error= 7.7%\n",
      "2017-09-05 10:39:26,036 Epoch 578, Average loss: 0.0277, learning rate: 0.0010\n",
      "2017-09-05 10:39:26,116 Verification error= 5.5%, loss= 0.2620\n",
      "2017-09-05 10:39:55,408 Iter 57900, Minibatch Loss= 0.4670, Training Accuracy= 0.7487, Minibatch error= 7.8%\n",
      "2017-09-05 10:44:25,994 Iter 57950, Minibatch Loss= 0.1813, Training Accuracy= 0.7552, Minibatch error= 6.0%\n",
      "2017-09-05 10:48:51,211 Epoch 579, Average loss: 0.0271, learning rate: 0.0010\n",
      "2017-09-05 10:48:51,291 Verification error= 6.1%, loss= 0.3483\n",
      "2017-09-05 10:49:20,673 Iter 58000, Minibatch Loss= 0.1402, Training Accuracy= 0.7508, Minibatch error= 4.8%\n",
      "2017-09-05 10:53:51,845 Iter 58050, Minibatch Loss= 0.1589, Training Accuracy= 0.7143, Minibatch error= 4.9%\n",
      "2017-09-05 10:58:17,800 Epoch 580, Average loss: 0.0265, learning rate: 0.0010\n",
      "2017-09-05 10:58:17,876 Verification error= 6.3%, loss= 0.3679\n",
      "2017-09-05 10:58:47,030 Iter 58100, Minibatch Loss= 0.6077, Training Accuracy= 0.7602, Minibatch error= 6.8%\n",
      "2017-09-05 11:03:18,660 Iter 58150, Minibatch Loss= 0.1664, Training Accuracy= 0.7167, Minibatch error= 5.3%\n",
      "2017-09-05 11:07:45,338 Epoch 581, Average loss: 0.0274, learning rate: 0.0010\n",
      "2017-09-05 11:07:45,414 Verification error= 6.2%, loss= 0.3347\n",
      "2017-09-05 11:08:16,483 Iter 58200, Minibatch Loss= 0.2685, Training Accuracy= 0.6990, Minibatch error= 7.7%\n",
      "2017-09-05 11:12:48,223 Iter 58250, Minibatch Loss= 0.2478, Training Accuracy= 0.7292, Minibatch error= 6.6%\n",
      "2017-09-05 11:17:14,713 Epoch 582, Average loss: 0.0258, learning rate: 0.0010\n",
      "2017-09-05 11:17:14,785 Verification error= 6.6%, loss= 0.3766\n",
      "2017-09-05 11:17:44,382 Iter 58300, Minibatch Loss= 0.1840, Training Accuracy= 0.7427, Minibatch error= 5.5%\n",
      "2017-09-05 11:22:17,096 Iter 58350, Minibatch Loss= 0.3016, Training Accuracy= 0.6906, Minibatch error= 6.4%\n",
      "2017-09-05 11:26:44,637 Epoch 583, Average loss: 0.0266, learning rate: 0.0010\n",
      "2017-09-05 11:26:44,709 Verification error= 7.3%, loss= 0.4109\n",
      "2017-09-05 11:27:14,017 Iter 58400, Minibatch Loss= 0.6604, Training Accuracy= 0.7279, Minibatch error= 9.4%\n",
      "2017-09-05 11:31:47,106 Iter 58450, Minibatch Loss= 1.1459, Training Accuracy= 0.6914, Minibatch error= 11.6%\n",
      "2017-09-05 11:36:14,862 Epoch 584, Average loss: 0.0268, learning rate: 0.0010\n",
      "2017-09-05 11:36:14,935 Verification error= 6.1%, loss= 0.2976\n",
      "2017-09-05 11:36:44,310 Iter 58500, Minibatch Loss= 0.4470, Training Accuracy= 0.7297, Minibatch error= 8.4%\n",
      "2017-09-05 11:41:18,058 Iter 58550, Minibatch Loss= 0.6545, Training Accuracy= 0.7365, Minibatch error= 8.4%\n",
      "2017-09-05 11:45:52,478 Epoch 585, Average loss: 0.0263, learning rate: 0.0010\n",
      "2017-09-05 11:45:52,553 Verification error= 6.4%, loss= 0.3352\n",
      "2017-09-05 11:46:22,959 Iter 58600, Minibatch Loss= 0.2127, Training Accuracy= 0.7359, Minibatch error= 6.7%\n",
      "2017-09-05 11:51:01,959 Iter 58650, Minibatch Loss= 0.1095, Training Accuracy= 0.7833, Minibatch error= 3.9%\n",
      "2017-09-05 11:55:38,653 Epoch 586, Average loss: 0.0255, learning rate: 0.0010\n",
      "2017-09-05 11:55:38,732 Verification error= 6.4%, loss= 0.3414\n",
      "2017-09-05 11:56:08,683 Iter 58700, Minibatch Loss= 0.1603, Training Accuracy= 0.7089, Minibatch error= 4.6%\n",
      "2017-09-05 12:00:42,795 Iter 58750, Minibatch Loss= 0.5593, Training Accuracy= 0.7456, Minibatch error= 7.7%\n",
      "2017-09-05 12:05:11,548 Epoch 587, Average loss: 0.0252, learning rate: 0.0010\n",
      "2017-09-05 12:05:11,623 Verification error= 6.0%, loss= 0.3751\n",
      "2017-09-05 12:05:41,820 Iter 58800, Minibatch Loss= 0.1953, Training Accuracy= 0.6818, Minibatch error= 5.7%\n",
      "2017-09-05 12:10:16,834 Iter 58850, Minibatch Loss= 0.2481, Training Accuracy= 0.7148, Minibatch error= 8.1%\n",
      "2017-09-05 12:14:46,349 Epoch 588, Average loss: 0.0274, learning rate: 0.0010\n",
      "2017-09-05 12:14:46,427 Verification error= 5.4%, loss= 0.2230\n",
      "2017-09-05 12:15:16,274 Iter 58900, Minibatch Loss= 0.1697, Training Accuracy= 0.7380, Minibatch error= 5.2%\n",
      "2017-09-05 12:19:51,915 Iter 58950, Minibatch Loss= 0.1732, Training Accuracy= 0.7474, Minibatch error= 4.9%\n",
      "2017-09-05 12:24:21,500 Epoch 589, Average loss: 0.0260, learning rate: 0.0010\n",
      "2017-09-05 12:24:21,576 Verification error= 5.8%, loss= 0.2803\n",
      "2017-09-05 12:24:51,022 Iter 59000, Minibatch Loss= 0.2363, Training Accuracy= 0.7224, Minibatch error= 5.7%\n",
      "2017-09-05 12:29:26,682 Iter 59050, Minibatch Loss= 0.4617, Training Accuracy= 0.7505, Minibatch error= 8.5%\n",
      "2017-09-05 12:33:57,392 Epoch 590, Average loss: 0.0261, learning rate: 0.0010\n",
      "2017-09-05 12:33:57,468 Verification error= 6.6%, loss= 0.3513\n",
      "2017-09-05 12:34:27,362 Iter 59100, Minibatch Loss= 1.2021, Training Accuracy= 0.7346, Minibatch error= 10.5%\n",
      "2017-09-05 12:39:03,508 Iter 59150, Minibatch Loss= 0.5494, Training Accuracy= 0.7344, Minibatch error= 8.9%\n",
      "2017-09-05 12:43:34,468 Epoch 591, Average loss: 0.0264, learning rate: 0.0010\n",
      "2017-09-05 12:43:34,542 Verification error= 6.6%, loss= 0.3530\n",
      "2017-09-05 12:44:04,327 Iter 59200, Minibatch Loss= 0.6162, Training Accuracy= 0.7432, Minibatch error= 8.4%\n",
      "2017-09-05 12:48:41,506 Iter 59250, Minibatch Loss= 0.2190, Training Accuracy= 0.7484, Minibatch error= 6.6%\n",
      "2017-09-05 12:53:12,548 Epoch 592, Average loss: 0.0255, learning rate: 0.0010\n",
      "2017-09-05 12:53:12,632 Verification error= 6.3%, loss= 0.3231\n",
      "2017-09-05 12:53:44,391 Iter 59300, Minibatch Loss= 0.1904, Training Accuracy= 0.7703, Minibatch error= 5.2%\n",
      "2017-09-05 12:58:21,190 Iter 59350, Minibatch Loss= 0.1997, Training Accuracy= 0.7057, Minibatch error= 5.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 13:02:52,818 Epoch 593, Average loss: 0.0245, learning rate: 0.0010\n",
      "2017-09-05 13:02:52,890 Verification error= 7.0%, loss= 0.3673\n",
      "2017-09-05 13:03:22,640 Iter 59400, Minibatch Loss= 0.5695, Training Accuracy= 0.7536, Minibatch error= 7.2%\n",
      "2017-09-05 13:08:00,161 Iter 59450, Minibatch Loss= 0.2138, Training Accuracy= 0.7279, Minibatch error= 6.2%\n",
      "2017-09-05 13:12:32,063 Epoch 594, Average loss: 0.0249, learning rate: 0.0010\n",
      "2017-09-05 13:12:32,135 Verification error= 5.8%, loss= 0.3149\n",
      "2017-09-05 13:13:01,909 Iter 59500, Minibatch Loss= 0.2604, Training Accuracy= 0.7057, Minibatch error= 7.8%\n",
      "2017-09-05 13:17:39,732 Iter 59550, Minibatch Loss= 0.1717, Training Accuracy= 0.7620, Minibatch error= 5.4%\n",
      "2017-09-05 13:22:12,370 Epoch 595, Average loss: 0.0263, learning rate: 0.0010\n",
      "2017-09-05 13:22:12,444 Verification error= 5.8%, loss= 0.2634\n",
      "2017-09-05 13:22:42,666 Iter 59600, Minibatch Loss= 0.1417, Training Accuracy= 0.7565, Minibatch error= 4.9%\n",
      "2017-09-05 13:27:20,865 Iter 59650, Minibatch Loss= 0.3003, Training Accuracy= 0.7070, Minibatch error= 6.6%\n",
      "2017-09-05 13:31:53,379 Epoch 596, Average loss: 0.0245, learning rate: 0.0010\n",
      "2017-09-05 13:31:53,451 Verification error= 6.7%, loss= 0.3650\n",
      "2017-09-05 13:32:23,847 Iter 59700, Minibatch Loss= 0.5297, Training Accuracy= 0.7510, Minibatch error= 8.8%\n",
      "2017-09-05 13:37:03,095 Iter 59750, Minibatch Loss= 1.0405, Training Accuracy= 0.7133, Minibatch error= 10.1%\n",
      "2017-09-05 13:41:36,155 Epoch 597, Average loss: 0.0244, learning rate: 0.0010\n",
      "2017-09-05 13:41:36,230 Verification error= 6.8%, loss= 0.3801\n",
      "2017-09-05 13:42:06,233 Iter 59800, Minibatch Loss= 0.4978, Training Accuracy= 0.6984, Minibatch error= 9.8%\n",
      "2017-09-05 13:46:45,676 Iter 59850, Minibatch Loss= 0.6265, Training Accuracy= 0.7380, Minibatch error= 9.6%\n",
      "2017-09-05 13:51:20,303 Epoch 598, Average loss: 0.0287, learning rate: 0.0010\n",
      "2017-09-05 13:51:20,375 Verification error= 5.8%, loss= 0.2434\n",
      "2017-09-05 13:51:50,360 Iter 59900, Minibatch Loss= 0.2140, Training Accuracy= 0.7526, Minibatch error= 7.0%\n",
      "2017-09-05 13:56:30,209 Iter 59950, Minibatch Loss= 0.1511, Training Accuracy= 0.7531, Minibatch error= 5.3%\n",
      "2017-09-05 14:01:04,337 Epoch 599, Average loss: 0.0254, learning rate: 0.0010\n",
      "2017-09-05 14:01:04,410 Verification error= 6.8%, loss= 0.3937\n",
      "2017-09-05 14:01:34,562 Iter 60000, Minibatch Loss= 0.2203, Training Accuracy= 0.6867, Minibatch error= 5.6%\n",
      "2017-09-05 14:06:14,478 Iter 60050, Minibatch Loss= 0.6330, Training Accuracy= 0.7453, Minibatch error= 8.3%\n",
      "2017-09-05 14:10:49,065 Epoch 600, Average loss: 0.0249, learning rate: 0.0010\n",
      "2017-09-05 14:10:49,145 Verification error= 5.7%, loss= 0.2953\n",
      "2017-09-05 14:11:19,721 Iter 60100, Minibatch Loss= 0.1775, Training Accuracy= 0.7391, Minibatch error= 5.7%\n",
      "2017-09-05 14:16:00,257 Iter 60150, Minibatch Loss= 0.4221, Training Accuracy= 0.6823, Minibatch error= 9.3%\n",
      "2017-09-05 14:20:35,368 Epoch 601, Average loss: 0.0250, learning rate: 0.0010\n",
      "2017-09-05 14:20:35,440 Verification error= 6.5%, loss= 0.3145\n",
      "2017-09-05 14:21:05,604 Iter 60200, Minibatch Loss= 0.2311, Training Accuracy= 0.7448, Minibatch error= 6.5%\n",
      "2017-09-05 14:25:46,717 Iter 60250, Minibatch Loss= 0.1426, Training Accuracy= 0.7299, Minibatch error= 5.1%\n",
      "2017-09-05 14:30:22,136 Epoch 602, Average loss: 0.0261, learning rate: 0.0010\n",
      "2017-09-05 14:30:22,208 Verification error= 6.0%, loss= 0.2739\n",
      "2017-09-05 14:30:52,403 Iter 60300, Minibatch Loss= 0.2708, Training Accuracy= 0.7284, Minibatch error= 6.1%\n",
      "2017-09-05 14:35:33,729 Iter 60350, Minibatch Loss= 0.6087, Training Accuracy= 0.7385, Minibatch error= 9.6%\n",
      "2017-09-05 14:40:10,624 Epoch 603, Average loss: 0.0245, learning rate: 0.0010\n",
      "2017-09-05 14:40:10,695 Verification error= 6.8%, loss= 0.3762\n",
      "2017-09-05 14:40:42,763 Iter 60400, Minibatch Loss= 0.9448, Training Accuracy= 0.7156, Minibatch error= 10.0%\n",
      "2017-09-05 14:45:24,872 Iter 60450, Minibatch Loss= 0.4851, Training Accuracy= 0.7339, Minibatch error= 9.5%\n",
      "2017-09-05 14:50:01,685 Epoch 604, Average loss: 0.0253, learning rate: 0.0010\n",
      "2017-09-05 14:50:01,756 Verification error= 6.8%, loss= 0.3863\n",
      "2017-09-05 14:50:32,036 Iter 60500, Minibatch Loss= 0.7239, Training Accuracy= 0.7346, Minibatch error= 9.4%\n",
      "2017-09-05 14:55:14,777 Iter 60550, Minibatch Loss= 0.2531, Training Accuracy= 0.7464, Minibatch error= 6.7%\n",
      "2017-09-05 14:59:51,718 Epoch 605, Average loss: 0.0241, learning rate: 0.0010\n",
      "2017-09-05 14:59:51,791 Verification error= 6.4%, loss= 0.3185\n",
      "2017-09-05 15:00:22,171 Iter 60600, Minibatch Loss= 0.1602, Training Accuracy= 0.7789, Minibatch error= 4.9%\n",
      "2017-09-05 15:05:05,528 Iter 60650, Minibatch Loss= 0.1870, Training Accuracy= 0.7195, Minibatch error= 5.5%\n",
      "2017-09-05 15:09:42,775 Epoch 606, Average loss: 0.0237, learning rate: 0.0010\n",
      "2017-09-05 15:09:42,855 Verification error= 6.9%, loss= 0.3896\n",
      "2017-09-05 15:10:13,217 Iter 60700, Minibatch Loss= 0.6672, Training Accuracy= 0.7547, Minibatch error= 7.8%\n",
      "2017-09-05 15:14:56,655 Iter 60750, Minibatch Loss= 0.2261, Training Accuracy= 0.7354, Minibatch error= 6.3%\n",
      "2017-09-05 15:19:34,253 Epoch 607, Average loss: 0.0255, learning rate: 0.0010\n",
      "2017-09-05 15:19:34,328 Verification error= 7.4%, loss= 0.4002\n",
      "2017-09-05 15:20:04,572 Iter 60800, Minibatch Loss= 0.3355, Training Accuracy= 0.6898, Minibatch error= 8.2%\n",
      "2017-09-05 15:24:48,351 Iter 60850, Minibatch Loss= 0.2365, Training Accuracy= 0.7383, Minibatch error= 6.4%\n",
      "2017-09-05 15:29:26,519 Epoch 608, Average loss: 0.0251, learning rate: 0.0010\n",
      "2017-09-05 15:29:26,592 Verification error= 5.8%, loss= 0.2977\n",
      "2017-09-05 15:29:57,034 Iter 60900, Minibatch Loss= 0.1514, Training Accuracy= 0.7594, Minibatch error= 4.5%\n",
      "2017-09-05 15:34:41,289 Iter 60950, Minibatch Loss= 0.2193, Training Accuracy= 0.7195, Minibatch error= 5.2%\n",
      "2017-09-05 15:39:19,873 Epoch 609, Average loss: 0.0241, learning rate: 0.0010\n",
      "2017-09-05 15:39:19,949 Verification error= 6.1%, loss= 0.3222\n",
      "2017-09-05 15:39:50,479 Iter 61000, Minibatch Loss= 0.5636, Training Accuracy= 0.7589, Minibatch error= 8.2%\n",
      "2017-09-05 15:44:34,774 Iter 61050, Minibatch Loss= 1.1511, Training Accuracy= 0.7161, Minibatch error= 10.9%\n",
      "2017-09-05 15:49:13,616 Epoch 610, Average loss: 0.0235, learning rate: 0.0010\n",
      "2017-09-05 15:49:13,689 Verification error= 6.8%, loss= 0.3920\n",
      "2017-09-05 15:49:44,659 Iter 61100, Minibatch Loss= 0.6212, Training Accuracy= 0.7190, Minibatch error= 9.3%\n",
      "2017-09-05 15:54:29,796 Iter 61150, Minibatch Loss= 0.4785, Training Accuracy= 0.7526, Minibatch error= 8.5%\n",
      "2017-09-05 15:59:09,139 Epoch 611, Average loss: 0.0247, learning rate: 0.0010\n",
      "2017-09-05 15:59:09,211 Verification error= 6.7%, loss= 0.3257\n",
      "2017-09-05 15:59:40,054 Iter 61200, Minibatch Loss= 0.1985, Training Accuracy= 0.7440, Minibatch error= 6.6%\n",
      "2017-09-05 16:04:27,115 Iter 61250, Minibatch Loss= 0.1583, Training Accuracy= 0.7578, Minibatch error= 5.7%\n",
      "2017-09-05 16:09:07,441 Epoch 612, Average loss: 0.0243, learning rate: 0.0010\n",
      "2017-09-05 16:09:07,516 Verification error= 6.6%, loss= 0.3014\n",
      "2017-09-05 16:09:39,094 Iter 61300, Minibatch Loss= 0.1694, Training Accuracy= 0.7195, Minibatch error= 5.4%\n",
      "2017-09-05 16:14:25,423 Iter 61350, Minibatch Loss= 0.5617, Training Accuracy= 0.7711, Minibatch error= 6.5%\n",
      "2017-09-05 16:19:05,403 Epoch 613, Average loss: 0.0234, learning rate: 0.0010\n",
      "2017-09-05 16:19:05,477 Verification error= 6.7%, loss= 0.3453\n",
      "2017-09-05 16:19:36,329 Iter 61400, Minibatch Loss= 0.1907, Training Accuracy= 0.7443, Minibatch error= 5.7%\n",
      "2017-09-05 16:24:22,770 Iter 61450, Minibatch Loss= 0.3449, Training Accuracy= 0.7073, Minibatch error= 8.1%\n",
      "2017-09-05 16:29:03,341 Epoch 614, Average loss: 0.0228, learning rate: 0.0010\n",
      "2017-09-05 16:29:03,412 Verification error= 7.1%, loss= 0.4124\n",
      "2017-09-05 16:29:36,391 Iter 61500, Minibatch Loss= 0.3085, Training Accuracy= 0.7240, Minibatch error= 7.6%\n",
      "2017-09-05 16:34:23,468 Iter 61550, Minibatch Loss= 0.2277, Training Accuracy= 0.7563, Minibatch error= 5.5%\n",
      "2017-09-05 16:39:04,606 Epoch 615, Average loss: 0.0243, learning rate: 0.0010\n",
      "2017-09-05 16:39:04,680 Verification error= 6.4%, loss= 0.3417\n",
      "2017-09-05 16:39:35,585 Iter 61600, Minibatch Loss= 0.3164, Training Accuracy= 0.7143, Minibatch error= 7.0%\n",
      "2017-09-05 16:44:23,006 Iter 61650, Minibatch Loss= 0.4006, Training Accuracy= 0.7560, Minibatch error= 7.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 16:49:04,696 Epoch 616, Average loss: 0.0242, learning rate: 0.0010\n",
      "2017-09-05 16:49:04,768 Verification error= 6.1%, loss= 0.2984\n",
      "2017-09-05 16:49:36,290 Iter 61700, Minibatch Loss= 0.9370, Training Accuracy= 0.7089, Minibatch error= 10.0%\n",
      "2017-09-05 16:54:24,372 Iter 61750, Minibatch Loss= 0.8164, Training Accuracy= 0.7188, Minibatch error= 9.3%\n",
      "2017-09-05 16:59:07,057 Epoch 617, Average loss: 0.0240, learning rate: 0.0010\n",
      "2017-09-05 16:59:07,131 Verification error= 6.7%, loss= 0.3665\n",
      "2017-09-05 16:59:38,748 Iter 61800, Minibatch Loss= 0.6512, Training Accuracy= 0.7336, Minibatch error= 9.1%\n",
      "2017-09-05 17:04:27,785 Iter 61850, Minibatch Loss= 0.2044, Training Accuracy= 0.7513, Minibatch error= 6.9%\n",
      "2017-09-05 17:09:10,846 Epoch 618, Average loss: 0.0257, learning rate: 0.0010\n",
      "2017-09-05 17:09:10,920 Verification error= 6.2%, loss= 0.3021\n",
      "2017-09-05 17:09:42,428 Iter 61900, Minibatch Loss= 0.1788, Training Accuracy= 0.7505, Minibatch error= 4.9%\n",
      "2017-09-05 17:14:31,392 Iter 61950, Minibatch Loss= 0.1751, Training Accuracy= 0.7161, Minibatch error= 5.2%\n",
      "2017-09-05 17:19:14,690 Epoch 619, Average loss: 0.0254, learning rate: 0.0010\n",
      "2017-09-05 17:19:14,763 Verification error= 6.5%, loss= 0.3207\n",
      "2017-09-05 17:19:45,840 Iter 62000, Minibatch Loss= 0.5325, Training Accuracy= 0.7685, Minibatch error= 7.3%\n",
      "2017-09-05 17:24:35,125 Iter 62050, Minibatch Loss= 0.1665, Training Accuracy= 0.7544, Minibatch error= 5.4%\n",
      "2017-09-05 17:29:18,790 Epoch 620, Average loss: 0.0238, learning rate: 0.0010\n",
      "2017-09-05 17:29:18,862 Verification error= 5.7%, loss= 0.2684\n",
      "2017-09-05 17:29:50,376 Iter 62100, Minibatch Loss= 0.3007, Training Accuracy= 0.7115, Minibatch error= 8.3%\n",
      "2017-09-05 17:34:40,994 Iter 62150, Minibatch Loss= 0.2445, Training Accuracy= 0.7398, Minibatch error= 7.0%\n",
      "2017-09-05 17:39:24,665 Epoch 621, Average loss: 0.0236, learning rate: 0.0010\n",
      "2017-09-05 17:39:24,739 Verification error= 6.0%, loss= 0.3140\n",
      "2017-09-05 17:39:55,959 Iter 62200, Minibatch Loss= 0.1510, Training Accuracy= 0.7549, Minibatch error= 4.6%\n",
      "2017-09-05 17:44:45,890 Iter 62250, Minibatch Loss= 0.2267, Training Accuracy= 0.7055, Minibatch error= 6.1%\n",
      "2017-09-05 17:49:30,813 Epoch 622, Average loss: 0.0232, learning rate: 0.0010\n",
      "2017-09-05 17:49:30,882 Verification error= 6.5%, loss= 0.3520\n",
      "2017-09-05 17:50:02,123 Iter 62300, Minibatch Loss= 0.6428, Training Accuracy= 0.7396, Minibatch error= 8.9%\n",
      "2017-09-05 17:54:52,498 Iter 62350, Minibatch Loss= 1.1327, Training Accuracy= 0.7221, Minibatch error= 9.5%\n",
      "2017-09-05 17:59:37,466 Epoch 623, Average loss: 0.0242, learning rate: 0.0010\n",
      "2017-09-05 17:59:37,536 Verification error= 6.9%, loss= 0.3692\n",
      "2017-09-05 18:00:08,829 Iter 62400, Minibatch Loss= 0.5494, Training Accuracy= 0.7138, Minibatch error= 9.7%\n",
      "2017-09-05 18:05:00,596 Iter 62450, Minibatch Loss= 0.5708, Training Accuracy= 0.7552, Minibatch error= 7.6%\n",
      "2017-09-05 18:09:45,669 Epoch 624, Average loss: 0.0242, learning rate: 0.0010\n",
      "2017-09-05 18:09:45,740 Verification error= 6.3%, loss= 0.3409\n",
      "2017-09-05 18:10:17,044 Iter 62500, Minibatch Loss= 0.2568, Training Accuracy= 0.7505, Minibatch error= 6.8%\n",
      "2017-09-05 18:15:09,232 Iter 62550, Minibatch Loss= 0.1563, Training Accuracy= 0.7698, Minibatch error= 4.6%\n",
      "2017-09-05 18:19:55,721 Epoch 625, Average loss: 0.0232, learning rate: 0.0010\n",
      "2017-09-05 18:19:55,791 Verification error= 6.6%, loss= 0.3371\n",
      "2017-09-05 18:20:29,137 Iter 62600, Minibatch Loss= 0.1649, Training Accuracy= 0.7315, Minibatch error= 4.9%\n",
      "2017-09-05 18:25:22,186 Iter 62650, Minibatch Loss= 0.4909, Training Accuracy= 0.7831, Minibatch error= 5.9%\n",
      "2017-09-05 18:30:07,983 Epoch 626, Average loss: 0.0230, learning rate: 0.0010\n",
      "2017-09-05 18:30:08,054 Verification error= 6.3%, loss= 0.3254\n",
      "2017-09-05 18:30:39,502 Iter 62700, Minibatch Loss= 0.1922, Training Accuracy= 0.7318, Minibatch error= 6.0%\n",
      "2017-09-05 18:35:31,905 Iter 62750, Minibatch Loss= 0.2747, Training Accuracy= 0.7013, Minibatch error= 8.5%\n",
      "2017-09-05 18:40:18,733 Epoch 627, Average loss: 0.0225, learning rate: 0.0010\n",
      "2017-09-05 18:40:18,805 Verification error= 7.0%, loss= 0.4291\n",
      "2017-09-05 18:40:50,327 Iter 62800, Minibatch Loss= 0.2299, Training Accuracy= 0.7484, Minibatch error= 6.7%\n",
      "2017-09-05 18:45:42,802 Iter 62850, Minibatch Loss= 0.1592, Training Accuracy= 0.7591, Minibatch error= 5.0%\n",
      "2017-09-05 18:50:30,003 Epoch 628, Average loss: 0.0221, learning rate: 0.0010\n",
      "2017-09-05 18:50:30,074 Verification error= 5.8%, loss= 0.2611\n",
      "2017-09-05 18:51:01,609 Iter 62900, Minibatch Loss= 0.2305, Training Accuracy= 0.7367, Minibatch error= 6.0%\n",
      "2017-09-05 18:55:55,529 Iter 62950, Minibatch Loss= 0.3854, Training Accuracy= 0.7721, Minibatch error= 8.3%\n",
      "2017-09-05 19:00:43,280 Epoch 629, Average loss: 0.0213, learning rate: 0.0010\n",
      "2017-09-05 19:00:43,355 Verification error= 6.5%, loss= 0.3255\n",
      "2017-09-05 19:01:14,944 Iter 63000, Minibatch Loss= 1.0092, Training Accuracy= 0.7232, Minibatch error= 9.7%\n",
      "2017-09-05 19:06:08,631 Iter 63050, Minibatch Loss= 0.4953, Training Accuracy= 0.6940, Minibatch error= 9.9%\n",
      "2017-09-05 19:10:57,230 Epoch 630, Average loss: 0.0222, learning rate: 0.0010\n",
      "2017-09-05 19:10:57,304 Verification error= 6.6%, loss= 0.3230\n",
      "2017-09-05 19:11:29,224 Iter 63100, Minibatch Loss= 0.6276, Training Accuracy= 0.7495, Minibatch error= 8.6%\n",
      "2017-09-05 19:16:23,664 Iter 63150, Minibatch Loss= 0.1919, Training Accuracy= 0.7570, Minibatch error= 6.3%\n",
      "2017-09-05 19:21:12,195 Epoch 631, Average loss: 0.0213, learning rate: 0.0010\n",
      "2017-09-05 19:21:12,264 Verification error= 7.3%, loss= 0.4175\n",
      "2017-09-05 19:21:43,876 Iter 63200, Minibatch Loss= 0.2031, Training Accuracy= 0.7328, Minibatch error= 5.9%\n",
      "2017-09-05 19:26:38,419 Iter 63250, Minibatch Loss= 0.1972, Training Accuracy= 0.7206, Minibatch error= 5.2%\n",
      "2017-09-05 19:31:27,121 Epoch 632, Average loss: 0.0222, learning rate: 0.0010\n",
      "2017-09-05 19:31:27,192 Verification error= 6.6%, loss= 0.3276\n",
      "2017-09-05 19:31:58,729 Iter 63300, Minibatch Loss= 0.5146, Training Accuracy= 0.7500, Minibatch error= 6.4%\n",
      "2017-09-05 19:36:53,926 Iter 63350, Minibatch Loss= 0.1795, Training Accuracy= 0.7167, Minibatch error= 5.8%\n",
      "2017-09-05 19:41:43,908 Epoch 633, Average loss: 0.0214, learning rate: 0.0010\n",
      "2017-09-05 19:41:43,979 Verification error= 5.8%, loss= 0.2562\n",
      "2017-09-05 19:42:15,613 Iter 63400, Minibatch Loss= 0.3000, Training Accuracy= 0.6810, Minibatch error= 8.6%\n",
      "2017-09-05 19:47:11,823 Iter 63450, Minibatch Loss= 0.1807, Training Accuracy= 0.7328, Minibatch error= 5.7%\n",
      "2017-09-05 19:52:01,652 Epoch 634, Average loss: 0.0206, learning rate: 0.0010\n",
      "2017-09-05 19:52:01,722 Verification error= 5.8%, loss= 0.2966\n",
      "2017-09-05 19:52:33,536 Iter 63500, Minibatch Loss= 0.1648, Training Accuracy= 0.7518, Minibatch error= 5.3%\n",
      "2017-09-05 19:57:30,213 Iter 63550, Minibatch Loss= 0.2166, Training Accuracy= 0.7245, Minibatch error= 5.6%\n",
      "2017-09-05 20:02:20,907 Epoch 635, Average loss: 0.0227, learning rate: 0.0010\n",
      "2017-09-05 20:02:20,976 Verification error= 6.2%, loss= 0.3377\n",
      "2017-09-05 20:02:52,715 Iter 63600, Minibatch Loss= 0.5555, Training Accuracy= 0.7453, Minibatch error= 8.7%\n",
      "2017-09-05 20:07:49,049 Iter 63650, Minibatch Loss= 0.8952, Training Accuracy= 0.7378, Minibatch error= 8.9%\n",
      "2017-09-05 20:12:39,742 Epoch 636, Average loss: 0.0224, learning rate: 0.0010\n",
      "2017-09-05 20:12:39,813 Verification error= 6.1%, loss= 0.3208\n",
      "2017-09-05 20:13:13,921 Iter 63700, Minibatch Loss= 0.5033, Training Accuracy= 0.7016, Minibatch error= 9.4%\n",
      "2017-09-05 20:18:11,085 Iter 63750, Minibatch Loss= 0.6601, Training Accuracy= 0.7242, Minibatch error= 9.0%\n",
      "2017-09-05 20:23:02,666 Epoch 637, Average loss: 0.0216, learning rate: 0.0010\n",
      "2017-09-05 20:23:02,736 Verification error= 8.0%, loss= 0.5239\n",
      "2017-09-05 20:23:34,837 Iter 63800, Minibatch Loss= 0.3970, Training Accuracy= 0.7122, Minibatch error= 8.4%\n",
      "2017-09-05 20:28:32,077 Iter 63850, Minibatch Loss= 0.2094, Training Accuracy= 0.7622, Minibatch error= 4.6%\n",
      "2017-09-05 20:33:23,456 Epoch 638, Average loss: 0.0239, learning rate: 0.0010\n",
      "2017-09-05 20:33:23,527 Verification error= 5.6%, loss= 0.3310\n",
      "2017-09-05 20:33:55,587 Iter 63900, Minibatch Loss= 0.1598, Training Accuracy= 0.7190, Minibatch error= 5.1%\n",
      "2017-09-05 20:38:53,633 Iter 63950, Minibatch Loss= 0.4815, Training Accuracy= 0.7823, Minibatch error= 6.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-05 20:43:46,069 Epoch 639, Average loss: 0.0226, learning rate: 0.0010\n",
      "2017-09-05 20:43:46,148 Verification error= 5.5%, loss= 0.2247\n",
      "2017-09-05 20:44:18,170 Iter 64000, Minibatch Loss= 0.1665, Training Accuracy= 0.7102, Minibatch error= 5.4%\n",
      "2017-09-05 20:49:16,347 Iter 64050, Minibatch Loss= 0.2539, Training Accuracy= 0.7031, Minibatch error= 8.0%\n",
      "2017-09-05 20:54:09,947 Epoch 640, Average loss: 0.0218, learning rate: 0.0010\n",
      "2017-09-05 20:54:10,021 Verification error= 5.9%, loss= 0.2708\n",
      "2017-09-05 20:54:42,034 Iter 64100, Minibatch Loss= 0.1510, Training Accuracy= 0.7646, Minibatch error= 4.4%\n",
      "2017-09-05 20:59:40,445 Iter 64150, Minibatch Loss= 0.1815, Training Accuracy= 0.7451, Minibatch error= 5.4%\n",
      "2017-09-05 21:04:33,358 Epoch 641, Average loss: 0.0220, learning rate: 0.0010\n",
      "2017-09-05 21:04:33,428 Verification error= 6.8%, loss= 0.3544\n",
      "2017-09-05 21:05:05,505 Iter 64200, Minibatch Loss= 0.2535, Training Accuracy= 0.7047, Minibatch error= 6.3%\n",
      "2017-09-05 21:10:04,521 Iter 64250, Minibatch Loss= 0.5010, Training Accuracy= 0.7573, Minibatch error= 7.9%\n",
      "2017-09-05 21:14:57,500 Epoch 642, Average loss: 0.0224, learning rate: 0.0010\n",
      "2017-09-05 21:14:57,570 Verification error= 6.2%, loss= 0.2817\n",
      "2017-09-05 21:15:29,813 Iter 64300, Minibatch Loss= 0.7815, Training Accuracy= 0.7313, Minibatch error= 9.0%\n",
      "2017-09-05 21:20:29,366 Iter 64350, Minibatch Loss= 0.4753, Training Accuracy= 0.7211, Minibatch error= 8.2%\n",
      "2017-09-05 21:25:24,368 Epoch 643, Average loss: 0.0238, learning rate: 0.0010\n",
      "2017-09-05 21:25:24,446 Verification error= 6.4%, loss= 0.3222\n",
      "2017-09-05 21:25:56,610 Iter 64400, Minibatch Loss= 0.5898, Training Accuracy= 0.7563, Minibatch error= 8.6%\n",
      "2017-09-05 21:30:57,328 Iter 64450, Minibatch Loss= 0.1988, Training Accuracy= 0.7490, Minibatch error= 6.6%\n",
      "2017-09-05 21:35:51,368 Epoch 644, Average loss: 0.0211, learning rate: 0.0010\n",
      "2017-09-05 21:35:51,439 Verification error= 5.9%, loss= 0.2850\n",
      "2017-09-05 21:36:23,695 Iter 64500, Minibatch Loss= 0.1327, Training Accuracy= 0.7516, Minibatch error= 4.5%\n",
      "2017-09-05 21:41:24,146 Iter 64550, Minibatch Loss= 0.1554, Training Accuracy= 0.7367, Minibatch error= 5.1%\n",
      "2017-09-05 21:46:19,130 Epoch 645, Average loss: 0.0215, learning rate: 0.0010\n",
      "2017-09-05 21:46:19,208 Verification error= 5.7%, loss= 0.2513\n",
      "2017-09-05 21:46:51,298 Iter 64600, Minibatch Loss= 0.6224, Training Accuracy= 0.7685, Minibatch error= 6.7%\n",
      "2017-09-05 21:51:53,299 Iter 64650, Minibatch Loss= 0.1888, Training Accuracy= 0.7193, Minibatch error= 5.7%\n",
      "2017-09-05 21:56:48,689 Epoch 646, Average loss: 0.0218, learning rate: 0.0010\n",
      "2017-09-05 21:56:48,759 Verification error= 6.1%, loss= 0.2841\n",
      "2017-09-05 21:57:20,984 Iter 64700, Minibatch Loss= 0.2907, Training Accuracy= 0.6977, Minibatch error= 7.8%\n",
      "2017-09-05 22:02:22,677 Iter 64750, Minibatch Loss= 0.2224, Training Accuracy= 0.7258, Minibatch error= 5.5%\n",
      "2017-09-05 22:07:18,403 Epoch 647, Average loss: 0.0210, learning rate: 0.0010\n",
      "2017-09-05 22:07:18,477 Verification error= 6.4%, loss= 0.3220\n",
      "2017-09-05 22:07:52,935 Iter 64800, Minibatch Loss= 0.2077, Training Accuracy= 0.7297, Minibatch error= 5.5%\n",
      "2017-09-05 22:12:54,992 Iter 64850, Minibatch Loss= 0.2450, Training Accuracy= 0.7047, Minibatch error= 6.1%\n",
      "2017-09-05 22:17:51,367 Epoch 648, Average loss: 0.0210, learning rate: 0.0010\n",
      "2017-09-05 22:17:51,437 Verification error= 6.1%, loss= 0.2996\n",
      "2017-09-05 22:18:23,767 Iter 64900, Minibatch Loss= 0.7558, Training Accuracy= 0.7242, Minibatch error= 8.7%\n",
      "2017-09-05 22:23:26,243 Iter 64950, Minibatch Loss= 0.7638, Training Accuracy= 0.7021, Minibatch error= 8.8%\n",
      "2017-09-05 22:28:23,981 Epoch 649, Average loss: 0.0211, learning rate: 0.0010\n",
      "2017-09-05 22:28:24,052 Verification error= 5.7%, loss= 0.2548\n",
      "2017-09-05 22:28:56,491 Iter 65000, Minibatch Loss= 0.4661, Training Accuracy= 0.7289, Minibatch error= 7.7%\n",
      "2017-09-05 22:33:59,473 Iter 65050, Minibatch Loss= 0.4062, Training Accuracy= 0.7453, Minibatch error= 7.2%\n",
      "2017-09-05 22:38:56,813 Epoch 650, Average loss: 0.0219, learning rate: 0.0010\n",
      "2017-09-05 22:38:56,891 Verification error= 6.0%, loss= 0.2628\n",
      "2017-09-05 22:39:29,446 Iter 65100, Minibatch Loss= 0.1741, Training Accuracy= 0.7396, Minibatch error= 6.6%\n",
      "2017-09-05 22:44:33,665 Iter 65150, Minibatch Loss= 0.1252, Training Accuracy= 0.7495, Minibatch error= 3.9%\n",
      "2017-09-05 22:49:30,858 Epoch 651, Average loss: 0.0204, learning rate: 0.0010\n",
      "2017-09-05 22:49:30,930 Verification error= 5.7%, loss= 0.2868\n",
      "2017-09-05 22:50:03,492 Iter 65200, Minibatch Loss= 0.1677, Training Accuracy= 0.7240, Minibatch error= 5.4%\n",
      "2017-09-05 22:55:07,636 Iter 65250, Minibatch Loss= 0.5352, Training Accuracy= 0.7651, Minibatch error= 6.1%\n",
      "2017-09-05 23:00:05,092 Epoch 652, Average loss: 0.0208, learning rate: 0.0010\n",
      "2017-09-05 23:00:05,162 Verification error= 5.7%, loss= 0.2532\n",
      "2017-09-05 23:00:37,903 Iter 65300, Minibatch Loss= 0.1410, Training Accuracy= 0.7193, Minibatch error= 5.1%\n",
      "2017-09-05 23:05:42,446 Iter 65350, Minibatch Loss= 0.2421, Training Accuracy= 0.6906, Minibatch error= 8.1%\n",
      "2017-09-05 23:10:40,892 Epoch 653, Average loss: 0.0203, learning rate: 0.0010\n",
      "2017-09-05 23:10:40,971 Verification error= 6.4%, loss= 0.4664\n",
      "2017-09-05 23:11:13,704 Iter 65400, Minibatch Loss= 0.3244, Training Accuracy= 0.7206, Minibatch error= 7.0%\n",
      "2017-09-05 23:16:18,497 Iter 65450, Minibatch Loss= 0.1601, Training Accuracy= 0.7492, Minibatch error= 4.2%\n",
      "2017-09-05 23:21:16,819 Epoch 654, Average loss: 0.0220, learning rate: 0.0010\n",
      "2017-09-05 23:21:16,893 Verification error= 5.7%, loss= 0.2910\n",
      "2017-09-05 23:21:50,011 Iter 65500, Minibatch Loss= 0.2794, Training Accuracy= 0.6839, Minibatch error= 5.5%\n",
      "2017-09-05 23:26:56,335 Iter 65550, Minibatch Loss= 0.5637, Training Accuracy= 0.7401, Minibatch error= 8.4%\n",
      "2017-09-05 23:31:59,079 Epoch 655, Average loss: 0.0213, learning rate: 0.0010\n",
      "2017-09-05 23:31:59,157 Verification error= 7.1%, loss= 0.4603\n",
      "2017-09-05 23:32:32,601 Iter 65600, Minibatch Loss= 1.3690, Training Accuracy= 0.6716, Minibatch error= 11.0%\n",
      "2017-09-05 23:37:42,395 Iter 65650, Minibatch Loss= 0.5841, Training Accuracy= 0.7135, Minibatch error= 8.2%\n",
      "2017-09-05 23:42:45,919 Epoch 656, Average loss: 0.0203, learning rate: 0.0010\n",
      "2017-09-05 23:42:45,989 Verification error= 6.9%, loss= 0.4407\n",
      "2017-09-05 23:43:19,086 Iter 65700, Minibatch Loss= 0.7477, Training Accuracy= 0.7026, Minibatch error= 9.6%\n",
      "2017-09-05 23:48:28,781 Iter 65750, Minibatch Loss= 0.1988, Training Accuracy= 0.7333, Minibatch error= 7.0%\n",
      "2017-09-05 23:53:32,458 Epoch 657, Average loss: 0.0205, learning rate: 0.0010\n",
      "2017-09-05 23:53:32,530 Verification error= 7.1%, loss= 0.4122\n",
      "2017-09-05 23:54:05,610 Iter 65800, Minibatch Loss= 0.1793, Training Accuracy= 0.7388, Minibatch error= 5.8%\n",
      "2017-09-05 23:59:15,936 Iter 65850, Minibatch Loss= 0.2105, Training Accuracy= 0.7109, Minibatch error= 5.8%\n",
      "2017-09-06 00:04:20,134 Epoch 658, Average loss: 0.0208, learning rate: 0.0010\n",
      "2017-09-06 00:04:20,207 Verification error= 6.3%, loss= 0.3767\n",
      "2017-09-06 00:04:56,037 Iter 65900, Minibatch Loss= 0.8526, Training Accuracy= 0.7578, Minibatch error= 7.4%\n",
      "2017-09-06 00:10:07,194 Iter 65950, Minibatch Loss= 0.2146, Training Accuracy= 0.7156, Minibatch error= 6.1%\n",
      "2017-09-06 00:15:12,353 Epoch 659, Average loss: 0.0207, learning rate: 0.0010\n",
      "2017-09-06 00:15:12,427 Verification error= 5.6%, loss= 0.2563\n",
      "2017-09-06 00:15:45,943 Iter 66000, Minibatch Loss= 0.3039, Training Accuracy= 0.6815, Minibatch error= 8.2%\n",
      "2017-09-06 00:20:57,333 Iter 66050, Minibatch Loss= 0.2502, Training Accuracy= 0.7318, Minibatch error= 6.0%\n",
      "2017-09-06 00:26:02,681 Epoch 660, Average loss: 0.0216, learning rate: 0.0010\n",
      "2017-09-06 00:26:02,759 Verification error= 5.8%, loss= 0.2802\n",
      "2017-09-06 00:26:35,834 Iter 66100, Minibatch Loss= 0.1660, Training Accuracy= 0.7695, Minibatch error= 4.6%\n",
      "2017-09-06 00:31:47,384 Iter 66150, Minibatch Loss= 0.2547, Training Accuracy= 0.7180, Minibatch error= 6.0%\n",
      "2017-09-06 00:36:52,611 Epoch 661, Average loss: 0.0213, learning rate: 0.0010\n",
      "2017-09-06 00:36:52,684 Verification error= 6.2%, loss= 0.3001\n",
      "2017-09-06 00:37:25,891 Iter 66200, Minibatch Loss= 0.4927, Training Accuracy= 0.7445, Minibatch error= 7.8%\n",
      "2017-09-06 00:42:38,353 Iter 66250, Minibatch Loss= 0.9961, Training Accuracy= 0.7289, Minibatch error= 8.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 00:47:44,242 Epoch 662, Average loss: 0.0201, learning rate: 0.0010\n",
      "2017-09-06 00:47:44,313 Verification error= 6.1%, loss= 0.3197\n",
      "2017-09-06 00:48:17,684 Iter 66300, Minibatch Loss= 0.5645, Training Accuracy= 0.7562, Minibatch error= 8.3%\n",
      "2017-09-06 00:53:30,473 Iter 66350, Minibatch Loss= 0.5434, Training Accuracy= 0.7698, Minibatch error= 7.8%\n",
      "2017-09-06 00:58:36,318 Epoch 663, Average loss: 0.0204, learning rate: 0.0010\n",
      "2017-09-06 00:58:36,389 Verification error= 5.5%, loss= 0.2454\n",
      "2017-09-06 00:59:09,752 Iter 66400, Minibatch Loss= 0.2057, Training Accuracy= 0.7518, Minibatch error= 6.2%\n",
      "2017-09-06 01:04:22,943 Iter 66450, Minibatch Loss= 0.1303, Training Accuracy= 0.7688, Minibatch error= 3.7%\n",
      "2017-09-06 01:09:29,217 Epoch 664, Average loss: 0.0200, learning rate: 0.0010\n",
      "2017-09-06 01:09:29,291 Verification error= 5.6%, loss= 0.2467\n",
      "2017-09-06 01:10:02,453 Iter 66500, Minibatch Loss= 0.1591, Training Accuracy= 0.7344, Minibatch error= 5.5%\n",
      "2017-09-06 01:15:15,307 Iter 66550, Minibatch Loss= 0.6358, Training Accuracy= 0.7682, Minibatch error= 7.6%\n",
      "2017-09-06 01:20:21,774 Epoch 665, Average loss: 0.0201, learning rate: 0.0010\n",
      "2017-09-06 01:20:21,852 Verification error= 6.5%, loss= 0.3126\n",
      "2017-09-06 01:20:55,067 Iter 66600, Minibatch Loss= 0.2072, Training Accuracy= 0.7331, Minibatch error= 6.2%\n",
      "2017-09-06 01:26:08,671 Iter 66650, Minibatch Loss= 0.2786, Training Accuracy= 0.6987, Minibatch error= 8.5%\n",
      "2017-09-06 01:31:16,522 Epoch 666, Average loss: 0.0197, learning rate: 0.0010\n",
      "2017-09-06 01:31:16,593 Verification error= 7.1%, loss= 0.3875\n",
      "2017-09-06 01:31:49,983 Iter 66700, Minibatch Loss= 0.3250, Training Accuracy= 0.7385, Minibatch error= 7.7%\n",
      "2017-09-06 01:37:03,767 Iter 66750, Minibatch Loss= 0.1908, Training Accuracy= 0.7565, Minibatch error= 5.9%\n",
      "2017-09-06 01:42:11,410 Epoch 667, Average loss: 0.0216, learning rate: 0.0010\n",
      "2017-09-06 01:42:11,481 Verification error= 6.9%, loss= 0.3563\n",
      "2017-09-06 01:42:44,747 Iter 66800, Minibatch Loss= 0.2858, Training Accuracy= 0.6815, Minibatch error= 6.9%\n",
      "2017-09-06 01:47:59,479 Iter 66850, Minibatch Loss= 0.6872, Training Accuracy= 0.7331, Minibatch error= 10.3%\n",
      "2017-09-06 01:53:07,710 Epoch 668, Average loss: 0.0198, learning rate: 0.0010\n",
      "2017-09-06 01:53:07,781 Verification error= 6.6%, loss= 0.3931\n",
      "2017-09-06 01:53:41,479 Iter 66900, Minibatch Loss= 1.1841, Training Accuracy= 0.7130, Minibatch error= 9.9%\n",
      "2017-09-06 01:58:57,118 Iter 66950, Minibatch Loss= 0.4054, Training Accuracy= 0.7440, Minibatch error= 7.7%\n",
      "2017-09-06 02:04:06,480 Epoch 669, Average loss: 0.0198, learning rate: 0.0010\n",
      "2017-09-06 02:04:06,550 Verification error= 6.0%, loss= 0.3055\n",
      "2017-09-06 02:04:41,941 Iter 67000, Minibatch Loss= 0.5370, Training Accuracy= 0.7458, Minibatch error= 7.5%\n",
      "2017-09-06 02:09:58,112 Iter 67050, Minibatch Loss= 0.2006, Training Accuracy= 0.7294, Minibatch error= 6.9%\n",
      "2017-09-06 02:15:07,666 Epoch 670, Average loss: 0.0205, learning rate: 0.0010\n",
      "2017-09-06 02:15:07,737 Verification error= 5.6%, loss= 0.2337\n",
      "2017-09-06 02:15:41,289 Iter 67100, Minibatch Loss= 0.1512, Training Accuracy= 0.7620, Minibatch error= 4.5%\n",
      "2017-09-06 02:20:57,625 Iter 67150, Minibatch Loss= 0.2066, Training Accuracy= 0.7112, Minibatch error= 5.5%\n",
      "2017-09-06 02:26:07,555 Epoch 671, Average loss: 0.0194, learning rate: 0.0010\n",
      "2017-09-06 02:26:07,626 Verification error= 6.0%, loss= 0.3246\n",
      "2017-09-06 02:26:41,282 Iter 67200, Minibatch Loss= 0.5595, Training Accuracy= 0.7430, Minibatch error= 6.5%\n",
      "2017-09-06 02:31:57,531 Iter 67250, Minibatch Loss= 0.2425, Training Accuracy= 0.6906, Minibatch error= 6.2%\n",
      "2017-09-06 02:37:07,331 Epoch 672, Average loss: 0.0196, learning rate: 0.0010\n",
      "2017-09-06 02:37:07,400 Verification error= 6.3%, loss= 0.3211\n",
      "2017-09-06 02:37:41,174 Iter 67300, Minibatch Loss= 0.3059, Training Accuracy= 0.6526, Minibatch error= 9.1%\n",
      "2017-09-06 02:42:58,547 Iter 67350, Minibatch Loss= 0.1986, Training Accuracy= 0.7435, Minibatch error= 5.4%\n",
      "2017-09-06 02:48:09,081 Epoch 673, Average loss: 0.0191, learning rate: 0.0010\n",
      "2017-09-06 02:48:09,151 Verification error= 5.6%, loss= 0.2762\n",
      "2017-09-06 02:48:42,859 Iter 67400, Minibatch Loss= 0.2281, Training Accuracy= 0.7552, Minibatch error= 4.6%\n",
      "2017-09-06 02:54:00,604 Iter 67450, Minibatch Loss= 0.2588, Training Accuracy= 0.6815, Minibatch error= 5.5%\n",
      "2017-09-06 02:59:11,570 Epoch 674, Average loss: 0.0187, learning rate: 0.0010\n",
      "2017-09-06 02:59:11,640 Verification error= 6.2%, loss= 0.3233\n",
      "2017-09-06 02:59:45,532 Iter 67500, Minibatch Loss= 0.4505, Training Accuracy= 0.7594, Minibatch error= 7.9%\n",
      "2017-09-06 03:05:03,956 Iter 67550, Minibatch Loss= 0.9907, Training Accuracy= 0.7417, Minibatch error= 8.2%\n",
      "2017-09-06 03:10:16,639 Epoch 675, Average loss: 0.0232, learning rate: 0.0010\n",
      "2017-09-06 03:10:16,709 Verification error= 6.4%, loss= 0.3732\n",
      "2017-09-06 03:10:50,478 Iter 67600, Minibatch Loss= 0.4338, Training Accuracy= 0.7456, Minibatch error= 8.2%\n",
      "2017-09-06 03:16:09,093 Iter 67650, Minibatch Loss= 0.4182, Training Accuracy= 0.7672, Minibatch error= 6.5%\n",
      "2017-09-06 03:21:21,369 Epoch 676, Average loss: 0.0203, learning rate: 0.0010\n",
      "2017-09-06 03:21:21,439 Verification error= 5.8%, loss= 0.3202\n",
      "2017-09-06 03:21:55,435 Iter 67700, Minibatch Loss= 0.2333, Training Accuracy= 0.7466, Minibatch error= 6.9%\n",
      "2017-09-06 03:27:14,495 Iter 67750, Minibatch Loss= 0.1587, Training Accuracy= 0.7622, Minibatch error= 4.6%\n",
      "2017-09-06 03:32:27,122 Epoch 677, Average loss: 0.0193, learning rate: 0.0010\n",
      "2017-09-06 03:32:27,191 Verification error= 5.2%, loss= 0.2591\n",
      "2017-09-06 03:33:01,249 Iter 67800, Minibatch Loss= 0.2035, Training Accuracy= 0.7437, Minibatch error= 5.5%\n",
      "2017-09-06 03:38:20,962 Iter 67850, Minibatch Loss= 0.5567, Training Accuracy= 0.7799, Minibatch error= 6.5%\n",
      "2017-09-06 03:43:34,230 Epoch 678, Average loss: 0.0189, learning rate: 0.0010\n",
      "2017-09-06 03:43:34,302 Verification error= 6.1%, loss= 0.3856\n",
      "2017-09-06 03:44:08,305 Iter 67900, Minibatch Loss= 0.2600, Training Accuracy= 0.6982, Minibatch error= 6.5%\n",
      "2017-09-06 03:49:28,189 Iter 67950, Minibatch Loss= 0.2795, Training Accuracy= 0.6930, Minibatch error= 7.7%\n",
      "2017-09-06 03:54:41,917 Epoch 679, Average loss: 0.0185, learning rate: 0.0010\n",
      "2017-09-06 03:54:41,996 Verification error= 5.8%, loss= 0.3140\n",
      "2017-09-06 03:55:15,742 Iter 68000, Minibatch Loss= 0.2112, Training Accuracy= 0.7471, Minibatch error= 5.8%\n",
      "2017-09-06 04:00:36,019 Iter 68050, Minibatch Loss= 0.1931, Training Accuracy= 0.7505, Minibatch error= 5.5%\n",
      "2017-09-06 04:05:49,369 Epoch 680, Average loss: 0.0190, learning rate: 0.0010\n",
      "2017-09-06 04:05:49,440 Verification error= 6.5%, loss= 0.3939\n",
      "2017-09-06 04:06:25,804 Iter 68100, Minibatch Loss= 0.3238, Training Accuracy= 0.6794, Minibatch error= 6.5%\n",
      "2017-09-06 04:11:47,221 Iter 68150, Minibatch Loss= 0.4365, Training Accuracy= 0.7862, Minibatch error= 7.6%\n",
      "2017-09-06 04:17:01,640 Epoch 681, Average loss: 0.0206, learning rate: 0.0010\n",
      "2017-09-06 04:17:01,714 Verification error= 5.7%, loss= 0.3157\n",
      "2017-09-06 04:17:35,764 Iter 68200, Minibatch Loss= 1.0186, Training Accuracy= 0.7445, Minibatch error= 8.5%\n",
      "2017-09-06 04:22:56,775 Iter 68250, Minibatch Loss= 0.5423, Training Accuracy= 0.7539, Minibatch error= 7.8%\n",
      "2017-09-06 04:28:11,670 Epoch 682, Average loss: 0.0203, learning rate: 0.0010\n",
      "2017-09-06 04:28:11,741 Verification error= 5.6%, loss= 0.2446\n",
      "2017-09-06 04:28:45,732 Iter 68300, Minibatch Loss= 0.4876, Training Accuracy= 0.7737, Minibatch error= 7.3%\n",
      "2017-09-06 04:34:07,136 Iter 68350, Minibatch Loss= 0.2453, Training Accuracy= 0.7526, Minibatch error= 7.1%\n",
      "2017-09-06 04:39:22,437 Epoch 683, Average loss: 0.0204, learning rate: 0.0010\n",
      "2017-09-06 04:39:22,516 Verification error= 5.8%, loss= 0.3184\n",
      "2017-09-06 04:39:56,766 Iter 68400, Minibatch Loss= 0.1370, Training Accuracy= 0.7672, Minibatch error= 4.0%\n",
      "2017-09-06 04:45:18,532 Iter 68450, Minibatch Loss= 0.2222, Training Accuracy= 0.7396, Minibatch error= 5.6%\n",
      "2017-09-06 04:50:34,636 Epoch 684, Average loss: 0.0199, learning rate: 0.0010\n",
      "2017-09-06 04:50:34,706 Verification error= 5.5%, loss= 0.2538\n",
      "2017-09-06 04:51:09,138 Iter 68500, Minibatch Loss= 0.4393, Training Accuracy= 0.7898, Minibatch error= 6.2%\n",
      "2017-09-06 04:56:31,891 Iter 68550, Minibatch Loss= 0.1620, Training Accuracy= 0.7193, Minibatch error= 5.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 05:01:48,057 Epoch 685, Average loss: 0.0194, learning rate: 0.0010\n",
      "2017-09-06 05:01:48,136 Verification error= 6.7%, loss= 0.3812\n",
      "2017-09-06 05:02:22,442 Iter 68600, Minibatch Loss= 0.2644, Training Accuracy= 0.7057, Minibatch error= 7.7%\n",
      "2017-09-06 05:07:47,058 Iter 68650, Minibatch Loss= 0.1775, Training Accuracy= 0.7414, Minibatch error= 5.3%\n",
      "2017-09-06 05:13:05,939 Epoch 686, Average loss: 0.0191, learning rate: 0.0010\n",
      "2017-09-06 05:13:06,009 Verification error= 5.7%, loss= 0.3130\n",
      "2017-09-06 05:13:40,331 Iter 68700, Minibatch Loss= 0.1917, Training Accuracy= 0.7440, Minibatch error= 4.6%\n",
      "2017-09-06 05:19:03,345 Iter 68750, Minibatch Loss= 0.3203, Training Accuracy= 0.7104, Minibatch error= 6.7%\n",
      "2017-09-06 05:24:20,651 Epoch 687, Average loss: 0.0193, learning rate: 0.0010\n",
      "2017-09-06 05:24:20,725 Verification error= 5.7%, loss= 0.2820\n",
      "2017-09-06 05:24:55,415 Iter 68800, Minibatch Loss= 0.4439, Training Accuracy= 0.7622, Minibatch error= 8.1%\n",
      "2017-09-06 05:30:19,387 Iter 68850, Minibatch Loss= 0.9809, Training Accuracy= 0.7341, Minibatch error= 8.9%\n",
      "2017-09-06 05:35:36,261 Epoch 688, Average loss: 0.0190, learning rate: 0.0010\n",
      "2017-09-06 05:35:36,331 Verification error= 5.8%, loss= 0.3140\n",
      "2017-09-06 05:36:10,775 Iter 68900, Minibatch Loss= 0.4631, Training Accuracy= 0.7404, Minibatch error= 7.3%\n",
      "2017-09-06 05:41:34,673 Iter 68950, Minibatch Loss= 0.5137, Training Accuracy= 0.7734, Minibatch error= 7.6%\n",
      "2017-09-06 05:46:52,357 Epoch 689, Average loss: 0.0186, learning rate: 0.0010\n",
      "2017-09-06 05:46:52,431 Verification error= 5.9%, loss= 0.2822\n",
      "2017-09-06 05:47:26,832 Iter 69000, Minibatch Loss= 0.1886, Training Accuracy= 0.7563, Minibatch error= 6.5%\n",
      "2017-09-06 05:52:51,682 Iter 69050, Minibatch Loss= 0.2348, Training Accuracy= 0.7615, Minibatch error= 5.6%\n",
      "2017-09-06 05:58:09,524 Epoch 690, Average loss: 0.0190, learning rate: 0.0010\n",
      "2017-09-06 05:58:09,594 Verification error= 6.3%, loss= 0.3179\n",
      "2017-09-06 05:58:44,029 Iter 69100, Minibatch Loss= 0.2217, Training Accuracy= 0.7430, Minibatch error= 6.1%\n",
      "2017-09-06 06:04:08,775 Iter 69150, Minibatch Loss= 0.6754, Training Accuracy= 0.7714, Minibatch error= 7.1%\n",
      "2017-09-06 06:09:27,702 Epoch 691, Average loss: 0.0184, learning rate: 0.0010\n",
      "2017-09-06 06:09:27,774 Verification error= 6.0%, loss= 0.3139\n",
      "2017-09-06 06:10:02,847 Iter 69200, Minibatch Loss= 0.1942, Training Accuracy= 0.7167, Minibatch error= 6.1%\n",
      "2017-09-06 06:15:27,956 Iter 69250, Minibatch Loss= 0.2897, Training Accuracy= 0.6943, Minibatch error= 8.2%\n",
      "2017-09-06 06:20:47,689 Epoch 692, Average loss: 0.0211, learning rate: 0.0010\n",
      "2017-09-06 06:20:47,764 Verification error= 6.8%, loss= 0.4346\n",
      "2017-09-06 06:21:25,245 Iter 69300, Minibatch Loss= 0.2974, Training Accuracy= 0.7148, Minibatch error= 7.0%\n",
      "2017-09-06 06:26:51,223 Iter 69350, Minibatch Loss= 0.2120, Training Accuracy= 0.7664, Minibatch error= 5.2%\n",
      "2017-09-06 06:32:10,574 Epoch 693, Average loss: 0.0193, learning rate: 0.0010\n",
      "2017-09-06 06:32:10,652 Verification error= 5.9%, loss= 0.3389\n",
      "2017-09-06 06:32:45,459 Iter 69400, Minibatch Loss= 0.2917, Training Accuracy= 0.7042, Minibatch error= 5.6%\n",
      "2017-09-06 06:38:11,901 Iter 69450, Minibatch Loss= 0.4750, Training Accuracy= 0.7383, Minibatch error= 7.5%\n",
      "2017-09-06 06:43:32,215 Epoch 694, Average loss: 0.0193, learning rate: 0.0010\n",
      "2017-09-06 06:43:32,289 Verification error= 5.6%, loss= 0.2756\n",
      "2017-09-06 06:44:07,156 Iter 69500, Minibatch Loss= 1.0449, Training Accuracy= 0.7292, Minibatch error= 8.7%\n",
      "2017-09-06 06:49:34,644 Iter 69550, Minibatch Loss= 0.5146, Training Accuracy= 0.7417, Minibatch error= 7.8%\n",
      "2017-09-06 06:54:55,141 Epoch 695, Average loss: 0.0180, learning rate: 0.0010\n",
      "2017-09-06 06:54:55,211 Verification error= 5.8%, loss= 0.3067\n",
      "2017-09-06 06:55:29,990 Iter 69600, Minibatch Loss= 0.6830, Training Accuracy= 0.7318, Minibatch error= 8.5%\n",
      "2017-09-06 07:00:58,356 Iter 69650, Minibatch Loss= 0.2122, Training Accuracy= 0.7391, Minibatch error= 7.1%\n",
      "2017-09-06 07:06:19,044 Epoch 696, Average loss: 0.0183, learning rate: 0.0010\n",
      "2017-09-06 07:06:19,114 Verification error= 6.6%, loss= 0.4170\n",
      "2017-09-06 07:06:53,905 Iter 69700, Minibatch Loss= 0.1870, Training Accuracy= 0.7417, Minibatch error= 5.3%\n",
      "2017-09-06 07:12:21,725 Iter 69750, Minibatch Loss= 0.2889, Training Accuracy= 0.7201, Minibatch error= 6.1%\n",
      "2017-09-06 07:17:43,216 Epoch 697, Average loss: 0.0178, learning rate: 0.0010\n",
      "2017-09-06 07:17:43,295 Verification error= 6.9%, loss= 0.4306\n",
      "2017-09-06 07:18:18,161 Iter 69800, Minibatch Loss= 0.7760, Training Accuracy= 0.7641, Minibatch error= 6.6%\n",
      "2017-09-06 07:23:46,751 Iter 69850, Minibatch Loss= 0.1651, Training Accuracy= 0.7076, Minibatch error= 5.3%\n",
      "2017-09-06 07:29:08,546 Epoch 698, Average loss: 0.0179, learning rate: 0.0010\n",
      "2017-09-06 07:29:08,616 Verification error= 5.6%, loss= 0.3170\n",
      "2017-09-06 07:29:43,637 Iter 69900, Minibatch Loss= 0.2434, Training Accuracy= 0.6763, Minibatch error= 7.7%\n",
      "2017-09-06 07:35:13,422 Iter 69950, Minibatch Loss= 0.2711, Training Accuracy= 0.7164, Minibatch error= 5.9%\n",
      "2017-09-06 07:40:35,570 Epoch 699, Average loss: 0.0178, learning rate: 0.0010\n",
      "2017-09-06 07:40:35,643 Verification error= 5.7%, loss= 0.3465\n",
      "2017-09-06 07:41:10,716 Iter 70000, Minibatch Loss= 0.1852, Training Accuracy= 0.7664, Minibatch error= 5.5%\n",
      "2017-09-06 07:46:40,090 Iter 70050, Minibatch Loss= 0.2060, Training Accuracy= 0.7237, Minibatch error= 5.2%\n",
      "2017-09-06 07:52:02,254 Epoch 700, Average loss: 0.0199, learning rate: 0.0010\n",
      "2017-09-06 07:52:02,332 Verification error= 6.3%, loss= 0.3387\n",
      "2017-09-06 07:52:37,557 Iter 70100, Minibatch Loss= 0.5202, Training Accuracy= 0.7521, Minibatch error= 8.2%\n",
      "2017-09-06 07:58:07,144 Iter 70150, Minibatch Loss= 1.0059, Training Accuracy= 0.7500, Minibatch error= 9.6%\n",
      "2017-09-06 08:03:30,444 Epoch 701, Average loss: 0.0187, learning rate: 0.0010\n",
      "2017-09-06 08:03:30,522 Verification error= 6.2%, loss= 0.3427\n",
      "2017-09-06 08:04:05,685 Iter 70200, Minibatch Loss= 0.5337, Training Accuracy= 0.7438, Minibatch error= 8.4%\n",
      "2017-09-06 08:09:35,591 Iter 70250, Minibatch Loss= 0.5255, Training Accuracy= 0.7635, Minibatch error= 7.7%\n",
      "2017-09-06 08:15:00,621 Epoch 702, Average loss: 0.0183, learning rate: 0.0010\n",
      "2017-09-06 08:15:00,690 Verification error= 6.2%, loss= 0.3350\n",
      "2017-09-06 08:15:35,891 Iter 70300, Minibatch Loss= 0.2120, Training Accuracy= 0.7484, Minibatch error= 7.0%\n",
      "2017-09-06 08:21:07,136 Iter 70350, Minibatch Loss= 0.1711, Training Accuracy= 0.7617, Minibatch error= 4.4%\n",
      "2017-09-06 08:26:31,606 Epoch 703, Average loss: 0.0180, learning rate: 0.0010\n",
      "2017-09-06 08:26:31,682 Verification error= 5.4%, loss= 0.3111\n",
      "2017-09-06 08:27:08,940 Iter 70400, Minibatch Loss= 0.2512, Training Accuracy= 0.7107, Minibatch error= 5.8%\n",
      "2017-09-06 08:32:39,599 Iter 70450, Minibatch Loss= 0.4638, Training Accuracy= 0.7857, Minibatch error= 6.1%\n",
      "2017-09-06 08:38:04,078 Epoch 704, Average loss: 0.0189, learning rate: 0.0010\n",
      "2017-09-06 08:38:04,157 Verification error= 5.2%, loss= 0.2851\n",
      "2017-09-06 08:38:39,471 Iter 70500, Minibatch Loss= 0.1994, Training Accuracy= 0.7112, Minibatch error= 6.0%\n",
      "2017-09-06 08:44:10,726 Iter 70550, Minibatch Loss= 0.3093, Training Accuracy= 0.7042, Minibatch error= 7.6%\n",
      "2017-09-06 08:49:35,733 Epoch 705, Average loss: 0.0186, learning rate: 0.0010\n",
      "2017-09-06 08:49:35,807 Verification error= 5.7%, loss= 0.3096\n",
      "2017-09-06 08:50:11,186 Iter 70600, Minibatch Loss= 0.1949, Training Accuracy= 0.7727, Minibatch error= 5.5%\n",
      "2017-09-06 08:55:43,524 Iter 70650, Minibatch Loss= 0.2367, Training Accuracy= 0.7661, Minibatch error= 5.2%\n",
      "2017-09-06 09:01:11,966 Epoch 706, Average loss: 0.0179, learning rate: 0.0010\n",
      "2017-09-06 09:01:12,049 Verification error= 7.0%, loss= 0.5027\n",
      "2017-09-06 09:01:47,612 Iter 70700, Minibatch Loss= 0.4119, Training Accuracy= 0.6979, Minibatch error= 6.4%\n",
      "2017-09-06 09:07:19,641 Iter 70750, Minibatch Loss= 0.4391, Training Accuracy= 0.7805, Minibatch error= 7.2%\n",
      "2017-09-06 09:12:45,360 Epoch 707, Average loss: 0.0188, learning rate: 0.0010\n",
      "2017-09-06 09:12:45,441 Verification error= 5.9%, loss= 0.3206\n",
      "2017-09-06 09:13:21,191 Iter 70800, Minibatch Loss= 1.2027, Training Accuracy= 0.7469, Minibatch error= 9.8%\n",
      "2017-09-06 09:18:53,584 Iter 70850, Minibatch Loss= 0.6124, Training Accuracy= 0.7318, Minibatch error= 8.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 09:24:19,850 Epoch 708, Average loss: 0.0173, learning rate: 0.0010\n",
      "2017-09-06 09:24:19,924 Verification error= 6.0%, loss= 0.3729\n",
      "2017-09-06 09:24:55,339 Iter 70900, Minibatch Loss= 0.8051, Training Accuracy= 0.7672, Minibatch error= 7.8%\n",
      "2017-09-06 09:30:28,586 Iter 70950, Minibatch Loss= 0.1993, Training Accuracy= 0.7500, Minibatch error= 6.9%\n",
      "2017-09-06 09:35:56,358 Epoch 709, Average loss: 0.0175, learning rate: 0.0010\n",
      "2017-09-06 09:35:56,432 Verification error= 6.2%, loss= 0.4139\n",
      "2017-09-06 09:36:32,306 Iter 71000, Minibatch Loss= 0.2632, Training Accuracy= 0.7536, Minibatch error= 5.6%\n",
      "2017-09-06 09:42:05,409 Iter 71050, Minibatch Loss= 0.2805, Training Accuracy= 0.7490, Minibatch error= 5.4%\n",
      "2017-09-06 09:47:32,763 Epoch 710, Average loss: 0.0174, learning rate: 0.0010\n",
      "2017-09-06 09:47:32,838 Verification error= 6.0%, loss= 0.3671\n",
      "2017-09-06 09:48:08,493 Iter 71100, Minibatch Loss= 0.6548, Training Accuracy= 0.7797, Minibatch error= 6.5%\n",
      "2017-09-06 09:53:42,429 Iter 71150, Minibatch Loss= 0.2836, Training Accuracy= 0.7083, Minibatch error= 6.6%\n",
      "2017-09-06 09:59:09,780 Epoch 711, Average loss: 0.0184, learning rate: 0.0010\n",
      "2017-09-06 09:59:09,851 Verification error= 5.3%, loss= 0.3239\n",
      "2017-09-06 09:59:45,537 Iter 71200, Minibatch Loss= 0.2695, Training Accuracy= 0.7083, Minibatch error= 7.6%\n",
      "2017-09-06 10:05:21,432 Iter 71250, Minibatch Loss= 0.2223, Training Accuracy= 0.7628, Minibatch error= 6.0%\n",
      "2017-09-06 10:10:49,813 Epoch 712, Average loss: 0.0180, learning rate: 0.0010\n",
      "2017-09-06 10:10:49,892 Verification error= 5.7%, loss= 0.3046\n",
      "2017-09-06 10:11:25,861 Iter 71300, Minibatch Loss= 0.1836, Training Accuracy= 0.7771, Minibatch error= 5.0%\n",
      "2017-09-06 10:17:00,696 Iter 71350, Minibatch Loss= 0.2224, Training Accuracy= 0.7664, Minibatch error= 5.8%\n",
      "2017-09-06 10:22:28,541 Epoch 713, Average loss: 0.0182, learning rate: 0.0010\n",
      "2017-09-06 10:22:28,620 Verification error= 6.7%, loss= 0.4177\n",
      "2017-09-06 10:23:04,058 Iter 71400, Minibatch Loss= 0.7145, Training Accuracy= 0.7805, Minibatch error= 8.6%\n",
      "2017-09-06 10:28:39,578 Iter 71450, Minibatch Loss= 1.0102, Training Accuracy= 0.7505, Minibatch error= 8.5%\n",
      "2017-09-06 10:34:08,612 Epoch 714, Average loss: 0.0180, learning rate: 0.0010\n",
      "2017-09-06 10:34:08,686 Verification error= 6.9%, loss= 0.4639\n",
      "2017-09-06 10:34:46,672 Iter 71500, Minibatch Loss= 0.6687, Training Accuracy= 0.7490, Minibatch error= 9.4%\n",
      "2017-09-06 10:40:23,615 Iter 71550, Minibatch Loss= 0.6366, Training Accuracy= 0.7865, Minibatch error= 7.5%\n",
      "2017-09-06 10:45:52,429 Epoch 715, Average loss: 0.0188, learning rate: 0.0010\n",
      "2017-09-06 10:45:52,503 Verification error= 6.0%, loss= 0.3968\n",
      "2017-09-06 10:46:28,895 Iter 71600, Minibatch Loss= 0.2845, Training Accuracy= 0.7630, Minibatch error= 7.1%\n",
      "2017-09-06 10:52:05,211 Iter 71650, Minibatch Loss= 0.2087, Training Accuracy= 0.7490, Minibatch error= 5.4%\n",
      "2017-09-06 10:57:35,071 Epoch 716, Average loss: 0.0181, learning rate: 0.0010\n",
      "2017-09-06 10:57:35,142 Verification error= 5.7%, loss= 0.2980\n",
      "2017-09-06 10:58:10,885 Iter 71700, Minibatch Loss= 0.2282, Training Accuracy= 0.7531, Minibatch error= 6.0%\n",
      "2017-09-06 11:03:48,108 Iter 71750, Minibatch Loss= 0.7050, Training Accuracy= 0.7753, Minibatch error= 6.6%\n",
      "2017-09-06 11:09:18,172 Epoch 717, Average loss: 0.0179, learning rate: 0.0010\n",
      "2017-09-06 11:09:18,246 Verification error= 6.4%, loss= 0.4009\n",
      "2017-09-06 11:09:54,018 Iter 71800, Minibatch Loss= 0.2264, Training Accuracy= 0.7393, Minibatch error= 6.5%\n",
      "2017-09-06 11:15:30,912 Iter 71850, Minibatch Loss= 0.2650, Training Accuracy= 0.7107, Minibatch error= 8.0%\n",
      "2017-09-06 11:21:00,761 Epoch 718, Average loss: 0.0173, learning rate: 0.0010\n",
      "2017-09-06 11:21:00,840 Verification error= 5.9%, loss= 0.3635\n",
      "2017-09-06 11:21:36,726 Iter 71900, Minibatch Loss= 0.1844, Training Accuracy= 0.7706, Minibatch error= 5.0%\n",
      "2017-09-06 11:27:16,095 Iter 71950, Minibatch Loss= 0.1985, Training Accuracy= 0.7823, Minibatch error= 6.1%\n",
      "2017-09-06 11:32:48,696 Epoch 719, Average loss: 0.0181, learning rate: 0.0010\n",
      "2017-09-06 11:32:48,765 Verification error= 6.0%, loss= 0.3592\n",
      "2017-09-06 11:33:24,817 Iter 72000, Minibatch Loss= 0.3205, Training Accuracy= 0.7326, Minibatch error= 6.5%\n",
      "2017-09-06 11:39:04,431 Iter 72050, Minibatch Loss= 0.6555, Training Accuracy= 0.7576, Minibatch error= 8.3%\n",
      "2017-09-06 11:44:36,519 Epoch 720, Average loss: 0.0179, learning rate: 0.0010\n",
      "2017-09-06 11:44:36,590 Verification error= 6.1%, loss= 0.3741\n",
      "2017-09-06 11:45:12,883 Iter 72100, Minibatch Loss= 1.4507, Training Accuracy= 0.7370, Minibatch error= 10.0%\n",
      "2017-09-06 11:50:52,712 Iter 72150, Minibatch Loss= 0.6940, Training Accuracy= 0.7555, Minibatch error= 9.2%\n",
      "2017-09-06 11:56:25,380 Epoch 721, Average loss: 0.0182, learning rate: 0.0010\n",
      "2017-09-06 11:56:25,450 Verification error= 6.5%, loss= 0.5284\n",
      "2017-09-06 11:57:01,513 Iter 72200, Minibatch Loss= 1.1986, Training Accuracy= 0.7698, Minibatch error= 9.0%\n",
      "2017-09-06 12:02:41,616 Iter 72250, Minibatch Loss= 0.2828, Training Accuracy= 0.7602, Minibatch error= 7.6%\n",
      "2017-09-06 12:08:14,938 Epoch 722, Average loss: 0.0174, learning rate: 0.0010\n",
      "2017-09-06 12:08:15,010 Verification error= 6.6%, loss= 0.4768\n",
      "2017-09-06 12:08:51,145 Iter 72300, Minibatch Loss= 0.3063, Training Accuracy= 0.7625, Minibatch error= 5.3%\n",
      "2017-09-06 12:14:31,840 Iter 72350, Minibatch Loss= 0.2414, Training Accuracy= 0.7456, Minibatch error= 6.3%\n",
      "2017-09-06 12:20:06,652 Epoch 723, Average loss: 0.0168, learning rate: 0.0010\n",
      "2017-09-06 12:20:06,722 Verification error= 6.8%, loss= 0.4899\n",
      "2017-09-06 12:20:43,102 Iter 72400, Minibatch Loss= 0.8373, Training Accuracy= 0.7651, Minibatch error= 7.0%\n",
      "2017-09-06 12:26:24,442 Iter 72450, Minibatch Loss= 0.2642, Training Accuracy= 0.7094, Minibatch error= 6.6%\n",
      "2017-09-06 12:31:58,998 Epoch 724, Average loss: 0.0164, learning rate: 0.0010\n",
      "2017-09-06 12:31:59,077 Verification error= 6.3%, loss= 0.4505\n",
      "2017-09-06 12:32:35,457 Iter 72500, Minibatch Loss= 0.3475, Training Accuracy= 0.6974, Minibatch error= 8.2%\n",
      "2017-09-06 12:38:17,370 Iter 72550, Minibatch Loss= 0.2240, Training Accuracy= 0.7518, Minibatch error= 5.9%\n",
      "2017-09-06 12:43:52,182 Epoch 725, Average loss: 0.0172, learning rate: 0.0010\n",
      "2017-09-06 12:43:52,253 Verification error= 6.7%, loss= 0.4250\n",
      "2017-09-06 12:44:31,633 Iter 72600, Minibatch Loss= 0.1937, Training Accuracy= 0.7805, Minibatch error= 5.6%\n",
      "2017-09-06 12:50:13,991 Iter 72650, Minibatch Loss= 0.2515, Training Accuracy= 0.7227, Minibatch error= 6.0%\n",
      "2017-09-06 12:55:49,200 Epoch 726, Average loss: 0.0172, learning rate: 0.0010\n",
      "2017-09-06 12:55:49,270 Verification error= 5.9%, loss= 0.3444\n",
      "2017-09-06 12:56:25,920 Iter 72700, Minibatch Loss= 0.5303, Training Accuracy= 0.7315, Minibatch error= 8.3%\n",
      "2017-09-06 13:02:08,493 Iter 72750, Minibatch Loss= 1.1827, Training Accuracy= 0.7266, Minibatch error= 8.8%\n",
      "2017-09-06 13:07:44,932 Epoch 727, Average loss: 0.0168, learning rate: 0.0010\n",
      "2017-09-06 13:07:45,003 Verification error= 4.8%, loss= 0.2298\n",
      "2017-09-06 13:08:21,398 Iter 72800, Minibatch Loss= 0.5499, Training Accuracy= 0.7714, Minibatch error= 6.8%\n",
      "2017-09-06 13:14:04,593 Iter 72850, Minibatch Loss= 0.6752, Training Accuracy= 0.7326, Minibatch error= 8.0%\n",
      "2017-09-06 13:19:40,486 Epoch 728, Average loss: 0.0177, learning rate: 0.0010\n",
      "2017-09-06 13:19:40,556 Verification error= 5.6%, loss= 0.3001\n",
      "2017-09-06 13:20:17,161 Iter 72900, Minibatch Loss= 0.1981, Training Accuracy= 0.7521, Minibatch error= 6.4%\n",
      "2017-09-06 13:26:00,728 Iter 72950, Minibatch Loss= 0.1776, Training Accuracy= 0.7719, Minibatch error= 4.3%\n",
      "2017-09-06 13:31:37,248 Epoch 729, Average loss: 0.0167, learning rate: 0.0010\n",
      "2017-09-06 13:31:37,318 Verification error= 6.0%, loss= 0.3415\n",
      "2017-09-06 13:32:13,721 Iter 73000, Minibatch Loss= 0.2516, Training Accuracy= 0.7362, Minibatch error= 5.5%\n",
      "2017-09-06 13:37:58,231 Iter 73050, Minibatch Loss= 0.8834, Training Accuracy= 0.7807, Minibatch error= 6.7%\n",
      "2017-09-06 13:43:35,845 Epoch 730, Average loss: 0.0160, learning rate: 0.0010\n",
      "2017-09-06 13:43:35,918 Verification error= 6.5%, loss= 0.4276\n",
      "2017-09-06 13:44:12,264 Iter 73100, Minibatch Loss= 0.2569, Training Accuracy= 0.6984, Minibatch error= 6.0%\n",
      "2017-09-06 13:49:56,817 Iter 73150, Minibatch Loss= 0.2893, Training Accuracy= 0.7336, Minibatch error= 9.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 13:55:34,450 Epoch 731, Average loss: 0.0176, learning rate: 0.0010\n",
      "2017-09-06 13:55:34,524 Verification error= 5.9%, loss= 0.3854\n",
      "2017-09-06 13:56:11,028 Iter 73200, Minibatch Loss= 0.1870, Training Accuracy= 0.7990, Minibatch error= 4.8%\n",
      "2017-09-06 14:01:55,856 Iter 73250, Minibatch Loss= 0.2362, Training Accuracy= 0.7724, Minibatch error= 6.5%\n",
      "2017-09-06 14:07:33,542 Epoch 732, Average loss: 0.0174, learning rate: 0.0010\n",
      "2017-09-06 14:07:33,612 Verification error= 6.2%, loss= 0.3607\n",
      "2017-09-06 14:08:10,194 Iter 73300, Minibatch Loss= 0.3189, Training Accuracy= 0.7573, Minibatch error= 6.5%\n",
      "2017-09-06 14:13:55,711 Iter 73350, Minibatch Loss= 0.6915, Training Accuracy= 0.7823, Minibatch error= 8.3%\n",
      "2017-09-06 14:19:34,939 Epoch 733, Average loss: 0.0160, learning rate: 0.0010\n",
      "2017-09-06 14:19:35,017 Verification error= 6.4%, loss= 0.4388\n",
      "2017-09-06 14:20:11,512 Iter 73400, Minibatch Loss= 1.6194, Training Accuracy= 0.7297, Minibatch error= 10.7%\n",
      "2017-09-06 14:25:57,142 Iter 73450, Minibatch Loss= 0.7587, Training Accuracy= 0.7531, Minibatch error= 8.9%\n",
      "2017-09-06 14:31:36,704 Epoch 734, Average loss: 0.0189, learning rate: 0.0010\n",
      "2017-09-06 14:31:36,783 Verification error= 5.5%, loss= 0.3081\n",
      "2017-09-06 14:32:13,313 Iter 73500, Minibatch Loss= 0.6671, Training Accuracy= 0.7591, Minibatch error= 7.9%\n",
      "2017-09-06 14:38:00,045 Iter 73550, Minibatch Loss= 0.2166, Training Accuracy= 0.7643, Minibatch error= 6.8%\n",
      "2017-09-06 14:43:39,481 Epoch 735, Average loss: 0.0176, learning rate: 0.0010\n",
      "2017-09-06 14:43:39,555 Verification error= 6.7%, loss= 0.4472\n",
      "2017-09-06 14:44:16,268 Iter 73600, Minibatch Loss= 0.2169, Training Accuracy= 0.7862, Minibatch error= 5.7%\n",
      "2017-09-06 14:50:02,564 Iter 73650, Minibatch Loss= 0.2835, Training Accuracy= 0.7641, Minibatch error= 5.6%\n",
      "2017-09-06 14:55:44,000 Epoch 736, Average loss: 0.0166, learning rate: 0.0010\n",
      "2017-09-06 14:55:44,070 Verification error= 5.7%, loss= 0.3191\n",
      "2017-09-06 14:56:23,222 Iter 73700, Minibatch Loss= 0.6628, Training Accuracy= 0.7833, Minibatch error= 6.6%\n",
      "2017-09-06 15:02:10,200 Iter 73750, Minibatch Loss= 0.2504, Training Accuracy= 0.7344, Minibatch error= 6.3%\n",
      "2017-09-06 15:07:50,680 Epoch 737, Average loss: 0.0169, learning rate: 0.0010\n",
      "2017-09-06 15:07:50,750 Verification error= 6.2%, loss= 0.4065\n",
      "2017-09-06 15:08:27,807 Iter 73800, Minibatch Loss= 0.2995, Training Accuracy= 0.7289, Minibatch error= 8.4%\n",
      "2017-09-06 15:14:15,327 Iter 73850, Minibatch Loss= 0.2333, Training Accuracy= 0.7789, Minibatch error= 5.8%\n",
      "2017-09-06 15:19:56,251 Epoch 738, Average loss: 0.0175, learning rate: 0.0010\n",
      "2017-09-06 15:19:56,321 Verification error= 7.1%, loss= 0.5176\n",
      "2017-09-06 15:20:33,297 Iter 73900, Minibatch Loss= 0.2083, Training Accuracy= 0.7904, Minibatch error= 6.0%\n",
      "2017-09-06 15:26:21,339 Iter 73950, Minibatch Loss= 0.3443, Training Accuracy= 0.7672, Minibatch error= 5.9%\n",
      "2017-09-06 15:32:02,433 Epoch 739, Average loss: 0.0180, learning rate: 0.0010\n",
      "2017-09-06 15:32:02,512 Verification error= 6.5%, loss= 0.4553\n",
      "2017-09-06 15:32:39,661 Iter 74000, Minibatch Loss= 0.8150, Training Accuracy= 0.7617, Minibatch error= 8.5%\n",
      "2017-09-06 15:38:28,203 Iter 74050, Minibatch Loss= 1.4047, Training Accuracy= 0.7500, Minibatch error= 10.2%\n",
      "2017-09-06 15:44:09,632 Epoch 740, Average loss: 0.0158, learning rate: 0.0010\n",
      "2017-09-06 15:44:09,706 Verification error= 6.1%, loss= 0.4048\n",
      "2017-09-06 15:44:46,603 Iter 74100, Minibatch Loss= 0.7640, Training Accuracy= 0.7497, Minibatch error= 8.4%\n",
      "2017-09-06 15:50:35,661 Iter 74150, Minibatch Loss= 0.7958, Training Accuracy= 0.7789, Minibatch error= 7.8%\n",
      "2017-09-06 15:56:17,607 Epoch 741, Average loss: 0.0160, learning rate: 0.0010\n",
      "2017-09-06 15:56:17,677 Verification error= 6.6%, loss= 0.4326\n",
      "2017-09-06 15:56:54,788 Iter 74200, Minibatch Loss= 0.2236, Training Accuracy= 0.7552, Minibatch error= 7.0%\n",
      "2017-09-06 16:02:44,350 Iter 74250, Minibatch Loss= 0.3077, Training Accuracy= 0.7628, Minibatch error= 5.5%\n",
      "2017-09-06 16:08:27,660 Epoch 742, Average loss: 0.0164, learning rate: 0.0010\n",
      "2017-09-06 16:08:27,736 Verification error= 5.7%, loss= 0.3488\n",
      "2017-09-06 16:09:04,711 Iter 74300, Minibatch Loss= 0.2605, Training Accuracy= 0.7505, Minibatch error= 5.2%\n",
      "2017-09-06 16:14:56,915 Iter 74350, Minibatch Loss= 0.9712, Training Accuracy= 0.7664, Minibatch error= 7.6%\n",
      "2017-09-06 16:20:40,821 Epoch 743, Average loss: 0.0172, learning rate: 0.0010\n",
      "2017-09-06 16:20:40,900 Verification error= 5.2%, loss= 0.2634\n",
      "2017-09-06 16:21:17,923 Iter 74400, Minibatch Loss= 0.2052, Training Accuracy= 0.7122, Minibatch error= 5.3%\n",
      "2017-09-06 16:27:08,297 Iter 74450, Minibatch Loss= 0.2680, Training Accuracy= 0.6974, Minibatch error= 9.3%\n",
      "2017-09-06 16:32:52,256 Epoch 744, Average loss: 0.0173, learning rate: 0.0010\n",
      "2017-09-06 16:32:52,327 Verification error= 6.0%, loss= 0.2917\n",
      "2017-09-06 16:33:29,595 Iter 74500, Minibatch Loss= 0.1966, Training Accuracy= 0.7815, Minibatch error= 5.4%\n",
      "2017-09-06 16:39:21,091 Iter 74550, Minibatch Loss= 0.2124, Training Accuracy= 0.7862, Minibatch error= 5.5%\n",
      "2017-09-06 16:45:04,958 Epoch 745, Average loss: 0.0162, learning rate: 0.0010\n",
      "2017-09-06 16:45:05,029 Verification error= 5.4%, loss= 0.3135\n",
      "2017-09-06 16:45:42,458 Iter 74600, Minibatch Loss= 0.2475, Training Accuracy= 0.7310, Minibatch error= 5.6%\n",
      "2017-09-06 16:51:34,082 Iter 74650, Minibatch Loss= 0.6119, Training Accuracy= 0.7857, Minibatch error= 8.2%\n",
      "2017-09-06 16:57:18,599 Epoch 746, Average loss: 0.0162, learning rate: 0.0010\n",
      "2017-09-06 16:57:18,673 Verification error= 5.7%, loss= 0.3470\n",
      "2017-09-06 16:57:56,017 Iter 74700, Minibatch Loss= 1.3132, Training Accuracy= 0.6893, Minibatch error= 10.1%\n",
      "2017-09-06 17:03:47,697 Iter 74750, Minibatch Loss= 0.5168, Training Accuracy= 0.7276, Minibatch error= 8.0%\n",
      "2017-09-06 17:09:32,765 Epoch 747, Average loss: 0.0172, learning rate: 0.0010\n",
      "2017-09-06 17:09:32,839 Verification error= 5.7%, loss= 0.3324\n",
      "2017-09-06 17:10:10,453 Iter 74800, Minibatch Loss= 0.6867, Training Accuracy= 0.7716, Minibatch error= 8.0%\n",
      "2017-09-06 17:16:03,401 Iter 74850, Minibatch Loss= 0.2012, Training Accuracy= 0.7630, Minibatch error= 6.7%\n",
      "2017-09-06 17:21:49,066 Epoch 748, Average loss: 0.0175, learning rate: 0.0010\n",
      "2017-09-06 17:21:49,137 Verification error= 5.7%, loss= 0.3302\n",
      "2017-09-06 17:22:28,796 Iter 74900, Minibatch Loss= 0.1582, Training Accuracy= 0.7818, Minibatch error= 3.9%\n",
      "2017-09-06 17:28:22,954 Iter 74950, Minibatch Loss= 0.2412, Training Accuracy= 0.7312, Minibatch error= 5.2%\n",
      "2017-09-06 17:34:08,933 Epoch 749, Average loss: 0.0157, learning rate: 0.0010\n",
      "2017-09-06 17:34:09,004 Verification error= 6.6%, loss= 0.4293\n",
      "2017-09-06 17:34:46,479 Iter 75000, Minibatch Loss= 0.9317, Training Accuracy= 0.7711, Minibatch error= 7.8%\n",
      "2017-09-06 17:40:40,689 Iter 75050, Minibatch Loss= 0.2449, Training Accuracy= 0.6971, Minibatch error= 6.2%\n",
      "2017-09-06 17:46:26,847 Epoch 750, Average loss: 0.0160, learning rate: 0.0010\n",
      "2017-09-06 17:46:26,921 Verification error= 5.4%, loss= 0.2525\n",
      "2017-09-06 17:47:04,434 Iter 75100, Minibatch Loss= 0.3019, Training Accuracy= 0.7057, Minibatch error= 9.3%\n",
      "2017-09-06 17:52:58,291 Iter 75150, Minibatch Loss= 0.2126, Training Accuracy= 0.7672, Minibatch error= 5.2%\n",
      "2017-09-06 17:58:45,339 Epoch 751, Average loss: 0.0177, learning rate: 0.0010\n",
      "2017-09-06 17:58:45,410 Verification error= 6.0%, loss= 0.3425\n",
      "2017-09-06 17:59:23,082 Iter 75200, Minibatch Loss= 0.2233, Training Accuracy= 0.7747, Minibatch error= 6.2%\n",
      "2017-09-06 18:05:17,413 Iter 75250, Minibatch Loss= 0.3110, Training Accuracy= 0.7117, Minibatch error= 5.7%\n",
      "2017-09-06 18:11:04,796 Epoch 752, Average loss: 0.0159, learning rate: 0.0010\n",
      "2017-09-06 18:11:04,867 Verification error= 6.6%, loss= 0.4364\n",
      "2017-09-06 18:11:42,739 Iter 75300, Minibatch Loss= 0.6798, Training Accuracy= 0.7542, Minibatch error= 8.6%\n",
      "2017-09-06 18:17:38,059 Iter 75350, Minibatch Loss= 1.5380, Training Accuracy= 0.7289, Minibatch error= 10.7%\n",
      "2017-09-06 18:23:24,745 Epoch 753, Average loss: 0.0170, learning rate: 0.0010\n",
      "2017-09-06 18:23:24,820 Verification error= 6.1%, loss= 0.4201\n",
      "2017-09-06 18:24:02,057 Iter 75400, Minibatch Loss= 0.7730, Training Accuracy= 0.7529, Minibatch error= 8.4%\n",
      "2017-09-06 18:29:57,201 Iter 75450, Minibatch Loss= 0.7428, Training Accuracy= 0.7456, Minibatch error= 8.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 18:35:45,914 Epoch 754, Average loss: 0.0144, learning rate: 0.0010\n",
      "2017-09-06 18:35:45,988 Verification error= 5.6%, loss= 0.3255\n",
      "2017-09-06 18:36:23,391 Iter 75500, Minibatch Loss= 0.1920, Training Accuracy= 0.7445, Minibatch error= 5.6%\n",
      "2017-09-06 18:42:20,060 Iter 75550, Minibatch Loss= 0.1428, Training Accuracy= 0.7831, Minibatch error= 4.1%\n",
      "2017-09-06 18:48:10,053 Epoch 755, Average loss: 0.0178, learning rate: 0.0010\n",
      "2017-09-06 18:48:10,123 Verification error= 5.9%, loss= 0.4006\n",
      "2017-09-06 18:48:47,454 Iter 75600, Minibatch Loss= 0.2822, Training Accuracy= 0.7341, Minibatch error= 5.8%\n",
      "2017-09-06 18:54:44,315 Iter 75650, Minibatch Loss= 0.7152, Training Accuracy= 0.7904, Minibatch error= 6.2%\n",
      "2017-09-06 19:00:33,825 Epoch 756, Average loss: 0.0162, learning rate: 0.0010\n",
      "2017-09-06 19:00:33,895 Verification error= 5.2%, loss= 0.2716\n",
      "2017-09-06 19:01:11,225 Iter 75700, Minibatch Loss= 0.1391, Training Accuracy= 0.7021, Minibatch error= 5.0%\n",
      "2017-09-06 19:07:09,177 Iter 75750, Minibatch Loss= 0.2904, Training Accuracy= 0.7065, Minibatch error= 8.4%\n",
      "2017-09-06 19:12:59,892 Epoch 757, Average loss: 0.0170, learning rate: 0.0010\n",
      "2017-09-06 19:12:59,970 Verification error= 6.0%, loss= 0.3543\n",
      "2017-09-06 19:13:37,281 Iter 75800, Minibatch Loss= 0.2436, Training Accuracy= 0.7583, Minibatch error= 6.2%\n",
      "2017-09-06 19:19:36,214 Iter 75850, Minibatch Loss= 0.2467, Training Accuracy= 0.7518, Minibatch error= 4.9%\n",
      "2017-09-06 19:25:25,819 Epoch 758, Average loss: 0.0159, learning rate: 0.0010\n",
      "2017-09-06 19:25:25,894 Verification error= 5.9%, loss= 0.3573\n",
      "2017-09-06 19:26:03,402 Iter 75900, Minibatch Loss= 0.3427, Training Accuracy= 0.7513, Minibatch error= 5.8%\n",
      "2017-09-06 19:32:00,189 Iter 75950, Minibatch Loss= 0.6813, Training Accuracy= 0.7674, Minibatch error= 9.0%\n",
      "2017-09-06 19:37:49,519 Epoch 759, Average loss: 0.0157, learning rate: 0.0010\n",
      "2017-09-06 19:37:49,593 Verification error= 5.3%, loss= 0.2817\n",
      "2017-09-06 19:38:29,671 Iter 76000, Minibatch Loss= 1.1066, Training Accuracy= 0.7357, Minibatch error= 9.5%\n",
      "2017-09-06 19:44:26,391 Iter 76050, Minibatch Loss= 0.6217, Training Accuracy= 0.7568, Minibatch error= 7.3%\n",
      "2017-09-06 19:50:16,216 Epoch 760, Average loss: 0.0147, learning rate: 0.0010\n",
      "2017-09-06 19:50:16,287 Verification error= 6.4%, loss= 0.4432\n",
      "2017-09-06 19:50:53,657 Iter 76100, Minibatch Loss= 0.9420, Training Accuracy= 0.7711, Minibatch error= 8.5%\n",
      "2017-09-06 19:56:51,245 Iter 76150, Minibatch Loss= 0.2505, Training Accuracy= 0.7721, Minibatch error= 6.5%\n",
      "2017-09-06 20:02:42,032 Epoch 761, Average loss: 0.0156, learning rate: 0.0010\n",
      "2017-09-06 20:02:42,101 Verification error= 5.7%, loss= 0.3177\n",
      "2017-09-06 20:03:19,510 Iter 76200, Minibatch Loss= 0.1704, Training Accuracy= 0.7958, Minibatch error= 4.6%\n",
      "2017-09-06 20:09:18,416 Iter 76250, Minibatch Loss= 0.2731, Training Accuracy= 0.7440, Minibatch error= 6.2%\n",
      "2017-09-06 20:15:09,410 Epoch 762, Average loss: 0.0157, learning rate: 0.0010\n",
      "2017-09-06 20:15:09,481 Verification error= 6.2%, loss= 0.4217\n",
      "2017-09-06 20:15:47,076 Iter 76300, Minibatch Loss= 0.8697, Training Accuracy= 0.7792, Minibatch error= 7.7%\n",
      "2017-09-06 20:21:46,009 Iter 76350, Minibatch Loss= 0.2384, Training Accuracy= 0.6979, Minibatch error= 6.2%\n",
      "2017-09-06 20:27:37,005 Epoch 763, Average loss: 0.0147, learning rate: 0.0010\n",
      "2017-09-06 20:27:37,075 Verification error= 6.1%, loss= 0.3538\n",
      "2017-09-06 20:28:14,439 Iter 76400, Minibatch Loss= 0.3169, Training Accuracy= 0.6953, Minibatch error= 9.0%\n",
      "2017-09-06 20:34:14,793 Iter 76450, Minibatch Loss= 0.2530, Training Accuracy= 0.7430, Minibatch error= 5.9%\n",
      "2017-09-06 20:40:06,854 Epoch 764, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-06 20:40:06,924 Verification error= 5.7%, loss= 0.3481\n",
      "2017-09-06 20:40:44,476 Iter 76500, Minibatch Loss= 0.2047, Training Accuracy= 0.7656, Minibatch error= 4.7%\n",
      "2017-09-06 20:46:44,378 Iter 76550, Minibatch Loss= 0.3057, Training Accuracy= 0.7388, Minibatch error= 6.0%\n",
      "2017-09-06 20:52:37,472 Epoch 765, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-06 20:52:37,545 Verification error= 5.8%, loss= 0.3171\n",
      "2017-09-06 20:53:14,995 Iter 76600, Minibatch Loss= 0.6126, Training Accuracy= 0.7599, Minibatch error= 7.8%\n",
      "2017-09-06 20:59:14,695 Iter 76650, Minibatch Loss= 1.3236, Training Accuracy= 0.6982, Minibatch error= 9.2%\n",
      "2017-09-06 21:05:08,902 Epoch 766, Average loss: 0.0149, learning rate: 0.0010\n",
      "2017-09-06 21:05:08,973 Verification error= 5.5%, loss= 0.3402\n",
      "2017-09-06 21:05:46,803 Iter 76700, Minibatch Loss= 0.4813, Training Accuracy= 0.7167, Minibatch error= 8.5%\n",
      "2017-09-06 21:11:47,056 Iter 76750, Minibatch Loss= 0.8818, Training Accuracy= 0.7370, Minibatch error= 8.8%\n",
      "2017-09-06 21:17:40,705 Epoch 767, Average loss: 0.0154, learning rate: 0.0010\n",
      "2017-09-06 21:17:40,779 Verification error= 5.6%, loss= 0.3176\n",
      "2017-09-06 21:18:18,441 Iter 76800, Minibatch Loss= 0.2084, Training Accuracy= 0.7458, Minibatch error= 6.7%\n",
      "2017-09-06 21:24:19,262 Iter 76850, Minibatch Loss= 0.2347, Training Accuracy= 0.7539, Minibatch error= 5.0%\n",
      "2017-09-06 21:30:12,787 Epoch 768, Average loss: 0.0163, learning rate: 0.0010\n",
      "2017-09-06 21:30:12,859 Verification error= 5.0%, loss= 0.2471\n",
      "2017-09-06 21:30:50,698 Iter 76900, Minibatch Loss= 0.2419, Training Accuracy= 0.7357, Minibatch error= 5.8%\n",
      "2017-09-06 21:36:52,417 Iter 76950, Minibatch Loss= 0.6468, Training Accuracy= 0.7857, Minibatch error= 6.5%\n",
      "2017-09-06 21:42:47,459 Epoch 769, Average loss: 0.0156, learning rate: 0.0010\n",
      "2017-09-06 21:42:47,529 Verification error= 5.3%, loss= 0.2829\n",
      "2017-09-06 21:43:25,156 Iter 77000, Minibatch Loss= 0.1388, Training Accuracy= 0.7247, Minibatch error= 5.1%\n",
      "2017-09-06 21:49:26,956 Iter 77050, Minibatch Loss= 0.3080, Training Accuracy= 0.7141, Minibatch error= 7.7%\n",
      "2017-09-06 21:55:21,647 Epoch 770, Average loss: 0.0144, learning rate: 0.0010\n",
      "2017-09-06 21:55:21,718 Verification error= 6.1%, loss= 0.4015\n",
      "2017-09-06 21:56:02,886 Iter 77100, Minibatch Loss= 0.2515, Training Accuracy= 0.7401, Minibatch error= 5.5%\n",
      "2017-09-06 22:02:05,504 Iter 77150, Minibatch Loss= 0.1762, Training Accuracy= 0.7797, Minibatch error= 4.3%\n",
      "2017-09-06 22:08:00,100 Epoch 771, Average loss: 0.0145, learning rate: 0.0010\n",
      "2017-09-06 22:08:00,170 Verification error= 6.6%, loss= 0.4699\n",
      "2017-09-06 22:08:38,050 Iter 77200, Minibatch Loss= 0.4692, Training Accuracy= 0.7380, Minibatch error= 6.7%\n",
      "2017-09-06 22:14:40,389 Iter 77250, Minibatch Loss= 0.6587, Training Accuracy= 0.7872, Minibatch error= 7.9%\n",
      "2017-09-06 22:20:35,550 Epoch 772, Average loss: 0.0169, learning rate: 0.0010\n",
      "2017-09-06 22:20:35,620 Verification error= 6.0%, loss= 0.3376\n",
      "2017-09-06 22:21:13,691 Iter 77300, Minibatch Loss= 1.2406, Training Accuracy= 0.7068, Minibatch error= 9.8%\n",
      "2017-09-06 22:27:16,932 Iter 77350, Minibatch Loss= 0.3677, Training Accuracy= 0.7789, Minibatch error= 6.5%\n",
      "2017-09-06 22:33:12,796 Epoch 773, Average loss: 0.0150, learning rate: 0.0010\n",
      "2017-09-06 22:33:12,866 Verification error= 6.5%, loss= 0.3804\n",
      "2017-09-06 22:33:50,647 Iter 77400, Minibatch Loss= 0.7126, Training Accuracy= 0.7786, Minibatch error= 8.4%\n",
      "2017-09-06 22:39:54,244 Iter 77450, Minibatch Loss= 0.1909, Training Accuracy= 0.7758, Minibatch error= 6.5%\n",
      "2017-09-06 22:45:50,234 Epoch 774, Average loss: 0.0149, learning rate: 0.0010\n",
      "2017-09-06 22:45:50,304 Verification error= 5.8%, loss= 0.3370\n",
      "2017-09-06 22:46:28,305 Iter 77500, Minibatch Loss= 0.1924, Training Accuracy= 0.8010, Minibatch error= 4.6%\n",
      "2017-09-06 22:52:31,929 Iter 77550, Minibatch Loss= 0.4040, Training Accuracy= 0.7323, Minibatch error= 6.9%\n",
      "2017-09-06 22:58:29,863 Epoch 775, Average loss: 0.0149, learning rate: 0.0010\n",
      "2017-09-06 22:58:29,933 Verification error= 5.8%, loss= 0.3282\n",
      "2017-09-06 22:59:07,973 Iter 77600, Minibatch Loss= 0.7776, Training Accuracy= 0.7734, Minibatch error= 6.9%\n",
      "2017-09-06 23:05:12,138 Iter 77650, Minibatch Loss= 0.1643, Training Accuracy= 0.7201, Minibatch error= 5.7%\n",
      "2017-09-06 23:11:10,149 Epoch 776, Average loss: 0.0147, learning rate: 0.0010\n",
      "2017-09-06 23:11:10,220 Verification error= 5.8%, loss= 0.3245\n",
      "2017-09-06 23:11:48,426 Iter 77700, Minibatch Loss= 0.3046, Training Accuracy= 0.7143, Minibatch error= 7.8%\n",
      "2017-09-06 23:17:53,302 Iter 77750, Minibatch Loss= 0.2687, Training Accuracy= 0.7445, Minibatch error= 5.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-06 23:23:51,202 Epoch 777, Average loss: 0.0157, learning rate: 0.0010\n",
      "2017-09-06 23:23:51,274 Verification error= 5.4%, loss= 0.2810\n",
      "2017-09-06 23:24:29,351 Iter 77800, Minibatch Loss= 0.2089, Training Accuracy= 0.7839, Minibatch error= 4.5%\n",
      "2017-09-06 23:30:34,562 Iter 77850, Minibatch Loss= 0.3220, Training Accuracy= 0.7471, Minibatch error= 5.9%\n",
      "2017-09-06 23:36:32,979 Epoch 778, Average loss: 0.0154, learning rate: 0.0010\n",
      "2017-09-06 23:36:33,052 Verification error= 6.4%, loss= 0.4213\n",
      "2017-09-06 23:37:11,935 Iter 77900, Minibatch Loss= 0.7229, Training Accuracy= 0.7812, Minibatch error= 8.6%\n",
      "2017-09-06 23:43:17,896 Iter 77950, Minibatch Loss= 0.9449, Training Accuracy= 0.7570, Minibatch error= 8.5%\n",
      "2017-09-06 23:49:17,153 Epoch 779, Average loss: 0.0147, learning rate: 0.0010\n",
      "2017-09-06 23:49:17,226 Verification error= 5.6%, loss= 0.3080\n",
      "2017-09-06 23:49:55,628 Iter 78000, Minibatch Loss= 0.5695, Training Accuracy= 0.7464, Minibatch error= 7.6%\n",
      "2017-09-06 23:56:02,984 Iter 78050, Minibatch Loss= 0.7937, Training Accuracy= 0.7682, Minibatch error= 7.8%\n",
      "2017-09-07 00:02:02,973 Epoch 780, Average loss: 0.0147, learning rate: 0.0010\n",
      "2017-09-07 00:02:03,043 Verification error= 6.2%, loss= 0.4268\n",
      "2017-09-07 00:02:41,409 Iter 78100, Minibatch Loss= 0.2081, Training Accuracy= 0.7911, Minibatch error= 6.2%\n",
      "2017-09-07 00:08:49,152 Iter 78150, Minibatch Loss= 0.2042, Training Accuracy= 0.7786, Minibatch error= 5.9%\n",
      "2017-09-07 00:14:50,430 Epoch 781, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-07 00:14:50,499 Verification error= 5.9%, loss= 0.3690\n",
      "2017-09-07 00:15:28,964 Iter 78200, Minibatch Loss= 0.2204, Training Accuracy= 0.7529, Minibatch error= 6.1%\n",
      "2017-09-07 00:21:37,553 Iter 78250, Minibatch Loss= 0.7706, Training Accuracy= 0.7802, Minibatch error= 6.8%\n",
      "2017-09-07 00:27:38,577 Epoch 782, Average loss: 0.0153, learning rate: 0.0010\n",
      "2017-09-07 00:27:38,655 Verification error= 4.6%, loss= 0.2110\n",
      "2017-09-07 00:28:19,604 Iter 78300, Minibatch Loss= 0.1329, Training Accuracy= 0.7453, Minibatch error= 4.7%\n",
      "2017-09-07 00:34:28,502 Iter 78350, Minibatch Loss= 0.3192, Training Accuracy= 0.7044, Minibatch error= 8.8%\n",
      "2017-09-07 00:40:30,735 Epoch 783, Average loss: 0.0142, learning rate: 0.0010\n",
      "2017-09-07 00:40:30,805 Verification error= 5.7%, loss= 0.3586\n",
      "2017-09-07 00:41:09,478 Iter 78400, Minibatch Loss= 0.3115, Training Accuracy= 0.7542, Minibatch error= 6.0%\n",
      "2017-09-07 00:47:20,306 Iter 78450, Minibatch Loss= 0.2776, Training Accuracy= 0.7854, Minibatch error= 5.2%\n",
      "2017-09-07 00:53:21,896 Epoch 784, Average loss: 0.0152, learning rate: 0.0010\n",
      "2017-09-07 00:53:21,965 Verification error= 5.2%, loss= 0.2808\n",
      "2017-09-07 00:54:01,453 Iter 78500, Minibatch Loss= 0.2815, Training Accuracy= 0.7495, Minibatch error= 6.0%\n",
      "2017-09-07 01:00:11,729 Iter 78550, Minibatch Loss= 0.5849, Training Accuracy= 0.7349, Minibatch error= 9.0%\n",
      "2017-09-07 01:06:14,412 Epoch 785, Average loss: 0.0141, learning rate: 0.0010\n",
      "2017-09-07 01:06:14,482 Verification error= 6.2%, loss= 0.3856\n",
      "2017-09-07 01:06:53,132 Iter 78600, Minibatch Loss= 1.3546, Training Accuracy= 0.7435, Minibatch error= 10.1%\n",
      "2017-09-07 01:13:03,484 Iter 78650, Minibatch Loss= 1.0027, Training Accuracy= 0.7424, Minibatch error= 9.8%\n",
      "2017-09-07 01:19:06,417 Epoch 786, Average loss: 0.0149, learning rate: 0.0010\n",
      "2017-09-07 01:19:06,496 Verification error= 6.1%, loss= 0.3959\n",
      "2017-09-07 01:19:45,413 Iter 78700, Minibatch Loss= 0.8150, Training Accuracy= 0.7586, Minibatch error= 8.3%\n",
      "2017-09-07 01:25:57,297 Iter 78750, Minibatch Loss= 0.1717, Training Accuracy= 0.7979, Minibatch error= 6.2%\n",
      "2017-09-07 01:32:01,072 Epoch 787, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-07 01:32:01,144 Verification error= 6.3%, loss= 0.4028\n",
      "2017-09-07 01:32:40,261 Iter 78800, Minibatch Loss= 0.2682, Training Accuracy= 0.7906, Minibatch error= 6.0%\n",
      "2017-09-07 01:38:52,304 Iter 78850, Minibatch Loss= 0.2167, Training Accuracy= 0.7865, Minibatch error= 5.6%\n",
      "2017-09-07 01:44:57,715 Epoch 788, Average loss: 0.0152, learning rate: 0.0010\n",
      "2017-09-07 01:44:57,789 Verification error= 6.2%, loss= 0.4256\n",
      "2017-09-07 01:45:36,805 Iter 78900, Minibatch Loss= 0.8254, Training Accuracy= 0.7831, Minibatch error= 6.9%\n",
      "2017-09-07 01:51:49,618 Iter 78950, Minibatch Loss= 0.2487, Training Accuracy= 0.7258, Minibatch error= 5.6%\n",
      "2017-09-07 01:57:54,904 Epoch 789, Average loss: 0.0145, learning rate: 0.0010\n",
      "2017-09-07 01:57:54,983 Verification error= 5.7%, loss= 0.3475\n",
      "2017-09-07 01:58:33,850 Iter 79000, Minibatch Loss= 0.3357, Training Accuracy= 0.7148, Minibatch error= 7.4%\n",
      "2017-09-07 02:04:45,990 Iter 79050, Minibatch Loss= 0.2284, Training Accuracy= 0.7534, Minibatch error= 5.7%\n",
      "2017-09-07 02:10:52,402 Epoch 790, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 02:10:52,473 Verification error= 5.7%, loss= 0.3284\n",
      "2017-09-07 02:11:31,409 Iter 79100, Minibatch Loss= 0.2373, Training Accuracy= 0.7768, Minibatch error= 5.0%\n",
      "2017-09-07 02:17:45,301 Iter 79150, Minibatch Loss= 0.3307, Training Accuracy= 0.7490, Minibatch error= 5.8%\n",
      "2017-09-07 02:23:50,798 Epoch 791, Average loss: 0.0146, learning rate: 0.0010\n",
      "2017-09-07 02:23:50,869 Verification error= 6.7%, loss= 0.3903\n",
      "2017-09-07 02:24:29,847 Iter 79200, Minibatch Loss= 0.6170, Training Accuracy= 0.7776, Minibatch error= 9.1%\n",
      "2017-09-07 02:30:43,906 Iter 79250, Minibatch Loss= 1.0746, Training Accuracy= 0.7664, Minibatch error= 8.4%\n",
      "2017-09-07 02:36:50,258 Epoch 792, Average loss: 0.0152, learning rate: 0.0010\n",
      "2017-09-07 02:36:50,328 Verification error= 5.9%, loss= 0.3360\n",
      "2017-09-07 02:37:29,493 Iter 79300, Minibatch Loss= 0.6996, Training Accuracy= 0.7641, Minibatch error= 7.8%\n",
      "2017-09-07 02:43:43,808 Iter 79350, Minibatch Loss= 0.5027, Training Accuracy= 0.7466, Minibatch error= 6.7%\n",
      "2017-09-07 02:49:50,502 Epoch 793, Average loss: 0.0148, learning rate: 0.0010\n",
      "2017-09-07 02:49:50,574 Verification error= 5.0%, loss= 0.2780\n",
      "2017-09-07 02:50:32,040 Iter 79400, Minibatch Loss= 0.1623, Training Accuracy= 0.7844, Minibatch error= 5.4%\n",
      "2017-09-07 02:56:46,695 Iter 79450, Minibatch Loss= 0.1859, Training Accuracy= 0.7951, Minibatch error= 4.3%\n",
      "2017-09-07 03:02:54,233 Epoch 794, Average loss: 0.0144, learning rate: 0.0010\n",
      "2017-09-07 03:02:54,312 Verification error= 5.4%, loss= 0.2949\n",
      "2017-09-07 03:03:33,447 Iter 79500, Minibatch Loss= 0.1814, Training Accuracy= 0.7724, Minibatch error= 5.7%\n",
      "2017-09-07 03:09:48,305 Iter 79550, Minibatch Loss= 0.9398, Training Accuracy= 0.7755, Minibatch error= 8.4%\n",
      "2017-09-07 03:15:56,453 Epoch 795, Average loss: 0.0143, learning rate: 0.0010\n",
      "2017-09-07 03:15:56,523 Verification error= 6.3%, loss= 0.3885\n",
      "2017-09-07 03:16:35,718 Iter 79600, Minibatch Loss= 0.2495, Training Accuracy= 0.7094, Minibatch error= 6.2%\n",
      "2017-09-07 03:22:51,373 Iter 79650, Minibatch Loss= 0.2900, Training Accuracy= 0.7240, Minibatch error= 8.4%\n",
      "2017-09-07 03:29:00,736 Epoch 796, Average loss: 0.0163, learning rate: 0.0010\n",
      "2017-09-07 03:29:00,808 Verification error= 6.1%, loss= 0.3356\n",
      "2017-09-07 03:29:40,132 Iter 79700, Minibatch Loss= 0.2329, Training Accuracy= 0.7578, Minibatch error= 5.4%\n",
      "2017-09-07 03:35:55,631 Iter 79750, Minibatch Loss= 0.2458, Training Accuracy= 0.7531, Minibatch error= 6.0%\n",
      "2017-09-07 03:42:04,531 Epoch 797, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 03:42:04,601 Verification error= 5.7%, loss= 0.3133\n",
      "2017-09-07 03:42:44,038 Iter 79800, Minibatch Loss= 0.3133, Training Accuracy= 0.7667, Minibatch error= 5.3%\n",
      "2017-09-07 03:49:01,216 Iter 79850, Minibatch Loss= 0.8120, Training Accuracy= 0.7648, Minibatch error= 10.3%\n",
      "2017-09-07 03:55:11,316 Epoch 798, Average loss: 0.0139, learning rate: 0.0010\n",
      "2017-09-07 03:55:11,394 Verification error= 5.8%, loss= 0.3740\n",
      "2017-09-07 03:55:50,868 Iter 79900, Minibatch Loss= 1.3232, Training Accuracy= 0.7312, Minibatch error= 9.3%\n",
      "2017-09-07 04:02:07,950 Iter 79950, Minibatch Loss= 1.1313, Training Accuracy= 0.7388, Minibatch error= 9.9%\n",
      "2017-09-07 04:08:17,748 Epoch 799, Average loss: 0.0136, learning rate: 0.0010\n",
      "2017-09-07 04:08:17,818 Verification error= 6.5%, loss= 0.4151\n",
      "2017-09-07 04:08:57,525 Iter 80000, Minibatch Loss= 0.8939, Training Accuracy= 0.7490, Minibatch error= 8.6%\n",
      "2017-09-07 04:15:16,201 Iter 80050, Minibatch Loss= 0.2121, Training Accuracy= 0.7555, Minibatch error= 6.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 04:21:26,925 Epoch 800, Average loss: 0.0141, learning rate: 0.0010\n",
      "2017-09-07 04:21:26,996 Verification error= 6.0%, loss= 0.3860\n",
      "2017-09-07 04:22:06,918 Iter 80100, Minibatch Loss= 0.2328, Training Accuracy= 0.7635, Minibatch error= 5.3%\n",
      "2017-09-07 04:28:25,488 Iter 80150, Minibatch Loss= 0.2543, Training Accuracy= 0.7589, Minibatch error= 5.5%\n",
      "2017-09-07 04:34:36,763 Epoch 801, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 04:34:36,837 Verification error= 6.3%, loss= 0.4345\n",
      "2017-09-07 04:35:16,179 Iter 80200, Minibatch Loss= 0.9871, Training Accuracy= 0.7797, Minibatch error= 6.8%\n",
      "2017-09-07 04:41:35,004 Iter 80250, Minibatch Loss= 0.1893, Training Accuracy= 0.7292, Minibatch error= 5.7%\n",
      "2017-09-07 04:47:46,453 Epoch 802, Average loss: 0.0143, learning rate: 0.0010\n",
      "2017-09-07 04:47:46,523 Verification error= 6.3%, loss= 0.4023\n",
      "2017-09-07 04:48:26,212 Iter 80300, Minibatch Loss= 0.3169, Training Accuracy= 0.6958, Minibatch error= 8.3%\n",
      "2017-09-07 04:54:45,843 Iter 80350, Minibatch Loss= 0.3045, Training Accuracy= 0.7698, Minibatch error= 7.0%\n",
      "2017-09-07 05:00:57,964 Epoch 803, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-07 05:00:58,034 Verification error= 6.2%, loss= 0.3689\n",
      "2017-09-07 05:01:37,480 Iter 80400, Minibatch Loss= 0.2093, Training Accuracy= 0.7865, Minibatch error= 5.5%\n",
      "2017-09-07 05:07:57,292 Iter 80450, Minibatch Loss= 0.4923, Training Accuracy= 0.7234, Minibatch error= 7.0%\n",
      "2017-09-07 05:14:09,543 Epoch 804, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 05:14:09,614 Verification error= 6.8%, loss= 0.4904\n",
      "2017-09-07 05:14:51,805 Iter 80500, Minibatch Loss= 0.8826, Training Accuracy= 0.7615, Minibatch error= 9.8%\n",
      "2017-09-07 05:21:13,635 Iter 80550, Minibatch Loss= 1.4045, Training Accuracy= 0.7047, Minibatch error= 10.2%\n",
      "2017-09-07 05:27:26,552 Epoch 805, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 05:27:26,621 Verification error= 5.7%, loss= 0.4218\n",
      "2017-09-07 05:28:06,094 Iter 80600, Minibatch Loss= 0.8497, Training Accuracy= 0.7716, Minibatch error= 7.6%\n",
      "2017-09-07 05:34:27,531 Iter 80650, Minibatch Loss= 0.6755, Training Accuracy= 0.7802, Minibatch error= 7.8%\n",
      "2017-09-07 05:40:40,716 Epoch 806, Average loss: 0.0138, learning rate: 0.0010\n",
      "2017-09-07 05:40:40,786 Verification error= 6.1%, loss= 0.4088\n",
      "2017-09-07 05:41:20,854 Iter 80700, Minibatch Loss= 0.2249, Training Accuracy= 0.7898, Minibatch error= 6.1%\n",
      "2017-09-07 05:47:42,440 Iter 80750, Minibatch Loss= 0.2591, Training Accuracy= 0.7596, Minibatch error= 5.4%\n",
      "2017-09-07 05:53:57,302 Epoch 807, Average loss: 0.0139, learning rate: 0.0010\n",
      "2017-09-07 05:53:57,372 Verification error= 6.3%, loss= 0.4474\n",
      "2017-09-07 05:54:37,082 Iter 80800, Minibatch Loss= 0.2724, Training Accuracy= 0.7727, Minibatch error= 6.1%\n",
      "2017-09-07 06:00:59,358 Iter 80850, Minibatch Loss= 1.0178, Training Accuracy= 0.7771, Minibatch error= 7.2%\n",
      "2017-09-07 06:07:14,043 Epoch 808, Average loss: 0.0135, learning rate: 0.0010\n",
      "2017-09-07 06:07:14,115 Verification error= 6.0%, loss= 0.3570\n",
      "2017-09-07 06:07:54,554 Iter 80900, Minibatch Loss= 0.2553, Training Accuracy= 0.7289, Minibatch error= 6.4%\n",
      "2017-09-07 06:14:16,549 Iter 80950, Minibatch Loss= 0.3500, Training Accuracy= 0.7091, Minibatch error= 8.7%\n",
      "2017-09-07 06:20:31,666 Epoch 809, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 06:20:31,736 Verification error= 6.2%, loss= 0.3761\n",
      "2017-09-07 06:21:11,553 Iter 81000, Minibatch Loss= 0.2712, Training Accuracy= 0.7471, Minibatch error= 6.1%\n",
      "2017-09-07 06:27:34,791 Iter 81050, Minibatch Loss= 0.2078, Training Accuracy= 0.7815, Minibatch error= 4.7%\n",
      "2017-09-07 06:33:50,065 Epoch 810, Average loss: 0.0138, learning rate: 0.0010\n",
      "2017-09-07 06:33:50,136 Verification error= 6.5%, loss= 0.4017\n",
      "2017-09-07 06:34:30,064 Iter 81100, Minibatch Loss= 0.3855, Training Accuracy= 0.7682, Minibatch error= 5.5%\n",
      "2017-09-07 06:40:52,775 Iter 81150, Minibatch Loss= 0.7612, Training Accuracy= 0.7542, Minibatch error= 8.6%\n",
      "2017-09-07 06:47:08,425 Epoch 811, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-07 06:47:08,496 Verification error= 6.5%, loss= 0.3843\n",
      "2017-09-07 06:47:48,702 Iter 81200, Minibatch Loss= 1.4703, Training Accuracy= 0.6930, Minibatch error= 9.9%\n",
      "2017-09-07 06:54:12,373 Iter 81250, Minibatch Loss= 0.6023, Training Accuracy= 0.7529, Minibatch error= 8.3%\n",
      "2017-09-07 07:00:28,519 Epoch 812, Average loss: 0.0131, learning rate: 0.0010\n",
      "2017-09-07 07:00:28,589 Verification error= 6.6%, loss= 0.4479\n",
      "2017-09-07 07:01:08,775 Iter 81300, Minibatch Loss= 0.8999, Training Accuracy= 0.7516, Minibatch error= 8.8%\n",
      "2017-09-07 07:07:33,009 Iter 81350, Minibatch Loss= 0.1521, Training Accuracy= 0.7745, Minibatch error= 5.9%\n",
      "2017-09-07 07:13:50,250 Epoch 813, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 07:13:50,321 Verification error= 6.1%, loss= 0.3686\n",
      "2017-09-07 07:14:30,523 Iter 81400, Minibatch Loss= 0.1715, Training Accuracy= 0.7878, Minibatch error= 3.8%\n",
      "2017-09-07 07:20:56,076 Iter 81450, Minibatch Loss= 0.3779, Training Accuracy= 0.7336, Minibatch error= 6.4%\n",
      "2017-09-07 07:27:13,681 Epoch 814, Average loss: 0.0136, learning rate: 0.0010\n",
      "2017-09-07 07:27:13,754 Verification error= 6.5%, loss= 0.4413\n",
      "2017-09-07 07:27:54,072 Iter 81500, Minibatch Loss= 0.9562, Training Accuracy= 0.7586, Minibatch error= 7.3%\n",
      "2017-09-07 07:34:19,334 Iter 81550, Minibatch Loss= 0.2108, Training Accuracy= 0.7135, Minibatch error= 5.7%\n",
      "2017-09-07 07:40:37,870 Epoch 815, Average loss: 0.0138, learning rate: 0.0010\n",
      "2017-09-07 07:40:37,941 Verification error= 6.2%, loss= 0.3573\n",
      "2017-09-07 07:41:20,990 Iter 81600, Minibatch Loss= 0.3243, Training Accuracy= 0.7242, Minibatch error= 8.2%\n",
      "2017-09-07 07:47:46,875 Iter 81650, Minibatch Loss= 0.2816, Training Accuracy= 0.7323, Minibatch error= 6.1%\n",
      "2017-09-07 07:54:05,525 Epoch 816, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 07:54:05,595 Verification error= 5.5%, loss= 0.3470\n",
      "2017-09-07 07:54:46,034 Iter 81700, Minibatch Loss= 0.2044, Training Accuracy= 0.7604, Minibatch error= 4.8%\n",
      "2017-09-07 08:01:12,800 Iter 81750, Minibatch Loss= 0.3951, Training Accuracy= 0.7182, Minibatch error= 5.9%\n",
      "2017-09-07 08:07:31,788 Epoch 817, Average loss: 0.0136, learning rate: 0.0010\n",
      "2017-09-07 08:07:31,858 Verification error= 5.4%, loss= 0.2681\n",
      "2017-09-07 08:08:12,930 Iter 81800, Minibatch Loss= 0.5229, Training Accuracy= 0.7258, Minibatch error= 7.7%\n",
      "2017-09-07 08:14:40,271 Iter 81850, Minibatch Loss= 1.1499, Training Accuracy= 0.6802, Minibatch error= 10.2%\n",
      "2017-09-07 08:20:59,162 Epoch 818, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 08:20:59,232 Verification error= 6.5%, loss= 0.4316\n",
      "2017-09-07 08:21:39,663 Iter 81900, Minibatch Loss= 0.9030, Training Accuracy= 0.7451, Minibatch error= 9.5%\n",
      "2017-09-07 08:28:06,374 Iter 81950, Minibatch Loss= 0.6815, Training Accuracy= 0.7565, Minibatch error= 8.1%\n",
      "2017-09-07 08:34:26,309 Epoch 819, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 08:34:26,380 Verification error= 5.7%, loss= 0.3079\n",
      "2017-09-07 08:35:06,700 Iter 82000, Minibatch Loss= 0.1764, Training Accuracy= 0.7826, Minibatch error= 5.8%\n",
      "2017-09-07 08:41:34,356 Iter 82050, Minibatch Loss= 0.1814, Training Accuracy= 0.7471, Minibatch error= 4.3%\n",
      "2017-09-07 08:47:54,291 Epoch 820, Average loss: 0.0135, learning rate: 0.0010\n",
      "2017-09-07 08:47:54,361 Verification error= 6.4%, loss= 0.3891\n",
      "2017-09-07 08:48:34,869 Iter 82100, Minibatch Loss= 0.3616, Training Accuracy= 0.7182, Minibatch error= 6.3%\n",
      "2017-09-07 08:55:02,719 Iter 82150, Minibatch Loss= 0.6389, Training Accuracy= 0.7906, Minibatch error= 6.1%\n",
      "2017-09-07 09:01:24,128 Epoch 821, Average loss: 0.0144, learning rate: 0.0010\n",
      "2017-09-07 09:01:24,200 Verification error= 5.3%, loss= 0.2833\n",
      "2017-09-07 09:02:04,692 Iter 82200, Minibatch Loss= 0.2186, Training Accuracy= 0.6859, Minibatch error= 5.8%\n",
      "2017-09-07 09:08:34,426 Iter 82250, Minibatch Loss= 0.2669, Training Accuracy= 0.7177, Minibatch error= 8.2%\n",
      "2017-09-07 09:14:55,390 Epoch 822, Average loss: 0.0138, learning rate: 0.0010\n",
      "2017-09-07 09:14:55,460 Verification error= 5.8%, loss= 0.3433\n",
      "2017-09-07 09:15:36,166 Iter 82300, Minibatch Loss= 0.2316, Training Accuracy= 0.7688, Minibatch error= 6.2%\n",
      "2017-09-07 09:22:04,906 Iter 82350, Minibatch Loss= 0.2205, Training Accuracy= 0.7706, Minibatch error= 4.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 09:28:26,100 Epoch 823, Average loss: 0.0129, learning rate: 0.0010\n",
      "2017-09-07 09:28:26,170 Verification error= 6.0%, loss= 0.3704\n",
      "2017-09-07 09:29:06,632 Iter 82400, Minibatch Loss= 0.3376, Training Accuracy= 0.7510, Minibatch error= 6.0%\n",
      "2017-09-07 09:35:36,289 Iter 82450, Minibatch Loss= 0.8365, Training Accuracy= 0.7497, Minibatch error= 8.8%\n",
      "2017-09-07 09:41:58,195 Epoch 824, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 09:41:58,269 Verification error= 6.0%, loss= 0.3459\n",
      "2017-09-07 09:42:39,010 Iter 82500, Minibatch Loss= 1.3724, Training Accuracy= 0.6943, Minibatch error= 10.1%\n",
      "2017-09-07 09:49:10,072 Iter 82550, Minibatch Loss= 0.8027, Training Accuracy= 0.7453, Minibatch error= 8.3%\n",
      "2017-09-07 09:55:33,214 Epoch 825, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 09:55:33,284 Verification error= 6.4%, loss= 0.3789\n",
      "2017-09-07 09:56:14,000 Iter 82600, Minibatch Loss= 0.6829, Training Accuracy= 0.7440, Minibatch error= 8.2%\n",
      "2017-09-07 10:02:45,864 Iter 82650, Minibatch Loss= 0.2238, Training Accuracy= 0.7635, Minibatch error= 6.6%\n",
      "2017-09-07 10:09:09,472 Epoch 826, Average loss: 0.0125, learning rate: 0.0010\n",
      "2017-09-07 10:09:09,542 Verification error= 6.3%, loss= 0.4323\n",
      "2017-09-07 10:09:50,716 Iter 82700, Minibatch Loss= 0.2511, Training Accuracy= 0.7458, Minibatch error= 5.4%\n",
      "2017-09-07 10:16:21,368 Iter 82750, Minibatch Loss= 0.4483, Training Accuracy= 0.6859, Minibatch error= 7.2%\n",
      "2017-09-07 10:22:45,205 Epoch 827, Average loss: 0.0140, learning rate: 0.0010\n",
      "2017-09-07 10:22:45,275 Verification error= 6.1%, loss= 0.3280\n",
      "2017-09-07 10:23:28,795 Iter 82800, Minibatch Loss= 0.6339, Training Accuracy= 0.7706, Minibatch error= 7.2%\n",
      "2017-09-07 10:30:01,523 Iter 82850, Minibatch Loss= 0.2591, Training Accuracy= 0.7010, Minibatch error= 6.1%\n",
      "2017-09-07 10:36:26,091 Epoch 828, Average loss: 0.0145, learning rate: 0.0010\n",
      "2017-09-07 10:36:26,163 Verification error= 6.0%, loss= 0.4020\n",
      "2017-09-07 10:37:07,184 Iter 82900, Minibatch Loss= 0.3917, Training Accuracy= 0.6531, Minibatch error= 8.6%\n",
      "2017-09-07 10:43:39,423 Iter 82950, Minibatch Loss= 0.2613, Training Accuracy= 0.7122, Minibatch error= 5.8%\n",
      "2017-09-07 10:50:03,272 Epoch 829, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-07 10:50:03,342 Verification error= 5.7%, loss= 0.3402\n",
      "2017-09-07 10:50:44,367 Iter 83000, Minibatch Loss= 0.2294, Training Accuracy= 0.7641, Minibatch error= 5.1%\n",
      "2017-09-07 10:57:17,388 Iter 83050, Minibatch Loss= 0.3295, Training Accuracy= 0.7279, Minibatch error= 5.4%\n",
      "2017-09-07 11:03:42,541 Epoch 830, Average loss: 0.0144, learning rate: 0.0010\n",
      "2017-09-07 11:03:42,610 Verification error= 5.6%, loss= 0.3091\n",
      "2017-09-07 11:04:23,747 Iter 83100, Minibatch Loss= 0.7916, Training Accuracy= 0.7367, Minibatch error= 8.2%\n",
      "2017-09-07 11:10:57,295 Iter 83150, Minibatch Loss= 1.3615, Training Accuracy= 0.6440, Minibatch error= 9.3%\n",
      "2017-09-07 11:17:23,291 Epoch 831, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-07 11:17:23,363 Verification error= 6.2%, loss= 0.3633\n",
      "2017-09-07 11:18:04,218 Iter 83200, Minibatch Loss= 0.5631, Training Accuracy= 0.7687, Minibatch error= 7.8%\n",
      "2017-09-07 11:24:37,993 Iter 83250, Minibatch Loss= 0.5279, Training Accuracy= 0.7930, Minibatch error= 8.0%\n",
      "2017-09-07 11:31:04,023 Epoch 832, Average loss: 0.0135, learning rate: 0.0010\n",
      "2017-09-07 11:31:04,093 Verification error= 6.2%, loss= 0.3746\n",
      "2017-09-07 11:31:45,203 Iter 83300, Minibatch Loss= 0.1857, Training Accuracy= 0.7794, Minibatch error= 6.8%\n",
      "2017-09-07 11:38:18,996 Iter 83350, Minibatch Loss= 0.2709, Training Accuracy= 0.7701, Minibatch error= 4.8%\n",
      "2017-09-07 11:44:45,182 Epoch 833, Average loss: 0.0131, learning rate: 0.0010\n",
      "2017-09-07 11:44:45,252 Verification error= 6.5%, loss= 0.4090\n",
      "2017-09-07 11:45:26,687 Iter 83400, Minibatch Loss= 0.3533, Training Accuracy= 0.7583, Minibatch error= 6.4%\n",
      "2017-09-07 11:52:01,063 Iter 83450, Minibatch Loss= 0.8768, Training Accuracy= 0.7693, Minibatch error= 6.9%\n",
      "2017-09-07 11:58:27,545 Epoch 834, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 11:58:27,615 Verification error= 6.2%, loss= 0.4347\n",
      "2017-09-07 11:59:08,755 Iter 83500, Minibatch Loss= 0.2522, Training Accuracy= 0.6503, Minibatch error= 5.9%\n",
      "2017-09-07 12:05:53,219 Iter 83550, Minibatch Loss= 0.2803, Training Accuracy= 0.7190, Minibatch error= 7.9%\n",
      "2017-09-07 12:12:27,292 Epoch 835, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 12:12:27,372 Verification error= 5.6%, loss= 0.3103\n",
      "2017-09-07 12:13:09,809 Iter 83600, Minibatch Loss= 0.1978, Training Accuracy= 0.7474, Minibatch error= 5.0%\n",
      "2017-09-07 12:19:52,280 Iter 83650, Minibatch Loss= 0.2664, Training Accuracy= 0.7453, Minibatch error= 5.0%\n",
      "2017-09-07 12:26:27,012 Epoch 836, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-07 12:26:27,094 Verification error= 5.6%, loss= 0.3521\n",
      "2017-09-07 12:27:09,257 Iter 83700, Minibatch Loss= 0.3658, Training Accuracy= 0.7005, Minibatch error= 5.9%\n",
      "2017-09-07 12:33:52,707 Iter 83750, Minibatch Loss= 0.7054, Training Accuracy= 0.7549, Minibatch error= 7.7%\n",
      "2017-09-07 12:40:28,117 Epoch 837, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 12:40:28,197 Verification error= 7.1%, loss= 0.4948\n",
      "2017-09-07 12:41:10,511 Iter 83800, Minibatch Loss= 1.6026, Training Accuracy= 0.7070, Minibatch error= 10.4%\n",
      "2017-09-07 12:47:53,607 Iter 83850, Minibatch Loss= 0.6763, Training Accuracy= 0.7000, Minibatch error= 8.4%\n",
      "2017-09-07 12:54:29,099 Epoch 838, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 12:54:29,177 Verification error= 6.0%, loss= 0.4147\n",
      "2017-09-07 12:55:14,049 Iter 83900, Minibatch Loss= 0.9302, Training Accuracy= 0.7411, Minibatch error= 8.6%\n",
      "2017-09-07 13:01:58,534 Iter 83950, Minibatch Loss= 0.2622, Training Accuracy= 0.7573, Minibatch error= 6.3%\n",
      "2017-09-07 13:08:35,269 Epoch 839, Average loss: 0.0131, learning rate: 0.0010\n",
      "2017-09-07 13:08:35,346 Verification error= 5.6%, loss= 0.3071\n",
      "2017-09-07 13:09:17,611 Iter 84000, Minibatch Loss= 0.2139, Training Accuracy= 0.7482, Minibatch error= 4.7%\n",
      "2017-09-07 13:16:03,587 Iter 84050, Minibatch Loss= 0.4129, Training Accuracy= 0.7341, Minibatch error= 6.1%\n",
      "2017-09-07 13:22:41,951 Epoch 840, Average loss: 0.0124, learning rate: 0.0010\n",
      "2017-09-07 13:22:42,028 Verification error= 7.6%, loss= 0.6285\n",
      "2017-09-07 13:23:24,718 Iter 84100, Minibatch Loss= 1.1296, Training Accuracy= 0.7448, Minibatch error= 8.2%\n",
      "2017-09-07 13:30:10,208 Iter 84150, Minibatch Loss= 0.2170, Training Accuracy= 0.6654, Minibatch error= 5.8%\n",
      "2017-09-07 13:36:49,224 Epoch 841, Average loss: 0.0124, learning rate: 0.0010\n",
      "2017-09-07 13:36:49,296 Verification error= 7.0%, loss= 0.5678\n",
      "2017-09-07 13:37:31,939 Iter 84200, Minibatch Loss= 0.3560, Training Accuracy= 0.7063, Minibatch error= 7.5%\n",
      "2017-09-07 13:44:17,798 Iter 84250, Minibatch Loss= 0.4522, Training Accuracy= 0.6932, Minibatch error= 6.7%\n",
      "2017-09-07 13:50:48,343 Epoch 842, Average loss: 0.0136, learning rate: 0.0010\n",
      "2017-09-07 13:50:48,420 Verification error= 6.5%, loss= 0.4884\n",
      "2017-09-07 13:51:30,272 Iter 84300, Minibatch Loss= 0.2481, Training Accuracy= 0.6849, Minibatch error= 5.2%\n",
      "2017-09-07 13:58:09,158 Iter 84350, Minibatch Loss= 0.3312, Training Accuracy= 0.7182, Minibatch error= 5.7%\n",
      "2017-09-07 14:04:39,829 Epoch 843, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 14:04:39,906 Verification error= 6.1%, loss= 0.4665\n",
      "2017-09-07 14:05:22,490 Iter 84400, Minibatch Loss= 0.7686, Training Accuracy= 0.7542, Minibatch error= 8.9%\n",
      "2017-09-07 14:12:01,929 Iter 84450, Minibatch Loss= 1.2987, Training Accuracy= 0.7031, Minibatch error= 9.0%\n",
      "2017-09-07 14:18:33,698 Epoch 844, Average loss: 0.0123, learning rate: 0.0010\n",
      "2017-09-07 14:18:33,779 Verification error= 7.0%, loss= 0.5011\n",
      "2017-09-07 14:19:15,745 Iter 84500, Minibatch Loss= 0.9390, Training Accuracy= 0.7086, Minibatch error= 9.6%\n",
      "2017-09-07 14:25:55,911 Iter 84550, Minibatch Loss= 0.8689, Training Accuracy= 0.7495, Minibatch error= 7.9%\n",
      "2017-09-07 14:32:28,429 Epoch 845, Average loss: 0.0125, learning rate: 0.0010\n",
      "2017-09-07 14:32:28,500 Verification error= 6.4%, loss= 0.4258\n",
      "2017-09-07 14:33:11,159 Iter 84600, Minibatch Loss= 0.2355, Training Accuracy= 0.7417, Minibatch error= 6.5%\n",
      "2017-09-07 14:39:51,493 Iter 84650, Minibatch Loss= 0.2465, Training Accuracy= 0.7701, Minibatch error= 4.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 14:46:24,890 Epoch 846, Average loss: 0.0128, learning rate: 0.0010\n",
      "2017-09-07 14:46:24,968 Verification error= 5.7%, loss= 0.3889\n",
      "2017-09-07 14:47:07,134 Iter 84700, Minibatch Loss= 0.2641, Training Accuracy= 0.7664, Minibatch error= 5.9%\n",
      "2017-09-07 14:53:48,766 Iter 84750, Minibatch Loss= 0.9180, Training Accuracy= 0.7951, Minibatch error= 7.0%\n",
      "2017-09-07 15:00:21,394 Epoch 847, Average loss: 0.0133, learning rate: 0.0010\n",
      "2017-09-07 15:00:21,464 Verification error= 5.6%, loss= 0.3064\n",
      "2017-09-07 15:01:03,541 Iter 84800, Minibatch Loss= 0.1880, Training Accuracy= 0.6883, Minibatch error= 5.3%\n",
      "2017-09-07 15:07:44,408 Iter 84850, Minibatch Loss= 0.3771, Training Accuracy= 0.7065, Minibatch error= 8.9%\n",
      "2017-09-07 15:14:17,298 Epoch 848, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-07 15:14:17,368 Verification error= 6.1%, loss= 0.4063\n",
      "2017-09-07 15:14:59,536 Iter 84900, Minibatch Loss= 0.2584, Training Accuracy= 0.7336, Minibatch error= 5.8%\n",
      "2017-09-07 15:21:41,099 Iter 84950, Minibatch Loss= 0.2739, Training Accuracy= 0.7716, Minibatch error= 5.5%\n",
      "2017-09-07 15:28:16,452 Epoch 849, Average loss: 0.0151, learning rate: 0.0010\n",
      "2017-09-07 15:28:16,530 Verification error= 6.2%, loss= 0.4020\n",
      "2017-09-07 15:29:01,244 Iter 85000, Minibatch Loss= 0.3283, Training Accuracy= 0.7281, Minibatch error= 5.8%\n",
      "2017-09-07 15:35:44,411 Iter 85050, Minibatch Loss= 0.4425, Training Accuracy= 0.7708, Minibatch error= 8.2%\n",
      "2017-09-07 15:42:20,188 Epoch 850, Average loss: 0.0123, learning rate: 0.0010\n",
      "2017-09-07 15:42:20,267 Verification error= 6.3%, loss= 0.4364\n",
      "2017-09-07 15:43:02,622 Iter 85100, Minibatch Loss= 1.2831, Training Accuracy= 0.7161, Minibatch error= 8.6%\n",
      "2017-09-07 15:49:44,779 Iter 85150, Minibatch Loss= 0.6021, Training Accuracy= 0.7724, Minibatch error= 7.7%\n",
      "2017-09-07 15:56:20,028 Epoch 851, Average loss: 0.0121, learning rate: 0.0010\n",
      "2017-09-07 15:56:20,107 Verification error= 5.9%, loss= 0.3917\n",
      "2017-09-07 15:57:02,085 Iter 85200, Minibatch Loss= 0.8633, Training Accuracy= 0.7112, Minibatch error= 8.4%\n",
      "2017-09-07 16:03:45,848 Iter 85250, Minibatch Loss= 0.2418, Training Accuracy= 0.7622, Minibatch error= 7.2%\n",
      "2017-09-07 16:10:21,551 Epoch 852, Average loss: 0.0135, learning rate: 0.0010\n",
      "2017-09-07 16:10:21,621 Verification error= 7.0%, loss= 0.5328\n",
      "2017-09-07 16:11:03,621 Iter 85300, Minibatch Loss= 0.1972, Training Accuracy= 0.7534, Minibatch error= 5.3%\n",
      "2017-09-07 16:17:46,714 Iter 85350, Minibatch Loss= 0.3475, Training Accuracy= 0.7177, Minibatch error= 6.5%\n",
      "2017-09-07 16:24:22,597 Epoch 853, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 16:24:22,668 Verification error= 5.5%, loss= 0.3627\n",
      "2017-09-07 16:25:04,752 Iter 85400, Minibatch Loss= 0.7490, Training Accuracy= 0.7875, Minibatch error= 5.9%\n",
      "2017-09-07 16:31:49,868 Iter 85450, Minibatch Loss= 0.2856, Training Accuracy= 0.6870, Minibatch error= 6.1%\n",
      "2017-09-07 16:38:25,345 Epoch 854, Average loss: 0.0129, learning rate: 0.0010\n",
      "2017-09-07 16:38:25,424 Verification error= 6.3%, loss= 0.4294\n",
      "2017-09-07 16:39:07,419 Iter 85500, Minibatch Loss= 0.4167, Training Accuracy= 0.7083, Minibatch error= 7.6%\n",
      "2017-09-07 16:45:52,697 Iter 85550, Minibatch Loss= 0.2463, Training Accuracy= 0.7547, Minibatch error= 5.8%\n",
      "2017-09-07 16:52:29,112 Epoch 855, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 16:52:29,181 Verification error= 7.0%, loss= 0.4244\n",
      "2017-09-07 16:53:11,556 Iter 85600, Minibatch Loss= 0.2212, Training Accuracy= 0.7273, Minibatch error= 6.3%\n",
      "2017-09-07 16:59:56,058 Iter 85650, Minibatch Loss= 0.3888, Training Accuracy= 0.7297, Minibatch error= 5.5%\n",
      "2017-09-07 17:06:32,718 Epoch 856, Average loss: 0.0122, learning rate: 0.0010\n",
      "2017-09-07 17:06:32,792 Verification error= 6.4%, loss= 0.4314\n",
      "2017-09-07 17:07:15,156 Iter 85700, Minibatch Loss= 0.8968, Training Accuracy= 0.6914, Minibatch error= 8.7%\n",
      "2017-09-07 17:14:00,392 Iter 85750, Minibatch Loss= 1.6235, Training Accuracy= 0.6815, Minibatch error= 10.2%\n",
      "2017-09-07 17:20:37,532 Epoch 857, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 17:20:37,602 Verification error= 5.6%, loss= 0.3247\n",
      "2017-09-07 17:21:19,823 Iter 85800, Minibatch Loss= 0.6491, Training Accuracy= 0.7794, Minibatch error= 7.7%\n",
      "2017-09-07 17:28:06,029 Iter 85850, Minibatch Loss= 0.7874, Training Accuracy= 0.7615, Minibatch error= 8.9%\n",
      "2017-09-07 17:34:43,736 Epoch 858, Average loss: 0.0129, learning rate: 0.0010\n",
      "2017-09-07 17:34:43,807 Verification error= 5.5%, loss= 0.3338\n",
      "2017-09-07 17:35:26,364 Iter 85900, Minibatch Loss= 0.2113, Training Accuracy= 0.7872, Minibatch error= 6.0%\n",
      "2017-09-07 17:42:13,488 Iter 85950, Minibatch Loss= 0.1912, Training Accuracy= 0.7661, Minibatch error= 4.7%\n",
      "2017-09-07 17:48:51,913 Epoch 859, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 17:48:51,983 Verification error= 6.2%, loss= 0.3876\n",
      "2017-09-07 17:49:34,635 Iter 86000, Minibatch Loss= 0.2947, Training Accuracy= 0.7753, Minibatch error= 6.2%\n",
      "2017-09-07 17:56:21,522 Iter 86050, Minibatch Loss= 0.6172, Training Accuracy= 0.7878, Minibatch error= 6.1%\n",
      "2017-09-07 18:03:00,058 Epoch 860, Average loss: 0.0137, learning rate: 0.0010\n",
      "2017-09-07 18:03:00,129 Verification error= 6.4%, loss= 0.4246\n",
      "2017-09-07 18:03:42,853 Iter 86100, Minibatch Loss= 0.2610, Training Accuracy= 0.7003, Minibatch error= 6.4%\n",
      "2017-09-07 18:10:30,989 Iter 86150, Minibatch Loss= 0.2853, Training Accuracy= 0.7250, Minibatch error= 8.2%\n",
      "2017-09-07 18:17:09,822 Epoch 861, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 18:17:09,892 Verification error= 5.9%, loss= 0.3386\n",
      "2017-09-07 18:17:55,447 Iter 86200, Minibatch Loss= 0.2323, Training Accuracy= 0.7664, Minibatch error= 6.1%\n",
      "2017-09-07 18:24:43,174 Iter 86250, Minibatch Loss= 0.2438, Training Accuracy= 0.7495, Minibatch error= 4.8%\n",
      "2017-09-07 18:31:23,919 Epoch 862, Average loss: 0.0121, learning rate: 0.0010\n",
      "2017-09-07 18:31:23,990 Verification error= 5.7%, loss= 0.3566\n",
      "2017-09-07 18:32:06,896 Iter 86300, Minibatch Loss= 0.4281, Training Accuracy= 0.7628, Minibatch error= 5.8%\n",
      "2017-09-07 18:38:55,189 Iter 86350, Minibatch Loss= 0.5785, Training Accuracy= 0.7682, Minibatch error= 8.5%\n",
      "2017-09-07 18:45:35,507 Epoch 863, Average loss: 0.0118, learning rate: 0.0010\n",
      "2017-09-07 18:45:35,576 Verification error= 6.0%, loss= 0.3694\n",
      "2017-09-07 18:46:18,541 Iter 86400, Minibatch Loss= 1.2498, Training Accuracy= 0.6016, Minibatch error= 9.3%\n",
      "2017-09-07 18:53:07,292 Iter 86450, Minibatch Loss= 0.5379, Training Accuracy= 0.7297, Minibatch error= 8.1%\n",
      "2017-09-07 18:59:48,005 Epoch 864, Average loss: 0.0115, learning rate: 0.0010\n",
      "2017-09-07 18:59:48,076 Verification error= 6.0%, loss= 0.3562\n",
      "2017-09-07 19:00:30,912 Iter 86500, Minibatch Loss= 0.7939, Training Accuracy= 0.7635, Minibatch error= 8.2%\n",
      "2017-09-07 19:07:19,863 Iter 86550, Minibatch Loss= 0.2064, Training Accuracy= 0.7578, Minibatch error= 6.3%\n",
      "2017-09-07 19:14:01,560 Epoch 865, Average loss: 0.0121, learning rate: 0.0010\n",
      "2017-09-07 19:14:01,631 Verification error= 5.8%, loss= 0.3487\n",
      "2017-09-07 19:14:44,770 Iter 86600, Minibatch Loss= 0.2352, Training Accuracy= 0.7641, Minibatch error= 5.2%\n",
      "2017-09-07 19:21:34,525 Iter 86650, Minibatch Loss= 0.4024, Training Accuracy= 0.7560, Minibatch error= 6.9%\n",
      "2017-09-07 19:28:16,075 Epoch 866, Average loss: 0.0133, learning rate: 0.0010\n",
      "2017-09-07 19:28:16,145 Verification error= 5.6%, loss= 0.3217\n",
      "2017-09-07 19:28:58,703 Iter 86700, Minibatch Loss= 0.6996, Training Accuracy= 0.7930, Minibatch error= 6.6%\n",
      "2017-09-07 19:35:49,082 Iter 86750, Minibatch Loss= 0.1993, Training Accuracy= 0.7049, Minibatch error= 6.3%\n",
      "2017-09-07 19:42:32,150 Epoch 867, Average loss: 0.0116, learning rate: 0.0010\n",
      "2017-09-07 19:42:32,220 Verification error= 5.7%, loss= 0.4060\n",
      "2017-09-07 19:43:15,004 Iter 86800, Minibatch Loss= 0.3546, Training Accuracy= 0.7221, Minibatch error= 8.7%\n",
      "2017-09-07 19:50:05,379 Iter 86850, Minibatch Loss= 0.3093, Training Accuracy= 0.7406, Minibatch error= 6.8%\n",
      "2017-09-07 19:56:47,867 Epoch 868, Average loss: 0.0121, learning rate: 0.0010\n",
      "2017-09-07 19:56:47,939 Verification error= 5.6%, loss= 0.3340\n",
      "2017-09-07 19:57:30,669 Iter 86900, Minibatch Loss= 0.2380, Training Accuracy= 0.7609, Minibatch error= 5.0%\n",
      "2017-09-07 20:04:21,425 Iter 86950, Minibatch Loss= 0.2572, Training Accuracy= 0.7596, Minibatch error= 5.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-07 20:11:04,855 Epoch 869, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 20:11:04,924 Verification error= 5.4%, loss= 0.3268\n",
      "2017-09-07 20:11:47,690 Iter 87000, Minibatch Loss= 0.7358, Training Accuracy= 0.7708, Minibatch error= 8.2%\n",
      "2017-09-07 20:18:41,132 Iter 87050, Minibatch Loss= 1.5555, Training Accuracy= 0.7128, Minibatch error= 8.9%\n",
      "2017-09-07 20:25:24,667 Epoch 870, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-07 20:25:24,739 Verification error= 6.1%, loss= 0.4297\n",
      "2017-09-07 20:26:07,620 Iter 87100, Minibatch Loss= 0.5716, Training Accuracy= 0.7568, Minibatch error= 8.0%\n",
      "2017-09-07 20:33:00,169 Iter 87150, Minibatch Loss= 0.6441, Training Accuracy= 0.7669, Minibatch error= 7.9%\n",
      "2017-09-07 20:39:44,463 Epoch 871, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-07 20:39:44,533 Verification error= 5.8%, loss= 0.3584\n",
      "2017-09-07 20:40:27,474 Iter 87200, Minibatch Loss= 0.1922, Training Accuracy= 0.7815, Minibatch error= 5.9%\n",
      "2017-09-07 20:47:19,744 Iter 87250, Minibatch Loss= 0.2158, Training Accuracy= 0.7492, Minibatch error= 5.2%\n",
      "2017-09-07 20:54:03,911 Epoch 872, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-07 20:54:03,985 Verification error= 6.0%, loss= 0.4533\n",
      "2017-09-07 20:54:49,606 Iter 87300, Minibatch Loss= 0.3282, Training Accuracy= 0.7542, Minibatch error= 6.1%\n",
      "2017-09-07 21:01:44,627 Iter 87350, Minibatch Loss= 1.0185, Training Accuracy= 0.7760, Minibatch error= 7.3%\n",
      "2017-09-07 21:08:30,758 Epoch 873, Average loss: 0.0115, learning rate: 0.0010\n",
      "2017-09-07 21:08:30,834 Verification error= 5.3%, loss= 0.3150\n",
      "2017-09-07 21:09:13,832 Iter 87400, Minibatch Loss= 0.1935, Training Accuracy= 0.6956, Minibatch error= 5.5%\n",
      "2017-09-07 21:16:07,792 Iter 87450, Minibatch Loss= 0.3094, Training Accuracy= 0.6857, Minibatch error= 7.9%\n",
      "2017-09-07 21:22:53,522 Epoch 874, Average loss: 0.0134, learning rate: 0.0010\n",
      "2017-09-07 21:22:53,592 Verification error= 6.3%, loss= 0.4203\n",
      "2017-09-07 21:23:36,793 Iter 87500, Minibatch Loss= 0.2784, Training Accuracy= 0.7599, Minibatch error= 5.9%\n",
      "2017-09-07 21:30:31,632 Iter 87550, Minibatch Loss= 0.2268, Training Accuracy= 0.7667, Minibatch error= 6.2%\n",
      "2017-09-07 21:37:17,796 Epoch 875, Average loss: 0.0122, learning rate: 0.0010\n",
      "2017-09-07 21:37:17,866 Verification error= 6.0%, loss= 0.3994\n",
      "2017-09-07 21:38:00,858 Iter 87600, Minibatch Loss= 0.3921, Training Accuracy= 0.7299, Minibatch error= 6.5%\n",
      "2017-09-07 21:44:55,368 Iter 87650, Minibatch Loss= 0.7861, Training Accuracy= 0.7484, Minibatch error= 8.4%\n",
      "2017-09-07 21:51:41,437 Epoch 876, Average loss: 0.0113, learning rate: 0.0010\n",
      "2017-09-07 21:51:41,507 Verification error= 5.6%, loss= 0.3508\n",
      "2017-09-07 21:52:24,838 Iter 87700, Minibatch Loss= 1.3815, Training Accuracy= 0.7003, Minibatch error= 9.6%\n",
      "2017-09-07 21:59:19,188 Iter 87750, Minibatch Loss= 0.5176, Training Accuracy= 0.7586, Minibatch error= 8.8%\n",
      "2017-09-07 22:06:06,282 Epoch 877, Average loss: 0.0118, learning rate: 0.0010\n",
      "2017-09-07 22:06:06,353 Verification error= 6.2%, loss= 0.4371\n",
      "2017-09-07 22:06:49,708 Iter 87800, Minibatch Loss= 0.9648, Training Accuracy= 0.7742, Minibatch error= 7.3%\n",
      "2017-09-07 22:13:45,358 Iter 87850, Minibatch Loss= 0.2268, Training Accuracy= 0.7948, Minibatch error= 6.5%\n",
      "2017-09-07 22:20:31,518 Epoch 878, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 22:20:31,591 Verification error= 5.8%, loss= 0.3593\n",
      "2017-09-07 22:21:15,061 Iter 87900, Minibatch Loss= 0.2454, Training Accuracy= 0.7656, Minibatch error= 5.3%\n",
      "2017-09-07 22:28:11,823 Iter 87950, Minibatch Loss= 0.2788, Training Accuracy= 0.7664, Minibatch error= 6.6%\n",
      "2017-09-07 22:35:02,212 Epoch 879, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-07 22:35:02,291 Verification error= 5.4%, loss= 0.3247\n",
      "2017-09-07 22:35:45,861 Iter 88000, Minibatch Loss= 0.7094, Training Accuracy= 0.7961, Minibatch error= 5.9%\n",
      "2017-09-07 22:42:42,938 Iter 88050, Minibatch Loss= 0.2347, Training Accuracy= 0.7219, Minibatch error= 6.2%\n",
      "2017-09-07 22:49:30,284 Epoch 880, Average loss: 0.0115, learning rate: 0.0010\n",
      "2017-09-07 22:49:30,355 Verification error= 5.8%, loss= 0.4115\n",
      "2017-09-07 22:50:14,219 Iter 88100, Minibatch Loss= 0.4044, Training Accuracy= 0.7073, Minibatch error= 9.0%\n",
      "2017-09-07 22:57:12,817 Iter 88150, Minibatch Loss= 0.2199, Training Accuracy= 0.7599, Minibatch error= 4.8%\n",
      "2017-09-07 23:04:01,497 Epoch 881, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-07 23:04:01,569 Verification error= 5.5%, loss= 0.3524\n",
      "2017-09-07 23:04:45,160 Iter 88200, Minibatch Loss= 0.2180, Training Accuracy= 0.7828, Minibatch error= 3.7%\n",
      "2017-09-07 23:11:43,291 Iter 88250, Minibatch Loss= 0.3377, Training Accuracy= 0.7440, Minibatch error= 5.5%\n",
      "2017-09-07 23:18:32,458 Epoch 882, Average loss: 0.0114, learning rate: 0.0010\n",
      "2017-09-07 23:18:32,536 Verification error= 5.4%, loss= 0.3084\n",
      "2017-09-07 23:19:16,347 Iter 88300, Minibatch Loss= 0.6521, Training Accuracy= 0.7599, Minibatch error= 8.2%\n",
      "2017-09-07 23:26:14,960 Iter 88350, Minibatch Loss= 1.2251, Training Accuracy= 0.7185, Minibatch error= 9.0%\n",
      "2017-09-07 23:33:04,735 Epoch 883, Average loss: 0.0148, learning rate: 0.0010\n",
      "2017-09-07 23:33:04,809 Verification error= 6.0%, loss= 0.3300\n",
      "2017-09-07 23:33:51,110 Iter 88400, Minibatch Loss= 0.4741, Training Accuracy= 0.7477, Minibatch error= 7.9%\n",
      "2017-09-07 23:40:49,654 Iter 88450, Minibatch Loss= 0.7991, Training Accuracy= 0.7380, Minibatch error= 8.6%\n",
      "2017-09-07 23:47:40,725 Epoch 884, Average loss: 0.0126, learning rate: 0.0010\n",
      "2017-09-07 23:47:40,799 Verification error= 5.6%, loss= 0.3134\n",
      "2017-09-07 23:48:24,975 Iter 88500, Minibatch Loss= 0.1715, Training Accuracy= 0.7654, Minibatch error= 5.9%\n",
      "2017-09-07 23:55:24,507 Iter 88550, Minibatch Loss= 0.2324, Training Accuracy= 0.7875, Minibatch error= 5.3%\n",
      "2017-09-08 00:02:15,648 Epoch 885, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-08 00:02:15,721 Verification error= 5.3%, loss= 0.2542\n",
      "2017-09-08 00:02:59,426 Iter 88600, Minibatch Loss= 0.2646, Training Accuracy= 0.7724, Minibatch error= 5.9%\n",
      "2017-09-08 00:09:58,000 Iter 88650, Minibatch Loss= 0.8541, Training Accuracy= 0.7680, Minibatch error= 6.6%\n",
      "2017-09-08 00:16:49,994 Epoch 886, Average loss: 0.0116, learning rate: 0.0010\n",
      "2017-09-08 00:16:50,063 Verification error= 5.7%, loss= 0.3115\n",
      "2017-09-08 00:17:33,780 Iter 88700, Minibatch Loss= 0.2296, Training Accuracy= 0.6859, Minibatch error= 5.8%\n",
      "2017-09-08 00:24:33,618 Iter 88750, Minibatch Loss= 0.3157, Training Accuracy= 0.7289, Minibatch error= 8.0%\n",
      "2017-09-08 00:31:25,038 Epoch 887, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 00:31:25,108 Verification error= 5.8%, loss= 0.3669\n",
      "2017-09-08 00:32:08,939 Iter 88800, Minibatch Loss= 0.2229, Training Accuracy= 0.7310, Minibatch error= 5.2%\n",
      "2017-09-08 00:39:09,548 Iter 88850, Minibatch Loss= 0.2445, Training Accuracy= 0.7542, Minibatch error= 5.3%\n",
      "2017-09-08 00:46:01,119 Epoch 888, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-08 00:46:01,189 Verification error= 6.8%, loss= 0.4441\n",
      "2017-09-08 00:46:44,928 Iter 88900, Minibatch Loss= 0.4748, Training Accuracy= 0.7359, Minibatch error= 6.9%\n",
      "2017-09-08 00:53:45,910 Iter 88950, Minibatch Loss= 0.6264, Training Accuracy= 0.7466, Minibatch error= 8.0%\n",
      "2017-09-08 01:00:38,910 Epoch 889, Average loss: 0.0127, learning rate: 0.0010\n",
      "2017-09-08 01:00:38,983 Verification error= 5.1%, loss= 0.2265\n",
      "2017-09-08 01:01:22,854 Iter 89000, Minibatch Loss= 0.9729, Training Accuracy= 0.7693, Minibatch error= 7.4%\n",
      "2017-09-08 01:08:23,926 Iter 89050, Minibatch Loss= 0.5665, Training Accuracy= 0.7648, Minibatch error= 8.2%\n",
      "2017-09-08 01:15:15,770 Epoch 890, Average loss: 0.0125, learning rate: 0.0010\n",
      "2017-09-08 01:15:15,842 Verification error= 6.6%, loss= 0.5631\n",
      "2017-09-08 01:15:59,937 Iter 89100, Minibatch Loss= 1.0306, Training Accuracy= 0.7318, Minibatch error= 9.3%\n",
      "2017-09-08 01:23:01,090 Iter 89150, Minibatch Loss= 0.2173, Training Accuracy= 0.7698, Minibatch error= 6.8%\n",
      "2017-09-08 01:29:53,460 Epoch 891, Average loss: 0.0113, learning rate: 0.0010\n",
      "2017-09-08 01:29:53,533 Verification error= 6.3%, loss= 0.4301\n",
      "2017-09-08 01:30:37,706 Iter 89200, Minibatch Loss= 0.2266, Training Accuracy= 0.7471, Minibatch error= 4.7%\n",
      "2017-09-08 01:37:39,465 Iter 89250, Minibatch Loss= 0.3594, Training Accuracy= 0.7492, Minibatch error= 6.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-08 01:44:32,565 Epoch 892, Average loss: 0.0111, learning rate: 0.0010\n",
      "2017-09-08 01:44:32,638 Verification error= 5.9%, loss= 0.4248\n",
      "2017-09-08 01:45:16,683 Iter 89300, Minibatch Loss= 0.7670, Training Accuracy= 0.7906, Minibatch error= 6.3%\n",
      "2017-09-08 01:52:19,360 Iter 89350, Minibatch Loss= 0.2307, Training Accuracy= 0.6781, Minibatch error= 5.9%\n",
      "2017-09-08 01:59:14,713 Epoch 893, Average loss: 0.0116, learning rate: 0.0010\n",
      "2017-09-08 01:59:14,783 Verification error= 5.7%, loss= 0.3534\n",
      "2017-09-08 01:59:58,981 Iter 89400, Minibatch Loss= 0.3984, Training Accuracy= 0.6297, Minibatch error= 8.8%\n",
      "2017-09-08 02:07:02,142 Iter 89450, Minibatch Loss= 0.2319, Training Accuracy= 0.7453, Minibatch error= 5.3%\n",
      "2017-09-08 02:13:56,926 Epoch 894, Average loss: 0.0115, learning rate: 0.0010\n",
      "2017-09-08 02:13:56,997 Verification error= 5.1%, loss= 0.2738\n",
      "2017-09-08 02:14:41,407 Iter 89500, Minibatch Loss= 0.2097, Training Accuracy= 0.7831, Minibatch error= 5.2%\n",
      "2017-09-08 02:21:44,883 Iter 89550, Minibatch Loss= 0.3910, Training Accuracy= 0.7143, Minibatch error= 5.8%\n",
      "2017-09-08 02:28:40,536 Epoch 895, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-08 02:28:40,610 Verification error= 6.3%, loss= 0.4402\n",
      "2017-09-08 02:29:27,368 Iter 89600, Minibatch Loss= 0.7621, Training Accuracy= 0.7279, Minibatch error= 8.4%\n",
      "2017-09-08 02:36:32,237 Iter 89650, Minibatch Loss= 1.9128, Training Accuracy= 0.6281, Minibatch error= 9.9%\n",
      "2017-09-08 02:43:28,199 Epoch 896, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 02:43:28,269 Verification error= 7.0%, loss= 0.6489\n",
      "2017-09-08 02:44:12,666 Iter 89700, Minibatch Loss= 0.8977, Training Accuracy= 0.6810, Minibatch error= 10.4%\n",
      "2017-09-08 02:51:17,274 Iter 89750, Minibatch Loss= 0.9747, Training Accuracy= 0.7354, Minibatch error= 8.9%\n",
      "2017-09-08 02:58:13,498 Epoch 897, Average loss: 0.0118, learning rate: 0.0010\n",
      "2017-09-08 02:58:13,568 Verification error= 6.4%, loss= 0.4737\n",
      "2017-09-08 02:58:57,906 Iter 89800, Minibatch Loss= 0.2088, Training Accuracy= 0.5977, Minibatch error= 6.0%\n",
      "2017-09-08 03:06:02,852 Iter 89850, Minibatch Loss= 0.2621, Training Accuracy= 0.7583, Minibatch error= 4.9%\n",
      "2017-09-08 03:13:00,059 Epoch 898, Average loss: 0.0125, learning rate: 0.0010\n",
      "2017-09-08 03:13:00,130 Verification error= 5.8%, loss= 0.3938\n",
      "2017-09-08 03:13:44,698 Iter 89900, Minibatch Loss= 0.2799, Training Accuracy= 0.7669, Minibatch error= 5.9%\n",
      "2017-09-08 03:20:50,873 Iter 89950, Minibatch Loss= 1.1370, Training Accuracy= 0.7755, Minibatch error= 7.5%\n",
      "2017-09-08 03:27:47,115 Epoch 899, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-08 03:27:47,185 Verification error= 5.6%, loss= 0.3632\n",
      "2017-09-08 03:28:31,885 Iter 90000, Minibatch Loss= 0.2372, Training Accuracy= 0.6857, Minibatch error= 5.6%\n",
      "2017-09-08 03:35:38,490 Iter 90050, Minibatch Loss= 0.2583, Training Accuracy= 0.6966, Minibatch error= 7.6%\n",
      "2017-09-08 03:42:36,225 Epoch 900, Average loss: 0.0130, learning rate: 0.0010\n",
      "2017-09-08 03:42:36,296 Verification error= 5.8%, loss= 0.4656\n",
      "2017-09-08 03:43:20,891 Iter 90100, Minibatch Loss= 0.3463, Training Accuracy= 0.7341, Minibatch error= 5.9%\n",
      "2017-09-08 03:50:27,326 Iter 90150, Minibatch Loss= 0.2145, Training Accuracy= 0.7758, Minibatch error= 5.5%\n",
      "2017-09-08 03:57:26,313 Epoch 901, Average loss: 0.0117, learning rate: 0.0010\n",
      "2017-09-08 03:57:26,382 Verification error= 5.4%, loss= 0.3361\n",
      "2017-09-08 03:58:11,007 Iter 90200, Minibatch Loss= 0.3728, Training Accuracy= 0.7198, Minibatch error= 5.9%\n",
      "2017-09-08 04:05:18,180 Iter 90250, Minibatch Loss= 0.6561, Training Accuracy= 0.7956, Minibatch error= 7.7%\n",
      "2017-09-08 04:12:17,470 Epoch 902, Average loss: 0.0123, learning rate: 0.0010\n",
      "2017-09-08 04:12:17,540 Verification error= 5.9%, loss= 0.3609\n",
      "2017-09-08 04:13:02,302 Iter 90300, Minibatch Loss= 1.5480, Training Accuracy= 0.6586, Minibatch error= 9.4%\n",
      "2017-09-08 04:20:10,762 Iter 90350, Minibatch Loss= 0.8306, Training Accuracy= 0.7318, Minibatch error= 9.2%\n",
      "2017-09-08 04:27:09,718 Epoch 903, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 04:27:09,797 Verification error= 5.6%, loss= 0.3463\n",
      "2017-09-08 04:27:54,548 Iter 90400, Minibatch Loss= 0.7225, Training Accuracy= 0.6885, Minibatch error= 7.6%\n",
      "2017-09-08 04:35:02,748 Iter 90450, Minibatch Loss= 0.2301, Training Accuracy= 0.7406, Minibatch error= 6.5%\n",
      "2017-09-08 04:42:01,095 Epoch 904, Average loss: 0.0116, learning rate: 0.0010\n",
      "2017-09-08 04:42:01,166 Verification error= 5.3%, loss= 0.2799\n",
      "2017-09-08 04:42:46,193 Iter 90500, Minibatch Loss= 0.1519, Training Accuracy= 0.7508, Minibatch error= 4.2%\n",
      "2017-09-08 04:49:54,583 Iter 90550, Minibatch Loss= 0.4389, Training Accuracy= 0.6964, Minibatch error= 6.8%\n",
      "2017-09-08 04:56:54,040 Epoch 905, Average loss: 0.0119, learning rate: 0.0010\n",
      "2017-09-08 04:56:54,110 Verification error= 5.1%, loss= 0.2854\n",
      "2017-09-08 04:57:38,458 Iter 90600, Minibatch Loss= 0.7483, Training Accuracy= 0.7867, Minibatch error= 5.8%\n",
      "2017-09-08 05:04:46,978 Iter 90650, Minibatch Loss= 0.2429, Training Accuracy= 0.6849, Minibatch error= 5.2%\n",
      "2017-09-08 05:11:46,974 Epoch 906, Average loss: 0.0117, learning rate: 0.0010\n",
      "2017-09-08 05:11:47,048 Verification error= 4.9%, loss= 0.2612\n",
      "2017-09-08 05:12:34,464 Iter 90700, Minibatch Loss= 0.2686, Training Accuracy= 0.6883, Minibatch error= 7.9%\n",
      "2017-09-08 05:19:43,908 Iter 90750, Minibatch Loss= 0.3142, Training Accuracy= 0.7063, Minibatch error= 6.1%\n",
      "2017-09-08 05:26:44,515 Epoch 907, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 05:26:44,585 Verification error= 5.7%, loss= 0.3738\n",
      "2017-09-08 05:27:29,190 Iter 90800, Minibatch Loss= 0.3037, Training Accuracy= 0.6984, Minibatch error= 5.5%\n",
      "2017-09-08 05:34:38,306 Iter 90850, Minibatch Loss= 0.3479, Training Accuracy= 0.7435, Minibatch error= 5.5%\n",
      "2017-09-08 05:41:39,378 Epoch 908, Average loss: 0.0117, learning rate: 0.0010\n",
      "2017-09-08 05:41:39,450 Verification error= 5.6%, loss= 0.3397\n",
      "2017-09-08 05:42:24,286 Iter 90900, Minibatch Loss= 0.7939, Training Accuracy= 0.7219, Minibatch error= 7.1%\n",
      "2017-09-08 05:49:34,723 Iter 90950, Minibatch Loss= 1.3506, Training Accuracy= 0.6391, Minibatch error= 9.2%\n",
      "2017-09-08 05:56:36,501 Epoch 909, Average loss: 0.0114, learning rate: 0.0010\n",
      "2017-09-08 05:56:36,573 Verification error= 6.2%, loss= 0.3940\n",
      "2017-09-08 05:57:22,157 Iter 91000, Minibatch Loss= 0.6883, Training Accuracy= 0.7419, Minibatch error= 7.5%\n",
      "2017-09-08 06:04:32,854 Iter 91050, Minibatch Loss= 0.6196, Training Accuracy= 0.6885, Minibatch error= 7.3%\n",
      "2017-09-08 06:11:35,213 Epoch 910, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 06:11:35,283 Verification error= 6.0%, loss= 0.3443\n",
      "2017-09-08 06:12:20,792 Iter 91100, Minibatch Loss= 0.2115, Training Accuracy= 0.6182, Minibatch error= 6.8%\n",
      "2017-09-08 06:19:31,889 Iter 91150, Minibatch Loss= 0.2769, Training Accuracy= 0.7107, Minibatch error= 5.0%\n",
      "2017-09-08 06:26:34,219 Epoch 911, Average loss: 0.0117, learning rate: 0.0010\n",
      "2017-09-08 06:26:34,289 Verification error= 6.7%, loss= 0.5217\n",
      "2017-09-08 06:27:19,613 Iter 91200, Minibatch Loss= 0.3289, Training Accuracy= 0.6435, Minibatch error= 6.4%\n",
      "2017-09-08 06:34:32,138 Iter 91250, Minibatch Loss= 0.5975, Training Accuracy= 0.7831, Minibatch error= 6.7%\n",
      "2017-09-08 06:41:35,811 Epoch 912, Average loss: 0.0120, learning rate: 0.0010\n",
      "2017-09-08 06:41:35,888 Verification error= 6.0%, loss= 0.4091\n",
      "2017-09-08 06:42:21,045 Iter 91300, Minibatch Loss= 0.1923, Training Accuracy= 0.5940, Minibatch error= 6.0%\n",
      "2017-09-08 06:49:32,916 Iter 91350, Minibatch Loss= 0.3293, Training Accuracy= 0.5706, Minibatch error= 8.5%\n",
      "2017-09-08 06:56:36,378 Epoch 913, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 06:56:36,448 Verification error= 5.8%, loss= 0.3256\n",
      "2017-09-08 06:57:21,436 Iter 91400, Minibatch Loss= 0.2574, Training Accuracy= 0.6995, Minibatch error= 5.1%\n",
      "2017-09-08 07:04:33,845 Iter 91450, Minibatch Loss= 0.2387, Training Accuracy= 0.6617, Minibatch error= 4.9%\n",
      "2017-09-08 07:11:38,802 Epoch 914, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 07:11:38,872 Verification error= 5.9%, loss= 0.3871\n",
      "2017-09-08 07:12:24,175 Iter 91500, Minibatch Loss= 0.3884, Training Accuracy= 0.7148, Minibatch error= 5.7%\n",
      "2017-09-08 07:19:37,957 Iter 91550, Minibatch Loss= 0.6168, Training Accuracy= 0.7211, Minibatch error= 7.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-08 07:26:43,561 Epoch 915, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 07:26:43,635 Verification error= 6.1%, loss= 0.4061\n",
      "2017-09-08 07:27:28,828 Iter 91600, Minibatch Loss= 1.6306, Training Accuracy= 0.6586, Minibatch error= 9.9%\n",
      "2017-09-08 07:34:41,931 Iter 91650, Minibatch Loss= 0.9769, Training Accuracy= 0.6599, Minibatch error= 9.3%\n",
      "2017-09-08 07:41:47,474 Epoch 916, Average loss: 0.0114, learning rate: 0.0010\n",
      "2017-09-08 07:41:47,545 Verification error= 5.8%, loss= 0.3529\n",
      "2017-09-08 07:42:32,624 Iter 91700, Minibatch Loss= 0.7564, Training Accuracy= 0.6831, Minibatch error= 7.5%\n",
      "2017-09-08 07:49:47,690 Iter 91750, Minibatch Loss= 0.2770, Training Accuracy= 0.6911, Minibatch error= 7.0%\n",
      "2017-09-08 07:56:53,575 Epoch 917, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 07:56:53,644 Verification error= 5.5%, loss= 0.3673\n",
      "2017-09-08 07:57:39,355 Iter 91800, Minibatch Loss= 0.1888, Training Accuracy= 0.7451, Minibatch error= 4.9%\n",
      "2017-09-08 08:04:53,761 Iter 91850, Minibatch Loss= 0.3188, Training Accuracy= 0.6646, Minibatch error= 6.0%\n",
      "2017-09-08 08:11:59,641 Epoch 918, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 08:11:59,711 Verification error= 5.9%, loss= 0.3504\n",
      "2017-09-08 08:12:48,223 Iter 91900, Minibatch Loss= 0.7491, Training Accuracy= 0.7904, Minibatch error= 6.9%\n",
      "2017-09-08 08:20:02,008 Iter 91950, Minibatch Loss= 0.1882, Training Accuracy= 0.7036, Minibatch error= 4.5%\n",
      "2017-09-08 08:27:08,021 Epoch 919, Average loss: 0.0119, learning rate: 0.0010\n",
      "2017-09-08 08:27:08,090 Verification error= 6.1%, loss= 0.3401\n",
      "2017-09-08 08:27:53,554 Iter 92000, Minibatch Loss= 0.3025, Training Accuracy= 0.6792, Minibatch error= 9.6%\n",
      "2017-09-08 08:35:09,668 Iter 92050, Minibatch Loss= 0.3096, Training Accuracy= 0.7250, Minibatch error= 5.7%\n",
      "2017-09-08 08:42:16,033 Epoch 920, Average loss: 0.0118, learning rate: 0.0010\n",
      "2017-09-08 08:42:16,104 Verification error= 6.5%, loss= 0.3799\n",
      "2017-09-08 08:43:01,836 Iter 92100, Minibatch Loss= 0.2596, Training Accuracy= 0.7180, Minibatch error= 5.4%\n",
      "2017-09-08 08:50:19,116 Iter 92150, Minibatch Loss= 0.1931, Training Accuracy= 0.7052, Minibatch error= 5.4%\n",
      "2017-09-08 08:57:27,018 Epoch 921, Average loss: 0.0117, learning rate: 0.0010\n",
      "2017-09-08 08:57:27,087 Verification error= 5.7%, loss= 0.3343\n",
      "2017-09-08 08:58:12,367 Iter 92200, Minibatch Loss= 0.8489, Training Accuracy= 0.7268, Minibatch error= 8.3%\n",
      "2017-09-08 09:05:28,975 Iter 92250, Minibatch Loss= 1.5548, Training Accuracy= 0.5961, Minibatch error= 9.8%\n",
      "2017-09-08 09:12:36,387 Epoch 922, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 09:12:36,459 Verification error= 6.1%, loss= 0.4202\n",
      "2017-09-08 09:13:21,768 Iter 92300, Minibatch Loss= 0.5527, Training Accuracy= 0.7370, Minibatch error= 7.3%\n",
      "2017-09-08 09:20:39,063 Iter 92350, Minibatch Loss= 1.0068, Training Accuracy= 0.6680, Minibatch error= 9.4%\n",
      "2017-09-08 09:27:48,218 Epoch 923, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 09:27:48,288 Verification error= 5.9%, loss= 0.3604\n",
      "2017-09-08 09:28:33,766 Iter 92400, Minibatch Loss= 0.2241, Training Accuracy= 0.7760, Minibatch error= 6.3%\n",
      "2017-09-08 09:35:53,391 Iter 92450, Minibatch Loss= 0.2085, Training Accuracy= 0.7047, Minibatch error= 4.3%\n",
      "2017-09-08 09:43:02,397 Epoch 924, Average loss: 0.0125, learning rate: 0.0010\n",
      "2017-09-08 09:43:02,475 Verification error= 6.7%, loss= 0.5318\n",
      "2017-09-08 09:43:48,799 Iter 92500, Minibatch Loss= 0.4246, Training Accuracy= 0.6760, Minibatch error= 6.8%\n",
      "2017-09-08 09:51:07,624 Iter 92550, Minibatch Loss= 0.8055, Training Accuracy= 0.7188, Minibatch error= 6.0%\n",
      "2017-09-08 09:58:17,447 Epoch 925, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 09:58:17,516 Verification error= 6.0%, loss= 0.3800\n",
      "2017-09-08 09:59:03,522 Iter 92600, Minibatch Loss= 0.2836, Training Accuracy= 0.6596, Minibatch error= 6.3%\n",
      "2017-09-08 10:06:22,032 Iter 92650, Minibatch Loss= 0.3459, Training Accuracy= 0.7026, Minibatch error= 8.6%\n",
      "2017-09-08 10:13:31,424 Epoch 926, Average loss: 0.0104, learning rate: 0.0010\n",
      "2017-09-08 10:13:31,494 Verification error= 6.2%, loss= 0.4368\n",
      "2017-09-08 10:14:17,347 Iter 92700, Minibatch Loss= 0.2084, Training Accuracy= 0.7250, Minibatch error= 5.1%\n",
      "2017-09-08 10:21:36,903 Iter 92750, Minibatch Loss= 0.2116, Training Accuracy= 0.7372, Minibatch error= 6.6%\n",
      "2017-09-08 10:28:47,002 Epoch 927, Average loss: 0.0114, learning rate: 0.0010\n",
      "2017-09-08 10:28:47,072 Verification error= 5.9%, loss= 0.3119\n",
      "2017-09-08 10:29:32,941 Iter 92800, Minibatch Loss= 0.2873, Training Accuracy= 0.6453, Minibatch error= 5.7%\n",
      "2017-09-08 10:36:52,550 Iter 92850, Minibatch Loss= 0.4894, Training Accuracy= 0.7510, Minibatch error= 7.5%\n",
      "2017-09-08 10:44:03,114 Epoch 928, Average loss: 0.0121, learning rate: 0.0010\n",
      "2017-09-08 10:44:03,184 Verification error= 5.9%, loss= 0.3759\n",
      "2017-09-08 10:44:49,146 Iter 92900, Minibatch Loss= 1.7344, Training Accuracy= 0.5638, Minibatch error= 10.5%\n",
      "2017-09-08 10:52:08,665 Iter 92950, Minibatch Loss= 0.5380, Training Accuracy= 0.7549, Minibatch error= 7.2%\n",
      "2017-09-08 10:59:19,964 Epoch 929, Average loss: 0.0122, learning rate: 0.0010\n",
      "2017-09-08 10:59:20,034 Verification error= 5.7%, loss= 0.3240\n",
      "2017-09-08 11:00:08,805 Iter 93000, Minibatch Loss= 0.6487, Training Accuracy= 0.7073, Minibatch error= 7.2%\n",
      "2017-09-08 11:07:29,934 Iter 93050, Minibatch Loss= 0.2172, Training Accuracy= 0.7458, Minibatch error= 6.4%\n",
      "2017-09-08 11:14:42,778 Epoch 930, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-08 11:14:42,856 Verification error= 6.3%, loss= 0.5377\n",
      "2017-09-08 11:15:28,739 Iter 93100, Minibatch Loss= 0.2294, Training Accuracy= 0.7430, Minibatch error= 5.1%\n",
      "2017-09-08 11:22:49,543 Iter 93150, Minibatch Loss= 0.4012, Training Accuracy= 0.6487, Minibatch error= 6.4%\n",
      "2017-09-08 11:30:01,961 Epoch 931, Average loss: 0.0106, learning rate: 0.0010\n",
      "2017-09-08 11:30:02,031 Verification error= 6.4%, loss= 0.4644\n",
      "2017-09-08 11:30:47,784 Iter 93200, Minibatch Loss= 0.8593, Training Accuracy= 0.7307, Minibatch error= 7.4%\n",
      "2017-09-08 11:38:08,714 Iter 93250, Minibatch Loss= 0.1878, Training Accuracy= 0.6297, Minibatch error= 5.6%\n",
      "2017-09-08 11:45:20,220 Epoch 932, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 11:45:20,291 Verification error= 5.9%, loss= 0.3174\n",
      "2017-09-08 11:46:06,752 Iter 93300, Minibatch Loss= 0.3549, Training Accuracy= 0.7654, Minibatch error= 9.2%\n",
      "2017-09-08 11:53:27,923 Iter 93350, Minibatch Loss= 0.2940, Training Accuracy= 0.7484, Minibatch error= 5.8%\n",
      "2017-09-08 12:00:40,209 Epoch 933, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 12:00:40,279 Verification error= 6.1%, loss= 0.3796\n",
      "2017-09-08 12:01:26,720 Iter 93400, Minibatch Loss= 0.2571, Training Accuracy= 0.7664, Minibatch error= 5.7%\n",
      "2017-09-08 12:08:48,072 Iter 93450, Minibatch Loss= 0.3151, Training Accuracy= 0.7070, Minibatch error= 5.6%\n",
      "2017-09-08 12:16:00,906 Epoch 934, Average loss: 0.0105, learning rate: 0.0010\n",
      "2017-09-08 12:16:00,985 Verification error= 6.7%, loss= 0.5889\n",
      "2017-09-08 12:16:47,754 Iter 93500, Minibatch Loss= 1.0177, Training Accuracy= 0.6526, Minibatch error= 9.0%\n",
      "2017-09-08 12:24:10,144 Iter 93550, Minibatch Loss= 1.7229, Training Accuracy= 0.5992, Minibatch error= 10.2%\n",
      "2017-09-08 12:31:23,517 Epoch 935, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 12:31:23,595 Verification error= 6.5%, loss= 0.4188\n",
      "2017-09-08 12:32:09,923 Iter 93600, Minibatch Loss= 0.5630, Training Accuracy= 0.7388, Minibatch error= 8.1%\n",
      "2017-09-08 12:39:32,689 Iter 93650, Minibatch Loss= 0.7072, Training Accuracy= 0.7568, Minibatch error= 7.9%\n",
      "2017-09-08 12:46:46,746 Epoch 936, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 12:46:46,825 Verification error= 5.9%, loss= 0.3416\n",
      "2017-09-08 12:47:33,307 Iter 93700, Minibatch Loss= 0.2255, Training Accuracy= 0.6958, Minibatch error= 6.7%\n",
      "2017-09-08 12:54:57,686 Iter 93750, Minibatch Loss= 0.1773, Training Accuracy= 0.7740, Minibatch error= 4.7%\n",
      "2017-09-08 13:02:12,343 Epoch 937, Average loss: 0.0098, learning rate: 0.0010\n",
      "2017-09-08 13:02:12,414 Verification error= 6.3%, loss= 0.4196\n",
      "2017-09-08 13:02:58,689 Iter 93800, Minibatch Loss= 0.4215, Training Accuracy= 0.6479, Minibatch error= 6.2%\n",
      "2017-09-08 13:10:22,535 Iter 93850, Minibatch Loss= 0.7523, Training Accuracy= 0.7654, Minibatch error= 6.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-08 13:17:38,828 Epoch 938, Average loss: 0.0104, learning rate: 0.0010\n",
      "2017-09-08 13:17:38,902 Verification error= 5.8%, loss= 0.2974\n",
      "2017-09-08 13:18:25,442 Iter 93900, Minibatch Loss= 0.1820, Training Accuracy= 0.6938, Minibatch error= 5.3%\n",
      "2017-09-08 13:25:49,506 Iter 93950, Minibatch Loss= 0.3213, Training Accuracy= 0.5474, Minibatch error= 8.1%\n",
      "2017-09-08 13:33:05,922 Epoch 939, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 13:33:06,001 Verification error= 5.9%, loss= 0.3467\n",
      "2017-09-08 13:33:52,377 Iter 94000, Minibatch Loss= 0.2422, Training Accuracy= 0.7102, Minibatch error= 5.5%\n",
      "2017-09-08 13:41:16,924 Iter 94050, Minibatch Loss= 0.2221, Training Accuracy= 0.6393, Minibatch error= 5.2%\n",
      "2017-09-08 13:48:34,102 Epoch 940, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 13:48:34,172 Verification error= 5.4%, loss= 0.2869\n",
      "2017-09-08 13:49:23,574 Iter 94100, Minibatch Loss= 0.2869, Training Accuracy= 0.6474, Minibatch error= 5.0%\n",
      "2017-09-08 13:56:49,009 Iter 94150, Minibatch Loss= 0.9547, Training Accuracy= 0.7107, Minibatch error= 8.8%\n",
      "2017-09-08 14:04:06,282 Epoch 941, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-08 14:04:06,355 Verification error= 5.2%, loss= 0.3174\n",
      "2017-09-08 14:04:52,783 Iter 94200, Minibatch Loss= 1.2684, Training Accuracy= 0.5378, Minibatch error= 9.5%\n",
      "2017-09-08 14:12:21,117 Iter 94250, Minibatch Loss= 0.5644, Training Accuracy= 0.7195, Minibatch error= 7.3%\n",
      "2017-09-08 14:19:39,041 Epoch 942, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 14:19:39,115 Verification error= 6.2%, loss= 0.3557\n",
      "2017-09-08 14:20:25,569 Iter 94300, Minibatch Loss= 0.7141, Training Accuracy= 0.7208, Minibatch error= 7.7%\n",
      "2017-09-08 14:27:52,223 Iter 94350, Minibatch Loss= 0.2617, Training Accuracy= 0.6383, Minibatch error= 7.4%\n",
      "2017-09-08 14:35:11,353 Epoch 943, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 14:35:11,427 Verification error= 5.2%, loss= 0.2915\n",
      "2017-09-08 14:35:58,430 Iter 94400, Minibatch Loss= 0.1930, Training Accuracy= 0.7117, Minibatch error= 3.9%\n",
      "2017-09-08 14:43:26,027 Iter 94450, Minibatch Loss= 0.3711, Training Accuracy= 0.7250, Minibatch error= 6.5%\n",
      "2017-09-08 14:50:44,258 Epoch 944, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 14:50:44,332 Verification error= 5.6%, loss= 0.3156\n",
      "2017-09-08 14:51:30,960 Iter 94500, Minibatch Loss= 0.6453, Training Accuracy= 0.7836, Minibatch error= 6.5%\n",
      "2017-09-08 14:58:59,934 Iter 94550, Minibatch Loss= 0.2536, Training Accuracy= 0.6716, Minibatch error= 6.4%\n",
      "2017-09-08 15:06:18,419 Epoch 945, Average loss: 0.0112, learning rate: 0.0010\n",
      "2017-09-08 15:06:18,488 Verification error= 5.9%, loss= 0.4263\n",
      "2017-09-08 15:07:05,391 Iter 94600, Minibatch Loss= 0.3292, Training Accuracy= 0.6000, Minibatch error= 8.8%\n",
      "2017-09-08 15:14:33,709 Iter 94650, Minibatch Loss= 0.3464, Training Accuracy= 0.7076, Minibatch error= 6.5%\n",
      "2017-09-08 15:21:52,572 Epoch 946, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 15:21:52,642 Verification error= 5.6%, loss= 0.3619\n",
      "2017-09-08 15:22:39,708 Iter 94700, Minibatch Loss= 0.2534, Training Accuracy= 0.6286, Minibatch error= 5.3%\n",
      "2017-09-08 15:30:08,495 Iter 94750, Minibatch Loss= 0.2723, Training Accuracy= 0.7312, Minibatch error= 5.3%\n",
      "2017-09-08 15:37:28,217 Epoch 947, Average loss: 0.0106, learning rate: 0.0010\n",
      "2017-09-08 15:37:28,294 Verification error= 6.2%, loss= 0.3971\n",
      "2017-09-08 15:38:15,433 Iter 94800, Minibatch Loss= 0.9849, Training Accuracy= 0.7156, Minibatch error= 8.2%\n",
      "2017-09-08 15:45:43,658 Iter 94850, Minibatch Loss= 1.5156, Training Accuracy= 0.6510, Minibatch error= 8.8%\n",
      "2017-09-08 15:53:03,584 Epoch 948, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 15:53:03,655 Verification error= 6.5%, loss= 0.5243\n",
      "2017-09-08 15:53:51,013 Iter 94900, Minibatch Loss= 1.1744, Training Accuracy= 0.7195, Minibatch error= 9.3%\n",
      "2017-09-08 16:01:19,747 Iter 94950, Minibatch Loss= 0.4905, Training Accuracy= 0.6911, Minibatch error= 6.7%\n",
      "2017-09-08 16:08:40,963 Epoch 949, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 16:08:41,035 Verification error= 6.8%, loss= 0.5392\n",
      "2017-09-08 16:09:28,377 Iter 95000, Minibatch Loss= 0.2382, Training Accuracy= 0.6214, Minibatch error= 6.9%\n",
      "2017-09-08 16:16:58,488 Iter 95050, Minibatch Loss= 0.1727, Training Accuracy= 0.7370, Minibatch error= 4.6%\n",
      "2017-09-08 16:24:20,788 Epoch 950, Average loss: 0.0100, learning rate: 0.0010\n",
      "2017-09-08 16:24:20,859 Verification error= 5.5%, loss= 0.2408\n",
      "2017-09-08 16:25:08,426 Iter 95100, Minibatch Loss= 0.2880, Training Accuracy= 0.6891, Minibatch error= 6.4%\n",
      "2017-09-08 16:32:38,813 Iter 95150, Minibatch Loss= 0.8910, Training Accuracy= 0.7508, Minibatch error= 7.3%\n",
      "2017-09-08 16:40:01,993 Epoch 951, Average loss: 0.0089, learning rate: 0.0010\n",
      "2017-09-08 16:40:02,072 Verification error= 5.8%, loss= 0.3637\n",
      "2017-09-08 16:40:49,138 Iter 95200, Minibatch Loss= 0.2299, Training Accuracy= 0.6005, Minibatch error= 5.4%\n",
      "2017-09-08 16:48:22,148 Iter 95250, Minibatch Loss= 0.5899, Training Accuracy= 0.6622, Minibatch error= 9.6%\n",
      "2017-09-08 16:55:44,925 Epoch 952, Average loss: 0.0110, learning rate: 0.0010\n",
      "2017-09-08 16:55:44,996 Verification error= 6.3%, loss= 0.4107\n",
      "2017-09-08 16:56:35,287 Iter 95300, Minibatch Loss= 0.3353, Training Accuracy= 0.6927, Minibatch error= 5.9%\n",
      "2017-09-08 17:04:07,073 Iter 95350, Minibatch Loss= 0.2776, Training Accuracy= 0.7635, Minibatch error= 6.4%\n",
      "2017-09-08 17:11:29,195 Epoch 953, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-08 17:11:29,267 Verification error= 6.6%, loss= 0.5318\n",
      "2017-09-08 17:12:16,456 Iter 95400, Minibatch Loss= 0.4486, Training Accuracy= 0.6612, Minibatch error= 6.1%\n",
      "2017-09-08 17:19:48,852 Iter 95450, Minibatch Loss= 1.0784, Training Accuracy= 0.6315, Minibatch error= 8.7%\n",
      "2017-09-08 17:27:12,380 Epoch 954, Average loss: 0.0105, learning rate: 0.0010\n",
      "2017-09-08 17:27:12,451 Verification error= 5.9%, loss= 0.4155\n",
      "2017-09-08 17:27:59,289 Iter 95500, Minibatch Loss= 1.5961, Training Accuracy= 0.5779, Minibatch error= 9.8%\n",
      "2017-09-08 17:35:31,445 Iter 95550, Minibatch Loss= 0.5476, Training Accuracy= 0.7617, Minibatch error= 7.7%\n",
      "2017-09-08 17:42:55,443 Epoch 955, Average loss: 0.0119, learning rate: 0.0010\n",
      "2017-09-08 17:42:55,513 Verification error= 5.6%, loss= 0.3481\n",
      "2017-09-08 17:43:42,585 Iter 95600, Minibatch Loss= 0.7388, Training Accuracy= 0.6534, Minibatch error= 8.0%\n",
      "2017-09-08 17:51:15,054 Iter 95650, Minibatch Loss= 0.2106, Training Accuracy= 0.7401, Minibatch error= 6.9%\n",
      "2017-09-08 17:58:38,762 Epoch 956, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 17:58:38,836 Verification error= 6.1%, loss= 0.4138\n",
      "2017-09-08 17:59:26,101 Iter 95700, Minibatch Loss= 0.2521, Training Accuracy= 0.7385, Minibatch error= 5.0%\n",
      "2017-09-08 18:06:59,494 Iter 95750, Minibatch Loss= 0.3593, Training Accuracy= 0.7312, Minibatch error= 7.4%\n",
      "2017-09-08 18:14:24,589 Epoch 957, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 18:14:24,667 Verification error= 5.4%, loss= 0.3365\n",
      "2017-09-08 18:15:12,018 Iter 95800, Minibatch Loss= 0.8157, Training Accuracy= 0.7482, Minibatch error= 6.0%\n",
      "2017-09-08 18:22:45,377 Iter 95850, Minibatch Loss= 0.1950, Training Accuracy= 0.6255, Minibatch error= 6.1%\n",
      "2017-09-08 18:30:13,311 Epoch 958, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 18:30:13,381 Verification error= 5.4%, loss= 0.2658\n",
      "2017-09-08 18:31:00,853 Iter 95900, Minibatch Loss= 0.2998, Training Accuracy= 0.6529, Minibatch error= 8.4%\n",
      "2017-09-08 18:38:35,356 Iter 95950, Minibatch Loss= 0.2914, Training Accuracy= 0.6693, Minibatch error= 4.8%\n",
      "2017-09-08 18:46:00,372 Epoch 959, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 18:46:00,450 Verification error= 5.6%, loss= 0.3425\n",
      "2017-09-08 18:46:49,077 Iter 96000, Minibatch Loss= 0.2560, Training Accuracy= 0.6445, Minibatch error= 4.6%\n",
      "2017-09-08 18:54:23,829 Iter 96050, Minibatch Loss= 0.2585, Training Accuracy= 0.6521, Minibatch error= 5.1%\n",
      "2017-09-08 19:01:49,996 Epoch 960, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 19:01:50,066 Verification error= 6.6%, loss= 0.4058\n",
      "2017-09-08 19:02:37,533 Iter 96100, Minibatch Loss= 1.0509, Training Accuracy= 0.6721, Minibatch error= 8.9%\n",
      "2017-09-08 19:10:13,196 Iter 96150, Minibatch Loss= 0.9514, Training Accuracy= 0.6932, Minibatch error= 8.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-08 19:17:38,570 Epoch 961, Average loss: 0.0114, learning rate: 0.0010\n",
      "2017-09-08 19:17:38,639 Verification error= 6.4%, loss= 0.3810\n",
      "2017-09-08 19:18:25,989 Iter 96200, Minibatch Loss= 0.5949, Training Accuracy= 0.7620, Minibatch error= 8.2%\n",
      "2017-09-08 19:26:01,728 Iter 96250, Minibatch Loss= 1.1549, Training Accuracy= 0.6786, Minibatch error= 8.8%\n",
      "2017-09-08 19:33:28,113 Epoch 962, Average loss: 0.0111, learning rate: 0.0010\n",
      "2017-09-08 19:33:28,191 Verification error= 6.1%, loss= 0.3814\n",
      "2017-09-08 19:34:15,788 Iter 96300, Minibatch Loss= 0.1861, Training Accuracy= 0.7229, Minibatch error= 6.1%\n",
      "2017-09-08 19:41:56,892 Iter 96350, Minibatch Loss= 0.1393, Training Accuracy= 0.7128, Minibatch error= 3.5%\n",
      "2017-09-08 19:49:29,435 Epoch 963, Average loss: 0.0096, learning rate: 0.0010\n",
      "2017-09-08 19:49:29,506 Verification error= 5.7%, loss= 0.4050\n",
      "2017-09-08 19:50:20,320 Iter 96400, Minibatch Loss= 0.3295, Training Accuracy= 0.7227, Minibatch error= 6.1%\n",
      "2017-09-08 19:58:02,562 Iter 96450, Minibatch Loss= 0.8130, Training Accuracy= 0.7643, Minibatch error= 6.6%\n",
      "2017-09-08 20:05:34,897 Epoch 964, Average loss: 0.0109, learning rate: 0.0010\n",
      "2017-09-08 20:05:34,975 Verification error= 5.6%, loss= 0.3756\n",
      "2017-09-08 20:06:22,921 Iter 96500, Minibatch Loss= 0.2361, Training Accuracy= 0.7026, Minibatch error= 6.4%\n",
      "2017-09-08 20:14:05,358 Iter 96550, Minibatch Loss= 0.3773, Training Accuracy= 0.5438, Minibatch error= 7.7%\n",
      "2017-09-08 20:21:38,831 Epoch 965, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 20:21:38,901 Verification error= 5.9%, loss= 0.4128\n",
      "2017-09-08 20:22:26,947 Iter 96600, Minibatch Loss= 0.3087, Training Accuracy= 0.7026, Minibatch error= 5.6%\n",
      "2017-09-08 20:30:10,280 Iter 96650, Minibatch Loss= 0.2826, Training Accuracy= 0.6594, Minibatch error= 6.5%\n",
      "2017-09-08 20:37:43,262 Epoch 966, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 20:37:43,340 Verification error= 5.9%, loss= 0.4452\n",
      "2017-09-08 20:38:30,995 Iter 96700, Minibatch Loss= 0.3613, Training Accuracy= 0.6836, Minibatch error= 5.2%\n",
      "2017-09-08 20:46:14,701 Iter 96750, Minibatch Loss= 0.6981, Training Accuracy= 0.7060, Minibatch error= 8.3%\n",
      "2017-09-08 20:53:49,329 Epoch 967, Average loss: 0.0099, learning rate: 0.0010\n",
      "2017-09-08 20:53:49,407 Verification error= 6.3%, loss= 0.3791\n",
      "2017-09-08 20:54:37,296 Iter 96800, Minibatch Loss= 1.5335, Training Accuracy= 0.6120, Minibatch error= 9.1%\n",
      "2017-09-08 21:02:21,379 Iter 96850, Minibatch Loss= 1.0178, Training Accuracy= 0.7357, Minibatch error= 9.3%\n",
      "2017-09-08 21:09:55,488 Epoch 968, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-08 21:09:55,558 Verification error= 5.8%, loss= 0.3371\n",
      "2017-09-08 21:10:44,023 Iter 96900, Minibatch Loss= 0.6075, Training Accuracy= 0.7615, Minibatch error= 7.6%\n",
      "2017-09-08 21:18:28,543 Iter 96950, Minibatch Loss= 0.2167, Training Accuracy= 0.6919, Minibatch error= 6.6%\n",
      "2017-09-08 21:26:03,068 Epoch 969, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 21:26:03,147 Verification error= 5.7%, loss= 0.3308\n",
      "2017-09-08 21:26:51,325 Iter 97000, Minibatch Loss= 0.1828, Training Accuracy= 0.7529, Minibatch error= 4.7%\n",
      "2017-09-08 21:34:35,928 Iter 97050, Minibatch Loss= 0.3736, Training Accuracy= 0.7255, Minibatch error= 6.8%\n",
      "2017-09-08 21:42:13,430 Epoch 970, Average loss: 0.0102, learning rate: 0.0010\n",
      "2017-09-08 21:42:13,509 Verification error= 6.3%, loss= 0.4055\n",
      "2017-09-08 21:43:01,489 Iter 97100, Minibatch Loss= 0.7952, Training Accuracy= 0.7831, Minibatch error= 7.0%\n",
      "2017-09-08 21:50:50,050 Iter 97150, Minibatch Loss= 0.1974, Training Accuracy= 0.6672, Minibatch error= 5.4%\n",
      "2017-09-08 21:58:30,062 Epoch 971, Average loss: 0.0094, learning rate: 0.0010\n",
      "2017-09-08 21:58:30,140 Verification error= 5.4%, loss= 0.3282\n",
      "2017-09-08 21:59:18,935 Iter 97200, Minibatch Loss= 0.3019, Training Accuracy= 0.6602, Minibatch error= 8.4%\n",
      "2017-09-08 22:07:07,460 Iter 97250, Minibatch Loss= 0.3768, Training Accuracy= 0.7271, Minibatch error= 5.8%\n",
      "2017-09-08 22:14:45,126 Epoch 972, Average loss: 0.0098, learning rate: 0.0010\n",
      "2017-09-08 22:14:45,196 Verification error= 5.9%, loss= 0.3890\n",
      "2017-09-08 22:15:33,530 Iter 97300, Minibatch Loss= 0.1839, Training Accuracy= 0.7740, Minibatch error= 5.5%\n",
      "2017-09-08 22:23:19,835 Iter 97350, Minibatch Loss= 0.3504, Training Accuracy= 0.7370, Minibatch error= 5.2%\n",
      "2017-09-08 22:30:56,749 Epoch 973, Average loss: 0.0104, learning rate: 0.0010\n",
      "2017-09-08 22:30:56,828 Verification error= 6.3%, loss= 0.3919\n",
      "2017-09-08 22:31:44,974 Iter 97400, Minibatch Loss= 0.8389, Training Accuracy= 0.7273, Minibatch error= 8.6%\n",
      "2017-09-08 22:39:31,998 Iter 97450, Minibatch Loss= 1.4498, Training Accuracy= 0.6831, Minibatch error= 8.3%\n",
      "2017-09-08 22:47:08,943 Epoch 974, Average loss: 0.0098, learning rate: 0.0010\n",
      "2017-09-08 22:47:09,012 Verification error= 6.7%, loss= 0.4780\n",
      "2017-09-08 22:47:57,693 Iter 97500, Minibatch Loss= 1.0991, Training Accuracy= 0.7622, Minibatch error= 8.3%\n",
      "2017-09-08 22:55:44,622 Iter 97550, Minibatch Loss= 0.9135, Training Accuracy= 0.7747, Minibatch error= 7.9%\n",
      "2017-09-08 23:03:22,335 Epoch 975, Average loss: 0.0103, learning rate: 0.0010\n",
      "2017-09-08 23:03:22,409 Verification error= 6.2%, loss= 0.3603\n",
      "2017-09-08 23:04:13,954 Iter 97600, Minibatch Loss= 0.2058, Training Accuracy= 0.7557, Minibatch error= 7.3%\n",
      "2017-09-08 23:12:01,591 Iter 97650, Minibatch Loss= 0.2752, Training Accuracy= 0.6336, Minibatch error= 5.7%\n",
      "2017-09-08 23:19:39,424 Epoch 976, Average loss: 0.0107, learning rate: 0.0010\n",
      "2017-09-08 23:19:39,502 Verification error= 6.0%, loss= 0.4113\n",
      "2017-09-08 23:20:28,276 Iter 97700, Minibatch Loss= 0.4502, Training Accuracy= 0.7237, Minibatch error= 6.1%\n",
      "2017-09-08 23:28:17,584 Iter 97750, Minibatch Loss= 0.7394, Training Accuracy= 0.7771, Minibatch error= 7.0%\n",
      "2017-09-08 23:35:55,838 Epoch 977, Average loss: 0.0113, learning rate: 0.0010\n",
      "2017-09-08 23:35:55,911 Verification error= 6.0%, loss= 0.3152\n",
      "2017-09-08 23:36:44,107 Iter 97800, Minibatch Loss= 0.2030, Training Accuracy= 0.6940, Minibatch error= 5.1%\n",
      "2017-09-08 23:44:32,812 Iter 97850, Minibatch Loss= 0.3060, Training Accuracy= 0.7125, Minibatch error= 9.0%\n",
      "2017-09-08 23:52:11,941 Epoch 978, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-08 23:52:12,020 Verification error= 7.0%, loss= 0.4651\n",
      "2017-09-08 23:53:00,343 Iter 97900, Minibatch Loss= 0.3349, Training Accuracy= 0.7297, Minibatch error= 6.6%\n",
      "2017-09-09 00:00:49,214 Iter 97950, Minibatch Loss= 0.2159, Training Accuracy= 0.6768, Minibatch error= 5.5%\n",
      "2017-09-09 00:08:29,068 Epoch 979, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-09 00:08:29,141 Verification error= 5.1%, loss= 0.2434\n",
      "2017-09-09 00:09:17,615 Iter 98000, Minibatch Loss= 0.2165, Training Accuracy= 0.7112, Minibatch error= 4.6%\n",
      "2017-09-09 00:17:08,091 Iter 98050, Minibatch Loss= 0.7578, Training Accuracy= 0.6703, Minibatch error= 8.1%\n",
      "2017-09-09 00:24:47,246 Epoch 980, Average loss: 0.0105, learning rate: 0.0010\n",
      "2017-09-09 00:24:47,325 Verification error= 5.7%, loss= 0.2977\n",
      "2017-09-09 00:25:36,219 Iter 98100, Minibatch Loss= 1.3159, Training Accuracy= 0.5716, Minibatch error= 8.9%\n",
      "2017-09-09 00:33:25,562 Iter 98150, Minibatch Loss= 0.3369, Training Accuracy= 0.7346, Minibatch error= 6.7%\n",
      "2017-09-09 00:41:05,735 Epoch 981, Average loss: 0.0093, learning rate: 0.0010\n",
      "2017-09-09 00:41:05,813 Verification error= 5.8%, loss= 0.3014\n",
      "2017-09-09 00:41:54,512 Iter 98200, Minibatch Loss= 0.5910, Training Accuracy= 0.7432, Minibatch error= 7.0%\n",
      "2017-09-09 00:49:44,667 Iter 98250, Minibatch Loss= 0.2213, Training Accuracy= 0.6888, Minibatch error= 5.8%\n",
      "2017-09-09 00:57:25,594 Epoch 982, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-09 00:57:25,672 Verification error= 5.4%, loss= 0.2591\n",
      "2017-09-09 00:58:14,229 Iter 98300, Minibatch Loss= 0.1386, Training Accuracy= 0.7299, Minibatch error= 3.6%\n",
      "2017-09-09 01:06:05,699 Iter 98350, Minibatch Loss= 0.2800, Training Accuracy= 0.6565, Minibatch error= 5.8%\n",
      "2017-09-09 01:13:46,699 Epoch 983, Average loss: 0.0096, learning rate: 0.0010\n",
      "2017-09-09 01:13:46,778 Verification error= 5.5%, loss= 0.2821\n",
      "2017-09-09 01:14:35,453 Iter 98400, Minibatch Loss= 0.7129, Training Accuracy= 0.8010, Minibatch error= 6.4%\n",
      "2017-09-09 01:22:25,959 Iter 98450, Minibatch Loss= 0.1955, Training Accuracy= 0.5927, Minibatch error= 5.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-09 01:30:07,430 Epoch 984, Average loss: 0.0101, learning rate: 0.0010\n",
      "2017-09-09 01:30:07,499 Verification error= 5.9%, loss= 0.3041\n",
      "2017-09-09 01:30:56,379 Iter 98500, Minibatch Loss= 0.3338, Training Accuracy= 0.6807, Minibatch error= 9.5%\n",
      "2017-09-09 01:38:48,344 Iter 98550, Minibatch Loss= 0.1919, Training Accuracy= 0.7456, Minibatch error= 5.5%\n",
      "2017-09-09 01:46:31,679 Epoch 985, Average loss: 0.0100, learning rate: 0.0010\n",
      "2017-09-09 01:46:31,752 Verification error= 5.6%, loss= 0.2783\n",
      "2017-09-09 01:47:20,629 Iter 98600, Minibatch Loss= 0.2335, Training Accuracy= 0.7521, Minibatch error= 4.9%\n",
      "2017-09-09 01:55:14,103 Iter 98650, Minibatch Loss= 0.3635, Training Accuracy= 0.7414, Minibatch error= 5.2%\n",
      "2017-09-09 02:02:56,463 Epoch 986, Average loss: 0.0098, learning rate: 0.0010\n",
      "2017-09-09 02:02:56,540 Verification error= 6.0%, loss= 0.3598\n",
      "2017-09-09 02:03:48,535 Iter 98700, Minibatch Loss= 0.6297, Training Accuracy= 0.6883, Minibatch error= 9.0%\n",
      "2017-09-09 02:11:42,949 Iter 98750, Minibatch Loss= 1.4772, Training Accuracy= 0.6169, Minibatch error= 10.3%\n",
      "2017-09-09 02:19:26,068 Epoch 987, Average loss: 0.0094, learning rate: 0.0010\n",
      "2017-09-09 02:19:26,137 Verification error= 5.4%, loss= 0.2697\n",
      "2017-09-09 02:20:15,784 Iter 98800, Minibatch Loss= 0.4760, Training Accuracy= 0.7805, Minibatch error= 6.4%\n",
      "2017-09-09 02:28:08,591 Iter 98850, Minibatch Loss= 0.6596, Training Accuracy= 0.7154, Minibatch error= 7.6%\n",
      "2017-09-09 02:35:52,466 Epoch 988, Average loss: 0.0091, learning rate: 0.0010\n",
      "2017-09-09 02:35:52,544 Verification error= 6.8%, loss= 0.4389\n",
      "2017-09-09 02:36:41,402 Iter 98900, Minibatch Loss= 0.2533, Training Accuracy= 0.7234, Minibatch error= 7.2%\n",
      "2017-09-09 02:44:36,499 Iter 98950, Minibatch Loss= 0.1772, Training Accuracy= 0.6870, Minibatch error= 4.2%\n",
      "2017-09-09 02:52:21,505 Epoch 989, Average loss: 0.0099, learning rate: 0.0010\n",
      "2017-09-09 02:52:21,583 Verification error= 5.4%, loss= 0.3173\n",
      "2017-09-09 02:53:10,653 Iter 99000, Minibatch Loss= 0.3174, Training Accuracy= 0.6544, Minibatch error= 6.8%\n",
      "2017-09-09 03:01:04,609 Iter 99050, Minibatch Loss= 0.5819, Training Accuracy= 0.7979, Minibatch error= 5.2%\n",
      "2017-09-09 03:08:49,727 Epoch 990, Average loss: 0.0108, learning rate: 0.0010\n",
      "2017-09-09 03:08:49,806 Verification error= 5.4%, loss= 0.2676\n",
      "2017-09-09 03:09:39,196 Iter 99100, Minibatch Loss= 0.1899, Training Accuracy= 0.7146, Minibatch error= 5.2%\n",
      "2017-09-09 03:17:33,420 Iter 99150, Minibatch Loss= 0.3538, Training Accuracy= 0.7563, Minibatch error= 9.0%\n",
      "2017-09-09 03:25:18,238 Epoch 991, Average loss: 0.0093, learning rate: 0.0010\n",
      "2017-09-09 03:25:18,308 Verification error= 6.3%, loss= 0.3824\n",
      "2017-09-09 03:26:08,203 Iter 99200, Minibatch Loss= 0.2989, Training Accuracy= 0.7003, Minibatch error= 6.5%\n",
      "2017-09-09 03:34:02,924 Iter 99250, Minibatch Loss= 0.2035, Training Accuracy= 0.7919, Minibatch error= 5.1%\n",
      "2017-09-09 03:41:48,141 Epoch 992, Average loss: 0.0135, learning rate: 0.0010\n",
      "2017-09-09 03:41:48,212 Verification error= 6.3%, loss= 0.3105\n",
      "2017-09-09 03:42:37,735 Iter 99300, Minibatch Loss= 0.2550, Training Accuracy= 0.7568, Minibatch error= 5.3%\n",
      "2017-09-09 03:50:33,705 Iter 99350, Minibatch Loss= 0.6857, Training Accuracy= 0.7589, Minibatch error= 7.9%\n",
      "2017-09-09 03:58:19,828 Epoch 993, Average loss: 0.0104, learning rate: 0.0010\n",
      "2017-09-09 03:58:19,899 Verification error= 5.9%, loss= 0.3773\n",
      "2017-09-09 03:59:09,276 Iter 99400, Minibatch Loss= 1.3138, Training Accuracy= 0.6630, Minibatch error= 8.8%\n",
      "2017-09-09 04:07:05,010 Iter 99450, Minibatch Loss= 0.4422, Training Accuracy= 0.7758, Minibatch error= 6.7%\n",
      "2017-09-09 04:14:51,686 Epoch 994, Average loss: 0.0104, learning rate: 0.0010\n",
      "2017-09-09 04:14:51,760 Verification error= 6.2%, loss= 0.3996\n",
      "2017-09-09 04:15:41,069 Iter 99500, Minibatch Loss= 0.8200, Training Accuracy= 0.7286, Minibatch error= 8.2%\n",
      "2017-09-09 04:23:38,279 Iter 99550, Minibatch Loss= 0.1913, Training Accuracy= 0.7807, Minibatch error= 6.5%\n",
      "2017-09-09 04:31:25,995 Epoch 995, Average loss: 0.0100, learning rate: 0.0010\n",
      "2017-09-09 04:31:26,073 Verification error= 5.9%, loss= 0.3479\n",
      "2017-09-09 04:32:15,550 Iter 99600, Minibatch Loss= 0.2320, Training Accuracy= 0.7669, Minibatch error= 4.4%\n",
      "2017-09-09 04:40:12,530 Iter 99650, Minibatch Loss= 0.4266, Training Accuracy= 0.7193, Minibatch error= 7.0%\n",
      "2017-09-09 04:48:00,556 Epoch 996, Average loss: 0.0098, learning rate: 0.0010\n",
      "2017-09-09 04:48:00,634 Verification error= 5.5%, loss= 0.3417\n",
      "2017-09-09 04:48:50,165 Iter 99700, Minibatch Loss= 0.7164, Training Accuracy= 0.7685, Minibatch error= 6.1%\n",
      "2017-09-09 04:56:47,534 Iter 99750, Minibatch Loss= 0.2460, Training Accuracy= 0.6951, Minibatch error= 5.4%\n",
      "2017-09-09 05:04:37,212 Epoch 997, Average loss: 0.0095, learning rate: 0.0010\n",
      "2017-09-09 05:04:37,291 Verification error= 5.4%, loss= 0.2910\n",
      "2017-09-09 05:05:29,758 Iter 99800, Minibatch Loss= 0.2650, Training Accuracy= 0.7625, Minibatch error= 8.4%\n",
      "2017-09-09 05:13:28,496 Iter 99850, Minibatch Loss= 0.2445, Training Accuracy= 0.7505, Minibatch error= 5.7%\n",
      "2017-09-09 05:21:18,087 Epoch 998, Average loss: 0.0096, learning rate: 0.0010\n",
      "2017-09-09 05:21:18,159 Verification error= 5.5%, loss= 0.3371\n",
      "2017-09-09 05:22:07,848 Iter 99900, Minibatch Loss= 0.2827, Training Accuracy= 0.6914, Minibatch error= 5.3%\n",
      "2017-09-09 05:30:07,166 Iter 99950, Minibatch Loss= 0.2633, Training Accuracy= 0.7240, Minibatch error= 5.1%\n",
      "2017-09-09 05:37:56,590 Epoch 999, Average loss: 0.0100, learning rate: 0.0010\n",
      "2017-09-09 05:37:56,663 Verification error= 5.6%, loss= 0.3313\n",
      "2017-09-09 05:38:36,540 Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "path = trainer.train(generator, \"./unet_trained\", training_iters=100, epochs=1000, dropout = 0.5, display_step=50, restore = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[1 2 3]\n",
      "[ True False False]\n"
     ]
    }
   ],
   "source": [
    " x = np.array([1, 2, 3])\n",
    "type(x)\n",
    "print (x.shape)\n",
    "print (x)\n",
    "a = (x == 1)\n",
    "print (a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
